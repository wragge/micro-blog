{
	"version": "https://jsonfeed.org/version/1",
	"title": "Tim Sherratt",
	"icon": "https://micro.blog/wragge/avatar.jpg",
	"home_page_url": "https://updates.timsherratt.org/",
	"feed_url": "https://updates.timsherratt.org/feed.json",
	"items": [
		
			{
				"id": "http://wragge.micro.blog/2021/10/15/glam-workbench-at.html",
				"title": "GLAM Workbench at eResearch Australasia 2021",
				"content_html": "<p>Way back in 2013, I went to the eResearch Australasia conference as the manager of Trove to talk about <a href=\"https://www.slideshare.net/wragge/beyond-discovery\">new research possibilities using the Trove API</a>. Eight years years later <a href=\"https://conference.eresearch.edu.au/events/a-glam-workbench-for-humanities-researchers/\">I was back</a>, still spruiking the possibilities of Trove data. This time, however, I was discussing Trove in the broader context of <strong>GLAM</strong> data ‚Äì all the exciting possibilities that have emerged as galleries, libraries, archives and museums make more of their collections available in machine-readable form. The <strong>big question</strong> is, of course, how do researchers, particularly those in the humanities, make use of that data? The <a href=\"https://glam-workbench.net/\">GLAM Workbench</a> is my attempt to address that question ‚Äì to provide humanities researchers with both the tools and information they need, and an understanding of the possibilities that might emerge if they invest a bit of time in working with GLAM data. My eResearch Australasia 2021 presentation provides a quick introduction to the GLAM Workbench, here‚Äôs the <a href=\"https://vimeo.com/631475562\">video</a>, and the <a href=\"https://slides.com/wragge/eresearch2021\">slides</a>.</p>\n\n<p><div style=\"padding:56.25% 0 0 0;position:relative;\"><iframe src=\"https://player.vimeo.com/video/631475562?h=6b2e2b5636\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen></iframe></div><script src=\"https://player.vimeo.com/api/player.js\"></script>\n<p><a href=\"https://vimeo.com/631475562\">A GLAM Workbench for humanities researchers</a> from <a href=\"https://vimeo.com/wragge\">Tim Sherratt</a> on <a href=\"https://vimeo.com\">Vimeo</a>.</p></p>\n\n<p>The presentation was pre-recorded, but I managed to sneak in an update via chat for those who attended the session. More news on this next week‚Ä¶ ü•≥</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/29b72b05bc.png\" alt=\"\" /></p>\n",
				"content_text": "Way back in 2013, I went to the eResearch Australasia conference as the manager of Trove to talk about [new research possibilities using the Trove API](https://www.slideshare.net/wragge/beyond-discovery). Eight years years later [I was back](https://conference.eresearch.edu.au/events/a-glam-workbench-for-humanities-researchers/), still spruiking the possibilities of Trove data. This time, however, I was discussing Trove in the broader context of **GLAM** data ‚Äì all the exciting possibilities that have emerged as galleries, libraries, archives and museums make more of their collections available in machine-readable form. The **big question** is, of course, how do researchers, particularly those in the humanities, make use of that data? The [GLAM Workbench](https://glam-workbench.net/) is my attempt to address that question ‚Äì to provide humanities researchers with both the tools and information they need, and an understanding of the possibilities that might emerge if they invest a bit of time in working with GLAM data. My eResearch Australasia 2021 presentation provides a quick introduction to the GLAM Workbench, here‚Äôs the [video](https://vimeo.com/631475562), and the [slides](https://slides.com/wragge/eresearch2021).\n\n<div style=\"padding:56.25% 0 0 0;position:relative;\"><iframe src=\"https://player.vimeo.com/video/631475562?h=6b2e2b5636\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen></iframe></div><script src=\"https://player.vimeo.com/api/player.js\"></script>\n<p><a href=\"https://vimeo.com/631475562\">A GLAM Workbench for humanities researchers</a> from <a href=\"https://vimeo.com/wragge\">Tim Sherratt</a> on <a href=\"https://vimeo.com\">Vimeo</a>.</p>\n\nThe presentation was pre-recorded, but I managed to sneak in an update via chat for those who attended the session. More news on this next week‚Ä¶ ü•≥\n\n![](https://updates.timsherratt.org/uploads/2021/29b72b05bc.png)\n\n",
				"date_published": "2021-10-15T09:50:58+11:00",
				"url": "https://updates.timsherratt.org/2021/10/15/glam-workbench-at.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/10/05/new-python-package.html",
				"title": "New Python package to download Trove newspaper images",
				"content_html": "<p>There&rsquo;s no reliable way of downloading an image of a Trove newspaper article from the web interface. The image download option produces an HTML page with embedded images, and the article is often sliced into pieces to fit the page.</p>\n\n<p>This <a href=\"https://pypi.org/project/trove-newspaper-images/\">Python package</a> includes tools to download articles as complete JPEG images. If an article is printed across multiple newspaper pages, multiple images will be downloaded ‚Äì one for each page. It&rsquo;s intended for integration into other tools and processing workflows, or for people who like working on the command line.</p>\n\n<p>You can use it as a library:</p>\n\n<pre><code>from trove_newspaper_images.articles import download_images\n\nimages = download_images('107024751')\n</code></pre>\n\n<p>Or from the command line:</p>\n\n<pre><code>trove_newspaper_images.download 107024751 --output_dir images\n</code></pre>\n\n<p>If you just want to quickly download an article as an image without installing anything, you can use <a href=\"https://glam-workbench.net/trove-newspapers/#save-a-trove-newspaper-article-as-an-image\">this web app</a> in the GLAM Workbench. To download images of all articles returned by a search in Trove, you can also use the <a href=\"https://glam-workbench.net/trove-harvester/\">Trove Newspaper and Gazette Harvester</a>.</p>\n\n<p>See the <a href=\"https://wragge.github.io/trove_newspaper_images/\">documentation</a> for more information. #dhhacks</p>\n",
				"content_text": "There's no reliable way of downloading an image of a Trove newspaper article from the web interface. The image download option produces an HTML page with embedded images, and the article is often sliced into pieces to fit the page.\n\nThis [Python package](https://pypi.org/project/trove-newspaper-images/) includes tools to download articles as complete JPEG images. If an article is printed across multiple newspaper pages, multiple images will be downloaded ‚Äì one for each page. It's intended for integration into other tools and processing workflows, or for people who like working on the command line.\n\nYou can use it as a library:\n\n\tfrom trove_newspaper_images.articles import download_images\n\t\n\timages = download_images('107024751')\n\nOr from the command line:\n\n\ttrove_newspaper_images.download 107024751 --output_dir images\n\nIf you just want to quickly download an article as an image without installing anything, you can use [this web app](https://glam-workbench.net/trove-newspapers/#save-a-trove-newspaper-article-as-an-image) in the GLAM Workbench. To download images of all articles returned by a search in Trove, you can also use the [Trove Newspaper and Gazette Harvester](https://glam-workbench.net/trove-harvester/).\n\nSee the [documentation](https://wragge.github.io/trove_newspaper_images/) for more information. #dhhacks\n\n",
				"date_published": "2021-10-05T12:03:00+11:00",
				"url": "https://updates.timsherratt.org/2021/10/05/new-python-package.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/09/29/more-records-for.html",
				"title": "More records for the GLAM Name Index Search",
				"content_html": "<p>Two more datasets have been added to the <a href=\"https://glam-workbench.net/name-search/\">GLAM Name Index Search</a>! From the <a href=\"https://history.sa.gov.au/\">History Trust of South Australia</a> and <a href=\"https://collab.sa.gov.au/\">Collab</a>, I‚Äôve added:</p>\n\n<ul>\n<li><a href=\"https://data.sa.gov.au/data/dataset/passengers-in-history\">Passengers in History</a> ‚Äì that‚Äôs 371,894 records of people arriving in South Australia from 1836 to 1961</li>\n<li><a href=\"https://data.sa.gov.au/data/dataset/3f6fab54-8cc8-4732-9c1e-fb3f73df53b0\">Women‚Äôs Suffrage Petition 1894 (South Australia)</a> ‚Äì another 10,638 names</li>\n</ul>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/7eadb95bde.png\" alt=\"\" title=\"Screenshot of GLAM Name Index Search home page\" /></p>\n\n<p>In total there‚Äôs 9.67 million name records to search across 197 datasets provided by 9 GLAM organisations!</p>\n",
				"content_text": "Two more datasets have been added to the [GLAM Name Index Search](https://glam-workbench.net/name-search/)! From the [History Trust of South Australia](https://history.sa.gov.au/) and [Collab](https://collab.sa.gov.au/), I‚Äôve added:\n\n* [Passengers in History](https://data.sa.gov.au/data/dataset/passengers-in-history) ‚Äì that‚Äôs 371,894 records of people arriving in South Australia from 1836 to 1961\n* [Women‚Äôs Suffrage Petition 1894 (South Australia)](https://data.sa.gov.au/data/dataset/3f6fab54-8cc8-4732-9c1e-fb3f73df53b0) ‚Äì another 10,638 names\n\n![](https://updates.timsherratt.org/uploads/2021/7eadb95bde.png \"Screenshot of GLAM Name Index Search home page\")\n\nIn total there‚Äôs 9.67 million name records to search across 197 datasets provided by 9 GLAM organisations!\n\n",
				"date_published": "2021-09-29T12:17:35+11:00",
				"url": "https://updates.timsherratt.org/2021/09/29/more-records-for.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/09/29/new-preprint-more.html",
				"title": "New preprint ‚Äì ‚ÄòMore than newspapers‚Äô",
				"content_html": "<p>Here‚Äôs the <a href=\"https://doi.org/10.5281/zenodo.5463710\">preprint version</a> of an article, ‚ÄòMore than newspapers‚Äô, that I‚Äôve submitted for a forum about Trove in a forthcoming issue of <em>History Australia</em>.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/79644bef1e.png\" alt=\"\" title=\"Screenshot of concluding paragraph of article: 'Access is a collective responsibility. GLAM institutions, like the National Library, need to be open about the policies and practices that shape their resources. But researchers need to honest about their methods, and ready to learn. Trove is not one thing. It is an attempt to bring together cultural heritage collections and deliver new means of discovery and use. Trove is revolutionary. Trove is flawed. It is inspiring and annoying ‚Äì seemingly limitless, but full of holes. Trove is a start, but not the end.'\" /></p>\n\n<p><a href=\"https://doi.org/10.5281/zenodo.5463710\"><img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.5463710.svg\" alt=\"DOI\" /></a></p>\n",
				"content_text": "Here‚Äôs the [preprint version](https://doi.org/10.5281/zenodo.5463710) of an article, ‚ÄòMore than newspapers‚Äô, that I‚Äôve submitted for a forum about Trove in a forthcoming issue of _History Australia_.\n\n![](https://updates.timsherratt.org/uploads/2021/79644bef1e.png \"Screenshot of concluding paragraph of article: 'Access is a collective responsibility. GLAM institutions, like the National Library, need to be open about the policies and practices that shape their resources. But researchers need to honest about their methods, and ready to learn. Trove is not one thing. It is an attempt to bring together cultural heritage collections and deliver new means of discovery and use. Trove is revolutionary. Trove is flawed. It is inspiring and annoying ‚Äì seemingly limitless, but full of holes. Trove is a start, but not the end.'\")\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.5463710.svg)](https://doi.org/10.5281/zenodo.5463710)\n\n\n\n",
				"date_published": "2021-09-29T11:53:08+11:00",
				"url": "https://updates.timsherratt.org/2021/09/29/new-preprint-more.html"
			},
			{
				"id": "http://wragge.micro.blog/2021/09/29/more-querypic-in.html",
				"title": "More QueryPic in action",
				"content_html": "<p>Recently I created a <a href=\"https://updates.timsherratt.org/2021/08/30/some-research-projects.html\">list of publications</a> that made use of <a href=\"https://glam-workbench.net/trove-newspapers/#querypic\">QueryPic</a>, my tool to visualise searches in Trove‚Äôs digitised newspapers. Here‚Äôs another example of the <a href=\"https://glam-workbench.net/\">GLAM Workbench</a> and QueryPic in action, in Professor Julian Meyrick‚Äôs recent keynote lecture, &lsquo;Looking Forward to the 1950s: A Hauntological Method for Investigating Australian Theatre History‚Äô.</p>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/iOLmEBlKeQs\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\\></iframe>\n",
				"content_text": "Recently I created a [list of publications](https://updates.timsherratt.org/2021/08/30/some-research-projects.html) that made use of [QueryPic](https://glam-workbench.net/trove-newspapers/#querypic), my tool to visualise searches in Trove‚Äôs digitised newspapers. Here‚Äôs another example of the [GLAM Workbench](https://glam-workbench.net/) and QueryPic in action, in Professor Julian Meyrick‚Äôs recent keynote lecture, 'Looking Forward to the 1950s: A Hauntological Method for Investigating Australian Theatre History‚Äô. \n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/iOLmEBlKeQs\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\\></iframe>\n\n",
				"date_published": "2021-09-29T11:30:26+11:00",
				"url": "https://updates.timsherratt.org/2021/09/29/more-querypic-in.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/09/10/some-thoughts-on.html",
				"title": "Some thoughts on the ‚ÄòTrove Researcher Platform for Advanced Research‚Äô draft plan",
				"content_html": "\n\n<p>Late last year the Federal Government <a href=\"https://ministers.dese.gov.au/tehan/improving-hass-and-indigenous-research-infrastructure\">announced</a> it was making an $8.9 million investment in HASS and Indigenous research infrastructure. This program is being managed by the ARDC and will lead to the development of a <a href=\"https://ardc.edu.au/collaborations/strategic-activities/hass-and-indigenous-research-data-commons/\">HASS Research Data Commons</a>. According to the ARDC, a research data commons:</p>\n\n<blockquote>\n<p>brings together people, skills, data, and related resources such as storage, compute, software, and models to enable researchers to conduct world class data-intensive research</p>\n</blockquote>\n\n<p>Sounds awesome!</p>\n\n<p>Based on scoping studies commissioned by the Department of Education, Skills, and Employment (which have not yet been made public), <a href=\"https://ardc.edu.au/collaborations/strategic-activities/hass-and-indigenous-research-data-commons/recommendations-for-co-investment-in-humanities-arts-and-social-sciences-research-data-commons-program/\">four activities were selected for initial funding</a> under this program. Draft project plans for these four activities have now been <a href=\"https://ardc.edu.au/collaborations/strategic-activities/hass-and-indigenous-research-data-commons/project-plans/\">released for public comment</a>.</p>\n\n<p>One of these activities aims to develop a ‚ÄôTrove researcher platform for advanced research‚Äô:</p>\n\n<blockquote>\n<p>Augmenting existing National Library of Australia resources, this platform will enable a focus on the delivery of researcher portals accessible through Trove, Australia‚Äôs unique public heritage site. The platform will create tools for visualisation, entity recognition, transcription and geocoding across Trove content and other corpora.</p>\n</blockquote>\n\n<p>You can <a href=\"https://ardc.edu.au/wp-content/uploads/2021/09/Research_Platform_TROVE.pdf\">download the draft project plan</a> for the Trove platform. Funding for this activity will be capped at $2,301,185 across 2021-23. In this post I‚Äôll try to pull together some of my own thoughts on this plan.</p>\n\n<p>I suppose I‚Äôd better start with a disclaimer ‚Äì I‚Äôm not a neutral observer in this. I started scraping data from Trove newspapers way back in 2010, building the first versions of tools like QueryPic and the Trove Newspaper Harvester. While I was manager of Trove, from 2013 to 2016, I argued for recognition of Trove as a key part of Australia‚Äôs humanities research infrastructure, and highlighted possible research uses of Trove data available through the API. Since then I‚Äôve worked to bring a range of digital tools, examples, tutorials, and hacks together for researchers in the <a href=\"https://glam-workbench.net/\">GLAM Workbench</a> ‚Äì a <a href=\"https://updates.timsherratt.org/2021/08/26/glam-workbench-a.html\">large number of these</a> work with data from Trove.</p>\n\n<p>I strongly believe that Trove should receive ongoing funding through <a href=\"https://www.dese.gov.au/ncris\">NCRIS</a> as a piece of national research infrastructure. Unfortunately though, the draft project plan does not make a strong case for investment ‚Äì it‚Äôs vague, unimaginative, and makes little attempt to integrate with existing tools and services. I think it scores poorly against the ARDC‚Äôs <a href=\"https://ardc.edu.au/wp-content/uploads/2021/09/Evaluation-Criteria-HASS-RDC-and-Indigenous-Research-Capability-program.pdf\">evaluation criteria</a>, and doesn‚Äôt seem to offer good value for money. As someone who has championed the use of Trove data for research across the last decade, I‚Äôm very disappointed.</p>\n\n<h2 id=\"what-s-planned\">What‚Äôs planned?</h2>\n\n<p>So what is being proposed? There seems to be three main components:</p>\n\n<ol>\n<li>Authenticated ‚Äòproject‚Äô spaces for researchers where datasets relating to a particular research topic can be stored</li>\n<li>The ability to create custom datasets from a search in Trove</li>\n<li>Tools to visualise stored datasets.</li>\n</ol>\n\n<p>There‚Äôs no doubt that these are all useful functions for researchers, but many problems arise when we look at how they‚Äôre going to be implemented.</p>\n\n<h3 id=\"1-authenticated-project-spaces\">1. Authenticated project spaces</h3>\n\n<p>The draft plan indicates that authentication of users through the <a href=\"https://aaf.edu.au/\">Australian Access Federation</a> is preferred. Why? Trove already has a system for the creation of user accounts. Using AAF would limit use of the new platform to those attached to universities or research agencies. I don‚Äôt understand what the use of AAF adds to the project, except perhaps to provide an example of integration with existing infrastructure services.</p>\n\n<p>The plan notes that project spaces could be ‚Äòpublic‚Äô or ‚Äòprivate‚Äô. Presumably a ‚Äòpublic‚Äô space would give access to stored datasets, but what sort of access controls would be available in relation to individual datasets? It‚Äôs also noted (Deliverable 7) that researchers would have ‚Äòan option to ‚Äúpublish‚Äù their research findings for public consumption‚Äò. Does this mean datasets and visualisations would be assigned a DOI (or other persistent identifier) and preserved indefinitely? How might these spaces integrate with existing data repositories?</p>\n\n<h3 id=\"2-create-custom-datasets\">2. Create custom datasets</h3>\n\n<p>The lack of detail in the plan makes it difficult to assess what‚Äôs being proposed here. But it seems that users would be able to construct a search using the Trove web interface (or a new search interface?) and save the results as a dataset.</p>\n\n<p>What data would be searched? It‚Äôs not clear, but in reference to the visualisations it‚Äôs stated that data would come from ‚ÄôTrove‚Äôs existing full text collections (newspapers and gazettes, magazines and newsletters, books)‚Äô. So no web archives, and no metadata from any of Trove‚Äôs aggregated collections (even without full text, collection metadata can create interesting research possibilities, see for example the <a href=\"https://glam-workbench.net/trove-music/\">Radio National records</a> in the GLAM Workbench).</p>\n\n<p>What will be included in each dataset? There‚Äôs few details, but at a minimum you‚Äôd expect something like a CSV containing the metadata of all the matching records, and files containing the full text content of the items. These could potentially be <em>very</em> large. There‚Äôs no indication about how storage and processing demands would be managed, but presumably there would be some per user, or per project, limits.</p>\n\n<p>Deliverable 8, ‚ÄòData and visual download‚Äô, states that:</p>\n\n<blockquote>\n<p>All query results must be available as downloadable files, this would include CSV, JSON and XML for the query results list.</p>\n</blockquote>\n\n<p>But there‚Äôs no mention of the full text content at all. Will it be included in downloadable datasets?</p>\n\n<p>As well as the record metadata and full text, you‚Äôd want there to be some metadata captured about the dataset itself ‚Äì the search query used, when it was captured, the number of records, etc. To support integration and reuse, it would be good to align this with something like <a href=\"https://www.researchobject.org/ro-crate/\">RO Crate</a>.</p>\n\n<p>How will searches be constructed? It‚Äôs not clear if this will be integrated with the existing search interface, or be something completely separate; however, the plan does note that ‚Äòlimitations are put onto the dataset like keyword search terms and filters corresponding to the filters currently available in the interface‚Äô. So it seems that the new platform will be using the existing search indexes. It‚Äôs obviously important for the relationship between existing search functions and the new dataset creation tool to be explicit and transparent so that researchers understand what they‚Äôre getting.</p>\n\n<p>It‚Äôs also worth noting that changes to the search interface last year removed some useful options from the advanced search form. In particular, you can no longer exclude matches in tags or comments. If you‚Äôre a researcher looking for the occurrence of a particular word, you generally don‚Äôt want to include records where that word only appears in a user added tag (I have a story about ‚ÄòWord War I‚Äô that illustrates this!).</p>\n\n<p>This raises a broader issue. There doesn‚Äôt seem to be any mention in the project plan of work to improve the metadata and indexing in response to research needs. Even just identifying digitised books in the current web interface can be a bit of a challenge, and digitised books and periodicals can be grouped into work records with other versions. We need to recognise that the needs of discovery sometimes compromise specific research uses.</p>\n\n<p>I‚Äôm trying to be constructive in my responses here, but at this point I just have to scream ‚Äì WHAT ABOUT THE <a href=\"https://glam-workbench.net/trove-harvester/\">TROVE NEWSPAPER HARVESTER</a>? A tool has existed for <em>ten years</em> that lets users create a dataset containing metadata and full text from a search in Trove‚Äôs newspapers and gazettes. I‚Äôve spent a lot of time over recent years adding features and making it easier to use. Now you can download not only full text, but also PDFs and images of articles. The latest web app version in the GLAM Workbench runs in the cloud. Just one click to start it up, then all you need to do is paste in your Trove API key and the url of your search. It can‚Äôt get much easier.</p>\n\n<p>The GLAM Workbench also includes tools to create datasets and download OCRd text from Trove‚Äôs <a href=\"https://glam-workbench.net/trove-books/\">books</a> and digitised <a href=\"https://glam-workbench.net/trove-journals/\">journals</a>. These are still in notebook form, so are not as easy to use, but I have created pre-harvested datasets of all books and periodicals with OCRd text, and stored them on CloudStor. What‚Äôs missing at the moment is something to harvest a collection of journal articles, but this would not be difficult. As an added bonus, the GLAM Workbench has tools to <a href=\"https://glam-workbench.net/web-archives/#harvesting-collections-of-text-from-archived-web-pages\">create full text datasets</a> from the Australian Web Archive.</p>\n\n<p>So what is this project really adding? And why is there no attempt to leverage existing tools and resources?</p>\n\n<h3 id=\"3-visualise-datasets\">3. Visualise datasets</h3>\n\n<p>Again, there‚Äôs a fair bit of hand waving in the plan, but it seems that users will be able to select a stored dataset and then choose a form of visualisation. The plan says that:</p>\n\n<blockquote>\n<p>An initial pilot would allow users to create line graphs that plot the frequency of a search term over time and maps that display results based on state-level geolocation.</p>\n</blockquote>\n\n<p>Up to three additional visualisations would be created later based on research feedback. It‚Äôs not clear which researchers will be consulted and when their feedback will be sought.</p>\n\n<p>The value of these sorts of visualisations is obviously dependent on the quality and consistency of the metadata. There‚Äôs nothing built into this plan that would, for example, allow a researcher to clean or normalise any of the saved data. You have to take what you‚Äôre given. The newspaper metadata is generally consistent, but books and periodicals less so.</p>\n\n<p>It‚Äôs also important to clarify what‚Äôs meant by ‚Äòthe frequency of a search term over time‚Äô. Does this mean the number of records matching a search term, or the number of times that the search term actually appears in the full text of all matched records? If the latter, then this <em>would</em> be a major enrichment of the available data. Though if this data was available it should be pushed through the API and/or made available as a downloadable dataset for integration with other platforms (perhaps along the lines of the Hathi Trust‚Äôs <a href=\"https://analytics.hathitrust.org/datasets\">Extracted Features Dataset</a>). I suspect, however, that what is actually meant is the number of matching search results.</p>\n\n<p>Again, the value of any geospatial visualisation depends on what is actually being visualised! The <code>state</code> facet in newspapers indicates place of publication, it‚Äôs not clear what the <code>place</code> facet in other categories represents. For this sort of visualisation to be useful in a research context, there would need to be some explanation of how these values were created, and any gaps or uncertainties.</p>\n\n<p>Time for another scream of frustration ‚Äî WHAT ABOUT <a href=\"https://glam-workbench.net/trove-newspapers/#querypic\">QUERYPIC</a>? Another long-standing tool which has already been <a href=\"https://updates.timsherratt.org/2021/08/30/some-research-projects.html\">cited a number of times</a> in research literature. <a href=\"https://glam-workbench.net/trove-newspapers/#querypic\">QueryPic</a> visualises searches in Trove‚Äôs newspapers and gazettes over time. You can adjust time scales and intervals, and download the results as images, a CSV file, and an HTML page. The project plan makes a point of claiming that its tools would not require any coding, but neither does QueryPic. Just plug in an API key and a search URL. I even made <a href=\"https://www.youtube.com/playlist?list=PLAclcciEeCD2z2BWQ2r3xD_Q8c05HppfP\">some videos</a> about it! The GLAM Workbench also includes a number of examples of how you can <a href=\"https://glam-workbench.net/trove-newspapers/#map-trove-newspaper-results-by-state\">visualise places of publication</a> of newspaper articles.</p>\n\n<p>But it‚Äôs not just the GLAM Workbench. The <a href=\"https://ardc.edu.au/wp-content/uploads/2021/09/Language_Commons_Australia.pdf\">Linguistics Data Commons of Australia</a>, another activity to be funded as part of the HASS Research Data Commons, will include tools for text analysis and visualisation. The <a href=\"https://www.tlcmap.org/\">Time Layered Cultural Map</a> is developing tools for geospatial visualisation of Australian collections. Surely the focus should be on connecting and reusing what‚Äôs available. Again I‚Äôm wondering what this project is really adding.</p>\n\n<h2 id=\"portals-and-platforms\">Portals and platforms</h2>\n\n<p>The original language describing the funded activity is interesting ‚Äî it is intended to ‚Äòfocus on the delivery of researcher portals accessible through Trove‚Äô.</p>\n\n<p><strong><em>Portals</em> (plural) accessible <em>through</em> (not in) Trove.</strong></p>\n\n<p>The NLA could meet a fair proportion of its stated objectives right now, simply by including links to QueryPic and the Trove Newspaper and Gazette Harvester. Done! There‚Äôs a million dollars saved.</p>\n\n<p>More seriously, there‚Äôs no reason why the outcome of this activity should be a new interface attached to Trove and managed by the NLA. Indeed, such an approach works against integration, reuse, and data sharing. I believe the basic assumptions of the draft plan are seriously flawed. We need to separate out the strands of what‚Äôs meant by a ‚Äòplatform for advanced research‚Äô, and think more creatively and collaboratively about how we could achieve something useful, flexible, and sustainable.</p>\n\n<h2 id=\"where-s-the-api\">Where‚Äôs the API?</h2>\n\n<p>I think the primary role of the NLA in the development of this research platform should be as the data provider. There are numerous ways in which Trove‚Äôs data might be improved and enriched in support of new research uses. These improvements could then be pushed through the API to integrate with a range of tools and resources. Which raises the question ‚Äî where is the API in this plan?</p>\n\n<p>The only mention of the API comes as an option for a user with ‚Äòhigh technical expertise‚Äô to extend the analysis provided by the built-in visualisations. This is all backwards. The API is the key pipeline for data-sharing and integration and should be at the heart of this plan.</p>\n\n<p>This program offers an opportunity to make some much-needed improvements to the API. Here‚Äôs a few possibilities:</p>\n\n<ul>\n<li>Bring the web interface and API back into sync so that researchers can easily transfer queries between the two (Trove‚Äôs interface update introduced new categories, while the API still groups resources by the original zones).</li>\n<li>Provide public API access to additional data about digitised items. For example, you can get lists of newspaper titles and issues from the API, but there‚Äôs no comparable method to get titles and issues for digitised periodicals. The data‚Äôs there ‚Äì it‚Äôs used to generate lists of issues in the browse interface ‚Äì but it‚Äôs not in the API. There‚Äôs also other resource metadata, such as parent/child relationships, which are embedded in web pages but not exposed in the API.</li>\n<li>Standardise the delivery of OCRd text for different resource types.</li>\n<li>Finally add the People &amp; Organisations data to the main RESTful API.</li>\n<li>Fix the limitations of the web archives CDX API (<a href=\"https://nbviewer.jupyter.org/github/GLAM-Workbench/web-archives/blob/master/comparing_cdx_apis.ipynb\">documented here</a>).</li>\n<li>Add a search API for the web archives.</li>\n<li>And what about a Write API? Integration between components in the HASS RDC would be greatly enhanced if other projects could automatically add structured annotations to existing Trove resources.</li>\n</ul>\n\n<p>I think the HASS RDC would benefit greatly by thinking much more about the role of the Trove API in establishing reusable data flows, and connecting up components.</p>\n\n<h2 id=\"pathways\">Pathways</h2>\n\n<p>Anyone who‚Äôs been to one of my <a href=\"https://glam-workbench.net/presentations/\">GLAM Workbench talks</a> will know that I talk a lot about ‚Äòpathways‚Äô. My concern is not just to provide useful tools and examples, but to try and connect them in ways that encourage researchers to develop their skills and confidence. So a researcher with limited digital skills can spin up QueryPic and start making visualisations without any specialised knowledge. But if they want to explore the data and assumptions behind QueryPic, they can view a notebook that walks them through the process of getting data from facets and assembling a time series. If they find something interesting in QueryPic, they can go to the Newspaper Harvester and assemble a dataset that helps them zoom into a particular period. There are places to go.</p>\n\n<p>Similarly, users can start making use of the GLAM Workbench in the cloud using <a href=\"https://glam-workbench.net/using-binder/\">Binder</a> ‚Äì one click and it‚Äôs running. But as their research develops they might find Binder a bit limiting, so there are options to spin up the GLAM Workbench using <a href=\"https://glam-workbench.net/using-reclaim-cloud/\">Reclaim Cloud</a> or <a href=\"https://glam-workbench.net/using-docker/\">Docker</a>. As a researcher‚Äôs skills, needs, and questions change, so does their use of the GLAM Workbench. At least that‚Äôs the plan ‚Äì I‚Äôm very aware that there‚Äôs much, much more to do to build and document these pathways.</p>\n\n<p>The developments described in the draft plan are focused on providing simple tools for non-technical users. That‚Äôs fair enough, but you have to give those users somewhere to go, some path beyond, or else it just becomes another dead end. Users can download their data or visualisation, but then what?</p>\n\n<p>Of course you don‚Äôt point a non-coder to API documentation and say ‚Äòthere you go‚Äô. But coders can use the API to build and share a range of tools that introduce people to the possibilities of data, and scaffold their learning. Why should there be just one interface? It‚Äôs not too difficult to imagine a range of introductory visualisation tools aimed at different humanities disciplines. Instead of focusing inward on a single Trove Viz Lite tool, why not look outwards at ways of embedding Trove data within a range of research training contexts?</p>\n\n<h2 id=\"integration\">Integration</h2>\n\n<p>A number of the HASS RDC Evaluation Criteria focus on issues of integration, collaboration, and reuse of existing resources. For example:</p>\n\n<blockquote>\n<ul>\n<li>Project plans should display robust proposal planning including the maximisation of the use or re-use of existing research infrastructure, platforms, tools, services, data storage and compute.</li>\n<li>Project plans should display integrated infrastructure layers with other HASS RDC activities, in particular by linking together elements such as data storage, tools, authentication, licensing, networks, cloud and high-performance computing, and access to data resources for reuse.</li>\n<li>Project plans must be robust and contribute to the HASS RDC as a coherent whole that capitalises on existing data collections, adheres to the F.A.I.R. principles, develops collaborative tools, utilises shared underlying infrastructure and has appropriate governance planning.</li>\n</ul>\n</blockquote>\n\n<p>There‚Äôs little evidence of this sort of thinking in the draft project plan. I‚Äôve mentioned a few obvious opportunities for integration above, but there are many more. Overall, I think the proposed ‚Äòplatform for advanced research‚Äô needs to be designed as a series of interconnected components, and not be seen as the product of a single institution.</p>\n\n<p>We could imagine, for example, a system where the NLA focused on the delivery of research-ready data via the Trove API. A layer of data filtering, cleaning, and packaging tools could be built on top of the API to help users assemble actionable datasets. The packaging processes could use standards such as RO-Crate to prepare datasets for ingest into data repositories. Existing storage services, such as CloudStor, could be used for saving and sharing working datasets. Another layer of visualisation and analysis tools could either process these datasets, or integrate directly with the API. These tools could be spread across different projects including LDaCA, TLCMap, and the GLAM Workbench ‚Äî using standards such as Jupyter to encourage sharing and reuse of individual components, and running on a variety of cloud-hosted platforms. Instead of just adding another component to Trove, we‚Äôd be building a collaborative network of tool builders and data wranglers ‚Äî developing capacities across the research sector, and spreading the burden of maintenance.</p>\n\n<h2 id=\"sustainability\">Sustainability</h2>\n\n<p>The draft project plan includes some pretty worrying comments about long-term support for the new platform. Work Package 5 notes:</p>\n\n<blockquote>\n<p>The developed product will require support post release which can be guaranteed for a period not exceeding the contracted period for this project</p>\n</blockquote>\n\n<p>And:</p>\n\n<blockquote>\n<p>ARDC will be responsible for providing ongoing financial support for this phase. It has not been included in the proposal.</p>\n</blockquote>\n\n<p>So once the project is over, the NLA will not support the new platform unless the ARDC provides ongoing funding. What researcher would want to ‚Äòpublish‚Äô their data on a platform that could disappear at any time? We all know that sustainability is hard, but you would think that the NLA could at least offer to work collaboratively with the research sector to develop a plan for sustainability, instead of just asking for more money. Why would anyone invest so much for so little?</p>\n\n<h2 id=\"leadership-and-community\">Leadership and community</h2>\n\n<p>The development of collaborations and communities also figure prominently in the HASS RDC Evaluation Criteria. For example:</p>\n\n<blockquote>\n<ul>\n<li>Project plans should clearly demonstrate that they enable collaboration and build communities across geographically dispersed research groups through facilitated sharing of high-quality data, particularly for computational analysis; the development of new platforms for collaboration and sharing; and, the encouragement of innovative methodologies through the use of analytic tools.</li>\n<li>Project plans must include a demonstrated commitment to ongoing community development to ensure the sustainability of the development is vital. The deliverables will act as ongoing national research infrastructure. They must be broadly usable by more than just the project partners and serve as input to a wide range of research.</li>\n<li>Project plans, and project leads in particular, should demonstrate the research leadership that will foster and encourage the uptake and use of the HASS RDC.</li>\n</ul>\n</blockquote>\n\n<p>Once again the draft project plan falls short. There are no project partners listed. Instead the plan refers broadly to all of Trove‚Äôs content partners, none of whom have direct involvement in this project. Indeed, as noted above, data aggregated from project parters is excluded from the new platform.</p>\n\n<p>There are no new governance arrangements proposed for this project. Instead the plan refers to the Trove Strategic Advisory Committee which includes representatives from partner organisations. But there are no researcher representatives on this committee.</p>\n\n<p>The only consultation with the research sector undertaken in the ‚ÄòConsultation Phase‚Äô of the project is that undertaken by the ARDC itself. Does that mean this current process whereby the ARDC is soliciting feedback on the project plans? Whoa, meta‚Ä¶</p>\n\n<p>The plan notes that during the testing phase described in Work Package 3, ‚ÄòHASS community members would gain access to a beta version of the product for comment‚Äô. However, later it is stated that access would be provided to ‚Äôa subset of researchers‚Äô, and that only system bugs and ‚Äòhigh priority improvements‚Äô would be acted upon.</p>\n\n<p>Generally speaking, it seems that the NLA is seeking as little consultation as possible. It‚Äôs not exploring options for collaboration. It‚Äôs not engaging with the research community about these developments. That doesn‚Äôt seem like an effective way to build communities. Nor does it demonstrate leadership.</p>\n\n<h2 id=\"summing-up\">Summing up</h2>\n\n<p>This project plan can‚Äôt be accepted in its current form. We‚Äôve had failures and disappointments in the development of HASS research infrastructure in the past. The HASS RDC program gives us a chance to start afresh, and the focus on integration, data-sharing, and reuse give hope that we can build something that will continue to grow and develop, and not wither through lack of engagement and support. So should the NLA be getting $2 million to add a new component to Trove that is not integrated with other HASS RDC projects, and substantially duplicates tools available elsewhere? No, I don‚Äôt think so. They need to go back to the drawing board, undertake some real consultation, and build collaborations, not products.</p>\n",
				"content_text": "Late last year the Federal Government [announced](https://ministers.dese.gov.au/tehan/improving-hass-and-indigenous-research-infrastructure) it was making an $8.9 million investment in HASS and Indigenous research infrastructure. This program is being managed by the ARDC and will lead to the development of a [HASS Research Data Commons](https://ardc.edu.au/collaborations/strategic-activities/hass-and-indigenous-research-data-commons/). According to the ARDC, a research data commons:\n\n> brings together people, skills, data, and related resources such as storage, compute, software, and models to enable researchers to conduct world class data-intensive research\n\nSounds awesome! \n\nBased on scoping studies commissioned by the Department of Education, Skills, and Employment (which have not yet been made public), [four activities were selected for initial funding](https://ardc.edu.au/collaborations/strategic-activities/hass-and-indigenous-research-data-commons/recommendations-for-co-investment-in-humanities-arts-and-social-sciences-research-data-commons-program/) under this program. Draft project plans for these four activities have now been [released for public comment](https://ardc.edu.au/collaborations/strategic-activities/hass-and-indigenous-research-data-commons/project-plans/).\n\nOne of these activities aims to develop a ‚ÄôTrove researcher platform for advanced research‚Äô:\n\n> Augmenting existing National Library of Australia resources, this platform will enable a focus on the delivery of researcher portals accessible through Trove, Australia‚Äôs unique public heritage site. The platform will create tools for visualisation, entity recognition, transcription and geocoding across Trove content and other corpora.\n\nYou can [download the draft project plan](https://ardc.edu.au/wp-content/uploads/2021/09/Research_Platform_TROVE.pdf) for the Trove platform. Funding for this activity will be capped at $2,301,185 across 2021-23. In this post I‚Äôll try to pull together some of my own thoughts on this plan.\n\nI suppose I‚Äôd better start with a disclaimer ‚Äì I‚Äôm not a neutral observer in this. I started scraping data from Trove newspapers way back in 2010, building the first versions of tools like QueryPic and the Trove Newspaper Harvester. While I was manager of Trove, from 2013 to 2016, I argued for recognition of Trove as a key part of Australia‚Äôs humanities research infrastructure, and highlighted possible research uses of Trove data available through the API. Since then I‚Äôve worked to bring a range of digital tools, examples, tutorials, and hacks together for researchers in the [GLAM Workbench](https://glam-workbench.net/) ‚Äì a [large number of these](https://updates.timsherratt.org/2021/08/26/glam-workbench-a.html) work with data from Trove.\n\nI strongly believe that Trove should receive ongoing funding through [NCRIS](https://www.dese.gov.au/ncris) as a piece of national research infrastructure. Unfortunately though, the draft project plan does not make a strong case for investment ‚Äì it‚Äôs vague, unimaginative, and makes little attempt to integrate with existing tools and services. I think it scores poorly against the ARDC‚Äôs [evaluation criteria](https://ardc.edu.au/wp-content/uploads/2021/09/Evaluation-Criteria-HASS-RDC-and-Indigenous-Research-Capability-program.pdf), and doesn‚Äôt seem to offer good value for money. As someone who has championed the use of Trove data for research across the last decade, I‚Äôm very disappointed.\n\n## What‚Äôs planned?\nSo what is being proposed? There seems to be three main components:\n\n1. Authenticated ‚Äòproject‚Äô spaces for researchers where datasets relating to a particular research topic can be stored\n2. The ability to create custom datasets from a search in Trove\n3. Tools to visualise stored datasets.\n\nThere‚Äôs no doubt that these are all useful functions for researchers, but many problems arise when we look at how they‚Äôre going to be implemented.\n\n### 1. Authenticated project spaces\nThe draft plan indicates that authentication of users through the [Australian Access Federation](https://aaf.edu.au/) is preferred. Why? Trove already has a system for the creation of user accounts. Using AAF would limit use of the new platform to those attached to universities or research agencies. I don‚Äôt understand what the use of AAF adds to the project, except perhaps to provide an example of integration with existing infrastructure services.\n\nThe plan notes that project spaces could be ‚Äòpublic‚Äô or ‚Äòprivate‚Äô. Presumably a ‚Äòpublic‚Äô space would give access to stored datasets, but what sort of access controls would be available in relation to individual datasets? It‚Äôs also noted (Deliverable 7) that researchers would have ‚Äòan option to ‚Äúpublish‚Äù their research findings for public consumption‚Äò. Does this mean datasets and visualisations would be assigned a DOI (or other persistent identifier) and preserved indefinitely? How might these spaces integrate with existing data repositories?\n\n### 2. Create custom datasets\nThe lack of detail in the plan makes it difficult to assess what‚Äôs being proposed here. But it seems that users would be able to construct a search using the Trove web interface (or a new search interface?) and save the results as a dataset. \n\nWhat data would be searched? It‚Äôs not clear, but in reference to the visualisations it‚Äôs stated that data would come from ‚ÄôTrove‚Äôs existing full text collections (newspapers and gazettes, magazines and newsletters, books)‚Äô. So no web archives, and no metadata from any of Trove‚Äôs aggregated collections (even without full text, collection metadata can create interesting research possibilities, see for example the [Radio National records](https://glam-workbench.net/trove-music/) in the GLAM Workbench).\n\nWhat will be included in each dataset? There‚Äôs few details, but at a minimum you‚Äôd expect something like a CSV containing the metadata of all the matching records, and files containing the full text content of the items. These could potentially be *very* large. There‚Äôs no indication about how storage and processing demands would be managed, but presumably there would be some per user, or per project, limits.\n\nDeliverable 8, ‚ÄòData and visual download‚Äô, states that: \n\n> All query results must be available as downloadable files, this would include CSV, JSON and XML for the query results list.\n\nBut there‚Äôs no mention of the full text content at all. Will it be included in downloadable datasets?\n\nAs well as the record metadata and full text, you‚Äôd want there to be some metadata captured about the dataset itself ‚Äì the search query used, when it was captured, the number of records, etc. To support integration and reuse, it would be good to align this with something like [RO Crate](https://www.researchobject.org/ro-crate/).\n\nHow will searches be constructed? It‚Äôs not clear if this will be integrated with the existing search interface, or be something completely separate; however, the plan does note that ‚Äòlimitations are put onto the dataset like keyword search terms and filters corresponding to the filters currently available in the interface‚Äô. So it seems that the new platform will be using the existing search indexes. It‚Äôs obviously important for the relationship between existing search functions and the new dataset creation tool to be explicit and transparent so that researchers understand what they‚Äôre getting. \n\nIt‚Äôs also worth noting that changes to the search interface last year removed some useful options from the advanced search form. In particular, you can no longer exclude matches in tags or comments. If you‚Äôre a researcher looking for the occurrence of a particular word, you generally don‚Äôt want to include records where that word only appears in a user added tag (I have a story about ‚ÄòWord War I‚Äô that illustrates this!).\n\nThis raises a broader issue. There doesn‚Äôt seem to be any mention in the project plan of work to improve the metadata and indexing in response to research needs. Even just identifying digitised books in the current web interface can be a bit of a challenge, and digitised books and periodicals can be grouped into work records with other versions. We need to recognise that the needs of discovery sometimes compromise specific research uses.\n\nI‚Äôm trying to be constructive in my responses here, but at this point I just have to scream ‚Äì WHAT ABOUT THE [TROVE NEWSPAPER HARVESTER](https://glam-workbench.net/trove-harvester/)? A tool has existed for *ten years* that lets users create a dataset containing metadata and full text from a search in Trove‚Äôs newspapers and gazettes. I‚Äôve spent a lot of time over recent years adding features and making it easier to use. Now you can download not only full text, but also PDFs and images of articles. The latest web app version in the GLAM Workbench runs in the cloud. Just one click to start it up, then all you need to do is paste in your Trove API key and the url of your search. It can‚Äôt get much easier.\n\nThe GLAM Workbench also includes tools to create datasets and download OCRd text from Trove‚Äôs [books](https://glam-workbench.net/trove-books/) and digitised [journals](https://glam-workbench.net/trove-journals/). These are still in notebook form, so are not as easy to use, but I have created pre-harvested datasets of all books and periodicals with OCRd text, and stored them on CloudStor. What‚Äôs missing at the moment is something to harvest a collection of journal articles, but this would not be difficult. As an added bonus, the GLAM Workbench has tools to [create full text datasets](https://glam-workbench.net/web-archives/#harvesting-collections-of-text-from-archived-web-pages) from the Australian Web Archive.\n\nSo what is this project really adding? And why is there no attempt to leverage existing tools and resources?\n\n### 3. Visualise datasets\nAgain, there‚Äôs a fair bit of hand waving in the plan, but it seems that users will be able to select a stored dataset and then choose a form of visualisation. The plan says that:\n\n> An initial pilot would allow users to create line graphs that plot the frequency of a search term over time and maps that display results based on state-level geolocation.\n\nUp to three additional visualisations would be created later based on research feedback. It‚Äôs not clear which researchers will be consulted and when their feedback will be sought.\n\nThe value of these sorts of visualisations is obviously dependent on the quality and consistency of the metadata. There‚Äôs nothing built into this plan that would, for example, allow a researcher to clean or normalise any of the saved data. You have to take what you‚Äôre given. The newspaper metadata is generally consistent, but books and periodicals less so. \n\nIt‚Äôs also important to clarify what‚Äôs meant by ‚Äòthe frequency of a search term over time‚Äô. Does this mean the number of records matching a search term, or the number of times that the search term actually appears in the full text of all matched records? If the latter, then this *would* be a major enrichment of the available data. Though if this data was available it should be pushed through the API and/or made available as a downloadable dataset for integration with other platforms (perhaps along the lines of the Hathi Trust‚Äôs [Extracted Features Dataset](https://analytics.hathitrust.org/datasets)). I suspect, however, that what is actually meant is the number of matching search results.\n\nAgain, the value of any geospatial visualisation depends on what is actually being visualised! The `state` facet in newspapers indicates place of publication, it‚Äôs not clear what the `place` facet in other categories represents. For this sort of visualisation to be useful in a research context, there would need to be some explanation of how these values were created, and any gaps or uncertainties.\n\nTime for another scream of frustration ‚Äî WHAT ABOUT [QUERYPIC](https://glam-workbench.net/trove-newspapers/#querypic)? Another long-standing tool which has already been [cited a number of times](https://updates.timsherratt.org/2021/08/30/some-research-projects.html) in research literature. [QueryPic](https://glam-workbench.net/trove-newspapers/#querypic) visualises searches in Trove‚Äôs newspapers and gazettes over time. You can adjust time scales and intervals, and download the results as images, a CSV file, and an HTML page. The project plan makes a point of claiming that its tools would not require any coding, but neither does QueryPic. Just plug in an API key and a search URL. I even made [some videos](https://www.youtube.com/playlist?list=PLAclcciEeCD2z2BWQ2r3xD_Q8c05HppfP) about it! The GLAM Workbench also includes a number of examples of how you can [visualise places of publication](https://glam-workbench.net/trove-newspapers/#map-trove-newspaper-results-by-state) of newspaper articles.\n\nBut it‚Äôs not just the GLAM Workbench. The [Linguistics Data Commons of Australia](https://ardc.edu.au/wp-content/uploads/2021/09/Language_Commons_Australia.pdf), another activity to be funded as part of the HASS Research Data Commons, will include tools for text analysis and visualisation. The [Time Layered Cultural Map](https://www.tlcmap.org/) is developing tools for geospatial visualisation of Australian collections. Surely the focus should be on connecting and reusing what‚Äôs available. Again I‚Äôm wondering what this project is really adding.\n\n## Portals and platforms\nThe original language describing the funded activity is interesting ‚Äî it is intended to ‚Äòfocus on the delivery of researcher portals accessible through Trove‚Äô. \n\n**_Portals_ (plural) accessible *through* (not in) Trove.**\n\nThe NLA could meet a fair proportion of its stated objectives right now, simply by including links to QueryPic and the Trove Newspaper and Gazette Harvester. Done! There‚Äôs a million dollars saved.\n\nMore seriously, there‚Äôs no reason why the outcome of this activity should be a new interface attached to Trove and managed by the NLA. Indeed, such an approach works against integration, reuse, and data sharing. I believe the basic assumptions of the draft plan are seriously flawed. We need to separate out the strands of what‚Äôs meant by a ‚Äòplatform for advanced research‚Äô, and think more creatively and collaboratively about how we could achieve something useful, flexible, and sustainable. \n\n## Where‚Äôs the API?\nI think the primary role of the NLA in the development of this research platform should be as the data provider. There are numerous ways in which Trove‚Äôs data might be improved and enriched in support of new research uses. These improvements could then be pushed through the API to integrate with a range of tools and resources. Which raises the question ‚Äî where is the API in this plan? \n\nThe only mention of the API comes as an option for a user with ‚Äòhigh technical expertise‚Äô to extend the analysis provided by the built-in visualisations. This is all backwards. The API is the key pipeline for data-sharing and integration and should be at the heart of this plan.\n\nThis program offers an opportunity to make some much-needed improvements to the API. Here‚Äôs a few possibilities:\n\n* Bring the web interface and API back into sync so that researchers can easily transfer queries between the two (Trove‚Äôs interface update introduced new categories, while the API still groups resources by the original zones).\n* Provide public API access to additional data about digitised items. For example, you can get lists of newspaper titles and issues from the API, but there‚Äôs no comparable method to get titles and issues for digitised periodicals. The data‚Äôs there ‚Äì it‚Äôs used to generate lists of issues in the browse interface ‚Äì but it‚Äôs not in the API. There‚Äôs also other resource metadata, such as parent/child relationships, which are embedded in web pages but not exposed in the API.\n* Standardise the delivery of OCRd text for different resource types. \n* Finally add the People & Organisations data to the main RESTful API.\n* Fix the limitations of the web archives CDX API ([documented here](https://nbviewer.jupyter.org/github/GLAM-Workbench/web-archives/blob/master/comparing_cdx_apis.ipynb)).\n* Add a search API for the web archives.\n* And what about a Write API? Integration between components in the HASS RDC would be greatly enhanced if other projects could automatically add structured annotations to existing Trove resources.\n\nI think the HASS RDC would benefit greatly by thinking much more about the role of the Trove API in establishing reusable data flows, and connecting up components.\n\n##  Pathways\nAnyone who‚Äôs been to one of my [GLAM Workbench talks](https://glam-workbench.net/presentations/) will know that I talk a lot about ‚Äòpathways‚Äô. My concern is not just to provide useful tools and examples, but to try and connect them in ways that encourage researchers to develop their skills and confidence. So a researcher with limited digital skills can spin up QueryPic and start making visualisations without any specialised knowledge. But if they want to explore the data and assumptions behind QueryPic, they can view a notebook that walks them through the process of getting data from facets and assembling a time series. If they find something interesting in QueryPic, they can go to the Newspaper Harvester and assemble a dataset that helps them zoom into a particular period. There are places to go.\n\nSimilarly, users can start making use of the GLAM Workbench in the cloud using [Binder](https://glam-workbench.net/using-binder/) ‚Äì one click and it‚Äôs running. But as their research develops they might find Binder a bit limiting, so there are options to spin up the GLAM Workbench using [Reclaim Cloud](https://glam-workbench.net/using-reclaim-cloud/) or [Docker](https://glam-workbench.net/using-docker/). As a researcher‚Äôs skills, needs, and questions change, so does their use of the GLAM Workbench. At least that‚Äôs the plan ‚Äì I‚Äôm very aware that there‚Äôs much, much more to do to build and document these pathways.\n\nThe developments described in the draft plan are focused on providing simple tools for non-technical users. That‚Äôs fair enough, but you have to give those users somewhere to go, some path beyond, or else it just becomes another dead end. Users can download their data or visualisation, but then what? \n\nOf course you don‚Äôt point a non-coder to API documentation and say ‚Äòthere you go‚Äô. But coders can use the API to build and share a range of tools that introduce people to the possibilities of data, and scaffold their learning. Why should there be just one interface? It‚Äôs not too difficult to imagine a range of introductory visualisation tools aimed at different humanities disciplines. Instead of focusing inward on a single Trove Viz Lite tool, why not look outwards at ways of embedding Trove data within a range of research training contexts?\n\n## Integration\nA number of the HASS RDC Evaluation Criteria focus on issues of integration, collaboration, and reuse of existing resources. For example:\n\n> * Project plans should display robust proposal planning including the maximisation of the use or re-use of existing research infrastructure, platforms, tools, services, data storage and compute.\n* Project plans should display integrated infrastructure layers with other HASS RDC activities, in particular by linking together elements such as data storage, tools, authentication, licensing, networks, cloud and high-performance computing, and access to data resources for reuse.\n* Project plans must be robust and contribute to the HASS RDC as a coherent whole that capitalises on existing data collections, adheres to the F.A.I.R. principles, develops collaborative tools, utilises shared underlying infrastructure and has appropriate governance planning.\n\n\nThere‚Äôs little evidence of this sort of thinking in the draft project plan. I‚Äôve mentioned a few obvious opportunities for integration above, but there are many more. Overall, I think the proposed ‚Äòplatform for advanced research‚Äô needs to be designed as a series of interconnected components, and not be seen as the product of a single institution.\n\nWe could imagine, for example, a system where the NLA focused on the delivery of research-ready data via the Trove API. A layer of data filtering, cleaning, and packaging tools could be built on top of the API to help users assemble actionable datasets. The packaging processes could use standards such as RO-Crate to prepare datasets for ingest into data repositories. Existing storage services, such as CloudStor, could be used for saving and sharing working datasets. Another layer of visualisation and analysis tools could either process these datasets, or integrate directly with the API. These tools could be spread across different projects including LDaCA, TLCMap, and the GLAM Workbench ‚Äî using standards such as Jupyter to encourage sharing and reuse of individual components, and running on a variety of cloud-hosted platforms. Instead of just adding another component to Trove, we‚Äôd be building a collaborative network of tool builders and data wranglers ‚Äî developing capacities across the research sector, and spreading the burden of maintenance.\n\n## Sustainability\nThe draft project plan includes some pretty worrying comments about long-term support for the new platform. Work Package 5 notes:\n\n> The developed product will require support post release which can be guaranteed for a period not exceeding the contracted period for this project\n\nAnd:\n\n> ARDC will be responsible for providing ongoing financial support for this phase. It has not been included in the proposal.\n\nSo once the project is over, the NLA will not support the new platform unless the ARDC provides ongoing funding. What researcher would want to ‚Äòpublish‚Äô their data on a platform that could disappear at any time? We all know that sustainability is hard, but you would think that the NLA could at least offer to work collaboratively with the research sector to develop a plan for sustainability, instead of just asking for more money. Why would anyone invest so much for so little?\n\n## Leadership and community\nThe development of collaborations and communities also figure prominently in the HASS RDC Evaluation Criteria. For example:\n\n> * Project plans should clearly demonstrate that they enable collaboration and build communities across geographically dispersed research groups through facilitated sharing of high-quality data, particularly for computational analysis; the development of new platforms for collaboration and sharing; and, the encouragement of innovative methodologies through the use of analytic tools.\n* Project plans must include a demonstrated commitment to ongoing community development to ensure the sustainability of the development is vital. The deliverables will act as ongoing national research infrastructure. They must be broadly usable by more than just the project partners and serve as input to a wide range of research.\n* Project plans, and project leads in particular, should demonstrate the research leadership that will foster and encourage the uptake and use of the HASS RDC.\n\n\nOnce again the draft project plan falls short. There are no project partners listed. Instead the plan refers broadly to all of Trove‚Äôs content partners, none of whom have direct involvement in this project. Indeed, as noted above, data aggregated from project parters is excluded from the new platform.\n\nThere are no new governance arrangements proposed for this project. Instead the plan refers to the Trove Strategic Advisory Committee which includes representatives from partner organisations. But there are no researcher representatives on this committee.\n\nThe only consultation with the research sector undertaken in the ‚ÄòConsultation Phase‚Äô of the project is that undertaken by the ARDC itself. Does that mean this current process whereby the ARDC is soliciting feedback on the project plans? Whoa, meta‚Ä¶\n\nThe plan notes that during the testing phase described in Work Package 3, ‚ÄòHASS community members would gain access to a beta version of the product for comment‚Äô. However, later it is stated that access would be provided to ‚Äôa subset of researchers‚Äô, and that only system bugs and ‚Äòhigh priority improvements‚Äô would be acted upon. \n\nGenerally speaking, it seems that the NLA is seeking as little consultation as possible. It‚Äôs not exploring options for collaboration. It‚Äôs not engaging with the research community about these developments. That doesn‚Äôt seem like an effective way to build communities. Nor does it demonstrate leadership.\n\n## Summing up\nThis project plan can‚Äôt be accepted in its current form. We‚Äôve had failures and disappointments in the development of HASS research infrastructure in the past. The HASS RDC program gives us a chance to start afresh, and the focus on integration, data-sharing, and reuse give hope that we can build something that will continue to grow and develop, and not wither through lack of engagement and support. So should the NLA be getting $2 million to add a new component to Trove that is not integrated with other HASS RDC projects, and substantially duplicates tools available elsewhere? No, I don‚Äôt think so. They need to go back to the drawing board, undertake some real consultation, and build collaborations, not products.\n\n\n",
				"date_published": "2021-09-10T11:12:00+11:00",
				"url": "https://updates.timsherratt.org/2021/09/10/some-thoughts-on.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/08/30/some-research-projects.html",
				"title": "Some research projects that have used QueryPic ",
				"content_html": "<p>A Twitter thread about some of the research uses of QueryPic&hellip;</p>\n\n<blockquote class=\"twitter-tweet\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">QueryPic, my tool for visualising searches in <a href=\"https://twitter.com/TroveAustralia?ref_src=twsrc%5Etfw\">@TroveAustralia</a>‚Äôs digitised newspapers, has been around in different forms for more than 10 years. The latest version is part of the <a href=\"https://twitter.com/hashtag/GLAMWorkbench?src=hash&amp;ref_src=twsrc%5Etfw\">#GLAMWorkbench</a>: <a href=\"https://t.co/qnY5tVDwgY\">https://t.co/qnY5tVDwgY</a>  <a href=\"https://twitter.com/hashtag/researchinfrastructure?src=hash&amp;ref_src=twsrc%5Etfw\">#researchinfrastructure</a> <a href=\"https://t.co/QyHWJwGV3u\">pic.twitter.com/QyHWJwGV3u</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431841378720370691?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">I thought I‚Äôd highlight some of the research publications that have made use of QueryPic over the years, so, in no particular order...</p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431841710477242378?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\n\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">There‚Äôs <a href=\"https://twitter.com/Airminded?ref_src=twsrc%5Etfw\">@Airminded</a>‚Äôs article in <a href=\"https://twitter.com/HistAustJournal?ref_src=twsrc%5Etfw\">@HistAustJournal</a> ‚Äì Brett Holman (2013) &#39;Dreaming War: Airmindedness and the Australian Mystery Aeroplane Scare of 1918&#39;, History Australia, 10:2, 180-201, DOI: <a href=\"https://t.co/2wgiLueHGL\">https://t.co/2wgiLueHGL</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431842737041510403?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\n\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">A book! Simon Sleight, Young People and the Shaping of Public Space in Melbourne, 1870‚Äì1914, Ashgate Publishing, Ltd., 2013. <a href=\"https://t.co/CPgGMrYYYq\">https://t.co/CPgGMrYYYq</a> <a href=\"https://t.co/XryAF0hJ5K\">pic.twitter.com/XryAF0hJ5K</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431843658664275973?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\n\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">Yorick Smaal (2013) Keeping it in the family: prosecuting incest in colonial Queensland, Journal of Australian Studies, 37:3, 316-332, DOI: <a href=\"https://t.co/n5tQlER9Vo\">https://t.co/n5tQlER9Vo</a> <a href=\"https://t.co/tKzpAosu1i\">pic.twitter.com/tKzpAosu1i</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431844330474409988?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\n\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">In <a href=\"https://twitter.com/AHSjournal?ref_src=twsrc%5Etfw\">@AHSjournal</a> there‚Äôs ‚Äì Murray G. Phillips &amp; Gary Osmond (2015) Australia&#39;s Women Surfers: History, Methodology and the Digital Humanities, Australian Historical Studies, 46:2, 285-303, DOI: <a href=\"https://t.co/Gxs1Ru6Ojt\">https://t.co/Gxs1Ru6Ojt</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431844996370419712?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\n\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">Gary Osmond (2015) ‚ÄòPink Tea and Sissy Boys‚Äô: Digitized Fragments of Male Homosexuality, Non-Heteronormativity and Homophobia in the Australian Sporting Press, 1845‚Äì1954, The International Journal of the History of Sport, 32:13, 1578-1592, DOI: <a href=\"https://t.co/C6FndD7C4E\">https://t.co/C6FndD7C4E</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431845470419050499?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\n\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">Murray G. Phillips, Gary Osmond &amp; Stephen Townsend (2015) A Bird‚Äôs-Eye View of the Past: Digital History, Distant Reading and Sport History, The International Journal of the History of Sport, 32:15, 1725-1740, DOI: <a href=\"https://t.co/4rB2hkmmDM\">https://t.co/4rB2hkmmDM</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431845844060282880?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\n\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">Sarah Ailwood and Maree Sainsbury, ‚ÄòCopyright Law, Readers and Authors in Colonial Australia‚Äô, Journal of the Association for the Study of Australian Literature, vol. 14, no. 3, 2014. <a href=\"https://t.co/XWqx8XJGLQ\">https://t.co/XWqx8XJGLQ</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431846330142314497?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\n\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">Sarah Ailwood and Maree Sainsbury, ‚ÄòThe Imperial Effect: Literary Copyright Law in Colonial Australia‚Äô, Law, Culture and the Humanities, vol. 12, no. 3, 1 October 2016, pp. 716‚Äì740. <a href=\"https://t.co/s6HrBZmQ6N\">https://t.co/s6HrBZmQ6N</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431846863200677888?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\n\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">A book chapter by <a href=\"https://twitter.com/JVLamond?ref_src=twsrc%5Etfw\">@JVLamond</a> ‚Äì Lamond, J, 2016, &#39;Zones of Connection: Common Reading in a Regional Australian Library&#39;, in Print Culture Histories Beyond the Metropolis, University of Toronto Press, Toronto, pp. 355-374. <a href=\"https://t.co/o3oAmreYne\">https://t.co/o3oAmreYne</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431848340660965378?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\n\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">Not just history ‚Äì Scifleet, P., Henninger, M. &amp; Albright, K.H. (2013). When social media are your source. Information Research, 18(3) paper C41. <a href=\"https://t.co/qOYbZ3TMTf\">https://t.co/qOYbZ3TMTf</a> <a href=\"https://t.co/GDP2TmeUzp\">pic.twitter.com/GDP2TmeUzp</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431849020478033926?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\n\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">There‚Äôs also a number of references to QueryPic as a tool in the DH &amp; library literature, that I won‚Äôt list.<br><br>There‚Äôs probably more ‚Äì citation of tools like QueryPic can be a bit hit and miss.</p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431850352396029955?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\n\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">The latest version of QueryPic is designed to be both easy-to-use and flexible ‚Äì click a link to start it up, paste in your <a href=\"https://twitter.com/TroveAustralia?ref_src=twsrc%5Etfw\">@TroveAustralia</a> API key, and a search url from Trove‚Ä¶ and bingo!<br><br>For a quick intro, see this video: <a href=\"https://t.co/Hh1oDIOh9a\">https://t.co/Hh1oDIOh9a</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431851213847347203?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">But even though it‚Äôs easy to get started, QueryPic can do interesting things like compare queries. You can also adjust facets, date ranges, and time scales.<br><br>This video shows you how to create more complex queries: <a href=\"https://t.co/0CoJhO7vaJ\">https://t.co/0CoJhO7vaJ</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431851859065507844?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\n\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">As I often say, not all <a href=\"https://twitter.com/hashtag/researchinfrastructure?src=hash&amp;ref_src=twsrc%5Etfw\">#researchinfrastructure</a> has to be big. A simple tool like this can help researchers see their topics in new ways.<br><br>And from this starting point, there‚Äôs all sorts of pathways to follow in the <a href=\"https://twitter.com/hashtag/GLAMWorkbench?src=hash&amp;ref_src=twsrc%5Etfw\">#GLAMWorkbench</a> <a href=\"https://t.co/AC2tipN8eY\">https://t.co/AC2tipN8eY</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431853486564536320?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\n",
				"content_text": "A Twitter thread about some of the research uses of QueryPic...\r\n\r\n<blockquote class=\"twitter-tweet\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">QueryPic, my tool for visualising searches in <a href=\"https://twitter.com/TroveAustralia?ref_src=twsrc%5Etfw\">@TroveAustralia</a>‚Äôs digitised newspapers, has been around in different forms for more than 10 years. The latest version is part of the <a href=\"https://twitter.com/hashtag/GLAMWorkbench?src=hash&amp;ref_src=twsrc%5Etfw\">#GLAMWorkbench</a>: <a href=\"https://t.co/qnY5tVDwgY\">https://t.co/qnY5tVDwgY</a>  <a href=\"https://twitter.com/hashtag/researchinfrastructure?src=hash&amp;ref_src=twsrc%5Etfw\">#researchinfrastructure</a> <a href=\"https://t.co/QyHWJwGV3u\">pic.twitter.com/QyHWJwGV3u</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431841378720370691?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\r\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\r\n\r\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">I thought I‚Äôd highlight some of the research publications that have made use of QueryPic over the years, so, in no particular order...</p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431841710477242378?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\r\n\r\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">There‚Äôs <a href=\"https://twitter.com/Airminded?ref_src=twsrc%5Etfw\">@Airminded</a>‚Äôs article in <a href=\"https://twitter.com/HistAustJournal?ref_src=twsrc%5Etfw\">@HistAustJournal</a> ‚Äì Brett Holman (2013) &#39;Dreaming War: Airmindedness and the Australian Mystery Aeroplane Scare of 1918&#39;, History Australia, 10:2, 180-201, DOI: <a href=\"https://t.co/2wgiLueHGL\">https://t.co/2wgiLueHGL</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431842737041510403?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\r\n\r\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">A book! Simon Sleight, Young People and the Shaping of Public Space in Melbourne, 1870‚Äì1914, Ashgate Publishing, Ltd., 2013. <a href=\"https://t.co/CPgGMrYYYq\">https://t.co/CPgGMrYYYq</a> <a href=\"https://t.co/XryAF0hJ5K\">pic.twitter.com/XryAF0hJ5K</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431843658664275973?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\r\n\r\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">Yorick Smaal (2013) Keeping it in the family: prosecuting incest in colonial Queensland, Journal of Australian Studies, 37:3, 316-332, DOI: <a href=\"https://t.co/n5tQlER9Vo\">https://t.co/n5tQlER9Vo</a> <a href=\"https://t.co/tKzpAosu1i\">pic.twitter.com/tKzpAosu1i</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431844330474409988?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\r\n\r\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">In <a href=\"https://twitter.com/AHSjournal?ref_src=twsrc%5Etfw\">@AHSjournal</a> there‚Äôs ‚Äì Murray G. Phillips &amp; Gary Osmond (2015) Australia&#39;s Women Surfers: History, Methodology and the Digital Humanities, Australian Historical Studies, 46:2, 285-303, DOI: <a href=\"https://t.co/Gxs1Ru6Ojt\">https://t.co/Gxs1Ru6Ojt</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431844996370419712?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\r\n\r\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">Gary Osmond (2015) ‚ÄòPink Tea and Sissy Boys‚Äô: Digitized Fragments of Male Homosexuality, Non-Heteronormativity and Homophobia in the Australian Sporting Press, 1845‚Äì1954, The International Journal of the History of Sport, 32:13, 1578-1592, DOI: <a href=\"https://t.co/C6FndD7C4E\">https://t.co/C6FndD7C4E</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431845470419050499?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\r\n\r\n\r\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">Murray G. Phillips, Gary Osmond &amp; Stephen Townsend (2015) A Bird‚Äôs-Eye View of the Past: Digital History, Distant Reading and Sport History, The International Journal of the History of Sport, 32:15, 1725-1740, DOI: <a href=\"https://t.co/4rB2hkmmDM\">https://t.co/4rB2hkmmDM</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431845844060282880?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\r\n\r\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">Sarah Ailwood and Maree Sainsbury, ‚ÄòCopyright Law, Readers and Authors in Colonial Australia‚Äô, Journal of the Association for the Study of Australian Literature, vol. 14, no. 3, 2014. <a href=\"https://t.co/XWqx8XJGLQ\">https://t.co/XWqx8XJGLQ</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431846330142314497?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\r\n\r\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">Sarah Ailwood and Maree Sainsbury, ‚ÄòThe Imperial Effect: Literary Copyright Law in Colonial Australia‚Äô, Law, Culture and the Humanities, vol. 12, no. 3, 1 October 2016, pp. 716‚Äì740. <a href=\"https://t.co/s6HrBZmQ6N\">https://t.co/s6HrBZmQ6N</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431846863200677888?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\r\n\r\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">A book chapter by <a href=\"https://twitter.com/JVLamond?ref_src=twsrc%5Etfw\">@JVLamond</a> ‚Äì Lamond, J, 2016, &#39;Zones of Connection: Common Reading in a Regional Australian Library&#39;, in Print Culture Histories Beyond the Metropolis, University of Toronto Press, Toronto, pp. 355-374. <a href=\"https://t.co/o3oAmreYne\">https://t.co/o3oAmreYne</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431848340660965378?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\r\n\r\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">Not just history ‚Äì Scifleet, P., Henninger, M. &amp; Albright, K.H. (2013). When social media are your source. Information Research, 18(3) paper C41. <a href=\"https://t.co/qOYbZ3TMTf\">https://t.co/qOYbZ3TMTf</a> <a href=\"https://t.co/GDP2TmeUzp\">pic.twitter.com/GDP2TmeUzp</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431849020478033926?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\r\n\r\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">There‚Äôs also a number of references to QueryPic as a tool in the DH &amp; library literature, that I won‚Äôt list.<br><br>There‚Äôs probably more ‚Äì citation of tools like QueryPic can be a bit hit and miss.</p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431850352396029955?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\r\n\r\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">The latest version of QueryPic is designed to be both easy-to-use and flexible ‚Äì click a link to start it up, paste in your <a href=\"https://twitter.com/TroveAustralia?ref_src=twsrc%5Etfw\">@TroveAustralia</a> API key, and a search url from Trove‚Ä¶ and bingo!<br><br>For a quick intro, see this video: <a href=\"https://t.co/Hh1oDIOh9a\">https://t.co/Hh1oDIOh9a</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431851213847347203?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\r\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\r\n\r\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">But even though it‚Äôs easy to get started, QueryPic can do interesting things like compare queries. You can also adjust facets, date ranges, and time scales.<br><br>This video shows you how to create more complex queries: <a href=\"https://t.co/0CoJhO7vaJ\">https://t.co/0CoJhO7vaJ</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431851859065507844?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\r\n\r\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-cards=\"hidden\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">As I often say, not all <a href=\"https://twitter.com/hashtag/researchinfrastructure?src=hash&amp;ref_src=twsrc%5Etfw\">#researchinfrastructure</a> has to be big. A simple tool like this can help researchers see their topics in new ways.<br><br>And from this starting point, there‚Äôs all sorts of pathways to follow in the <a href=\"https://twitter.com/hashtag/GLAMWorkbench?src=hash&amp;ref_src=twsrc%5Etfw\">#GLAMWorkbench</a> <a href=\"https://t.co/AC2tipN8eY\">https://t.co/AC2tipN8eY</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1431853486564536320?ref_src=twsrc%5Etfw\">August 29, 2021</a></blockquote>\n",
				"date_published": "2021-08-30T12:48:11+11:00",
				"url": "https://updates.timsherratt.org/2021/08/30/some-research-projects.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/08/30/government-publications-in.html",
				"title": "Government publications in Trove",
				"content_html": "<p>Over the last few weeks I‚Äôve been updating my harvests of OCRd text from digitised <a href=\"https://updates.timsherratt.org/2021/08/16/explore-troves-digitised.html\">books</a> and <a href=\"https://updates.timsherratt.org/2021/08/06/updated-lots-and.html\">periodicals</a> in Trove. As part of the harvesting process, I‚Äôve created lists of both that are available in digital form ‚Äì this includes digitised works, as well as those that are born-digital (such as PDFs or epubs). I‚Äôve published the full lists of <a href=\"https://trove-digital-books.glitch.me/data/trove-digital-books\">books</a> and <a href=\"https://trove-digital-periodicals.glitch.me/data/trove-digital-journals\">periodicals</a> as searchable databases to make them easy to explore.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/51c3edce9a.png\" alt=\"\" title=\"Screenshot of database of Trove's government publications.\" /></p>\n\n<p>One thing that you might notice is that works with the format ‚ÄòGovernment publication‚Äô pop up in both lists ‚Äì sometimes it‚Äôs not clear whether something is a ‚Äòbook‚Äô or ‚Äòperiodical‚Äô. To make it easier to find these items, no matter what their format, I‚Äôve combined data from my two harvests and created a <a href=\"https://trove-government-publications.glitch.me/data/trove-government-publications\">searchable dataset of government publications</a>. It includes links to download OCRd text from CloudStor if available.</p>\n\n<p>All three databases make use of Datasette, which I‚Äôve also used for the <a href=\"https://updates.timsherratt.org/2021/08/23/a-family-history.html\">GLAM Name Index Search</a>. One of the cool things about <a href=\"https://datasette.io/\">Datasette</a> is that it provides it‚Äôs own API, so if you find some interesting in any of these databases, you can easily download the machine-readable data for further analysis. #dhhacks</p>\n",
				"content_text": "Over the last few weeks I‚Äôve been updating my harvests of OCRd text from digitised [books](https://updates.timsherratt.org/2021/08/16/explore-troves-digitised.html) and [periodicals](https://updates.timsherratt.org/2021/08/06/updated-lots-and.html) in Trove. As part of the harvesting process, I‚Äôve created lists of both that are available in digital form ‚Äì this includes digitised works, as well as those that are born-digital (such as PDFs or epubs). I‚Äôve published the full lists of [books](https://trove-digital-books.glitch.me/data/trove-digital-books) and [periodicals](https://trove-digital-periodicals.glitch.me/data/trove-digital-journals) as searchable databases to make them easy to explore.\n\n![](https://updates.timsherratt.org/uploads/2021/51c3edce9a.png \"Screenshot of database of Trove's government publications.\")\n\nOne thing that you might notice is that works with the format ‚ÄòGovernment publication‚Äô pop up in both lists ‚Äì sometimes it‚Äôs not clear whether something is a ‚Äòbook‚Äô or ‚Äòperiodical‚Äô. To make it easier to find these items, no matter what their format, I‚Äôve combined data from my two harvests and created a [searchable dataset of government publications](https://trove-government-publications.glitch.me/data/trove-government-publications). It includes links to download OCRd text from CloudStor if available.\n\nAll three databases make use of Datasette, which I‚Äôve also used for the [GLAM Name Index Search](https://updates.timsherratt.org/2021/08/23/a-family-history.html). One of the cool things about [Datasette](https://datasette.io/) is that it provides it‚Äôs own API, so if you find some interesting in any of these databases, you can easily download the machine-readable data for further analysis. #dhhacks\n\n",
				"date_published": "2021-08-30T12:21:46+11:00",
				"url": "https://updates.timsherratt.org/2021/08/30/government-publications-in.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/08/26/glam-workbench-a.html",
				"title": "GLAM Workbench ‚Äì a platform for digital HASS research",
				"content_html": "\n\n<p>We‚Äôre in the midst of planning for the <a href=\"https://ardc.edu.au/collaborations/strategic-activities/hass-and-indigenous-research-data-commons/\">HASS Research Data Commons</a>, which will deliver some much-needed investment in digital research infrastructure for the humanities and social sciences. Amongst the funded programs are tools for text analysis as part of the Linguistics Data Commons, and a platform for more advanced research using Trove. I‚Äôm hoping that this will be an opportunity to take stock of existing tools and resources, and build flexible pathways for researchers that enable them to collect, move, analyse, preserve, and share data across different platforms and services.</p>\n\n<p>To this end, I thought it might be useful to try and summarise what the <a href=\"https://glam-workbench.net/\">GLAM Workbench</a> offers, particularly for <a href=\"https://trove.nla.gov.au/\">Trove</a> researchers. The GLAM Workbench doesn‚Äôt really have an institutional home, and is mostly unfunded ‚Äì it‚Äôs my passion project. That means that it‚Äôs easy to overlook, particularly when the big grants are being doled out. But I think it has a lot to offer and I‚Äôm looking forward to exploring ways it can connect with these new initiatives.</p>\n\n<h2 id=\"getting-and-moving-data\">Getting and moving data</h2>\n\n<p>There‚Äôs lots of fabulous data in Trove and other GLAM collections. In fact, there‚Äôs so much data that it can be difficult for researchers to find and collect what‚Äôs relevant to their interests. There are many tools in the GLAM Workbench to help researchers assemble their own datasets. For example:</p>\n\n<ul>\n<li><strong><a href=\"https://glam-workbench.net/trove-harvester/\">Get newspaper articles in bulk with the Trove Newspaper and Gazette Harvester</a></strong> ‚Äì This has been around in some form for more than ten years (it pre-dates the Trove API!). Give it the url of a search in Trove‚Äôs newspapers and gazettes and the harvester will save all the metadata in a CSV file, and optionally download the complete articles as OCRd text, images, or PDFs. The amount of data you harvest is really only limited by your patience and disk space. I‚Äôve harvested more than a million articles in the past. The GLAM Workbench includes a web app version of the harvester that runs live in the cloud ‚Äì just paste in your Trove API key and the search url, and click the button.</li>\n<li><strong>Get Trove newspaper pages as images</strong> ‚Äì If you need a nice, high-resolution version of a newspaper page you can <a href=\"https://glam-workbench.net/trove-newspapers/#download-a-page-image\">use this web app</a>. If you want to harvest every front page (or some other particular page) here‚Äôs an example that <a href=\"https://glam-workbench.net/trove-newspapers/#harvest-australian-womens-weekly-covers-or-the-front-pages-of-any-newspaper\">gets all the covers of the <em>Australian Women‚Äôs Weekly</em></a>. A pre-harvested <a href=\"https://glam-workbench.net/trove-newspapers/#australian-womens-weekly-front-covers-1933-to-1982\">collection of the AWW covers</a> is included as a bonus extra.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-newspapers/#save-a-trove-newspaper-article-as-an-image\">Get Trove newspaper articles as images</a></strong> ‚Äì The Trove web interface makes it difficult to download complete images of articles, but this tool will do the job. There‚Äôs a handy web app to grab individual images, but the code from this tool is reused in other places such as the Trove Newspaper Harvester and the Omeka uploader, and could be built-in to your own research workflows.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-newspapers/#upload-trove-newspaper-articles-to-omeka-s\">Upload Trove newspaper articles to Omeka</a></strong> ‚Äì Whether you‚Äôre creating on online exhibition or building a research database, Omeka can be very useful. This notebook connects Trove‚Äôs newspapers to Omeka for easy upload. Your selected articles can come from a search query, a Trove list, a Zotero library, or just a list of article ids. Metadata records are created in Omeka for each article and newspaper, and an image of each article is attached.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-journals/#get-ocrd-text-from-a-digitised-journal-in-trove\">Get OCRd text from digitised periodicals in Trove</a></strong> ‚Äì They‚Äôre often overshadowed by the newspapers, but there‚Äôs now lots of digitised journals, magazines, and parliamentary papers in Trove. You can get article-level data from the API, but not issue data. This notebook enables researchers to get metadata and OCRd text from every available issue of a periodical. To make researchers‚Äô lives even easier, I regularly harvest <a href=\"https://glam-workbench.net/trove-journals/#ocrd-text-from-trove-digitised-journals\"><strong>all</strong> the available OCRd text</a> from digitised periodicals in Trove. The latest harvest downloaded 51,928 issues from 1,163 periodicals ‚Äì that‚Äôs about 10gb of text. You can <a href=\"https://github.com/GLAM-Workbench/trove-journals/blob/master/digital-journals-with-text.md\">browse the list of periodicals</a> with OCRd text, or <a href=\"https://trove-digital-periodicals.glitch.me/data/trove-digital-journals\">search this database</a>. All the OCRd text is stored in a public repository on CloudStor.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-journals/#get-covers-or-any-other-pages-from-a-digitised-journal-in-trove\">Get page images from digitised periodicals in Trove</a></strong> ‚Äì There‚Äôs more than text in digitised periodicals, and you might want to download images of pages for visual analysis. This notebook shows you how to get cover images, but could be easily modified to get another page, or a PDF. I used a modified version of this to create <a href=\"https://glam-workbench.net/trove-journals/#editorial-cartoons-from-the-bulletin-1886-to-1952\">a collection of 3,471 full page editorial cartoons</a> from <em>The Bulletin</em>, 1886 to 1952 ‚Äì all available to download from CloudStor.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-books/#harvesting-the-text-of-digitised-books-and-ephemera\">Get OCRd text from digitised books in Trove</a></strong> ‚Äì Yep, there‚Äôs digitised books as well as newspapers and periodicals. You can download OCRd text from an individual book using the Trove web interface, but how do you make a collection of books without all that pointing and clicking? This notebook downloads all the available OCRd text from digitised books in Trove. The latest harvest includes <a href=\"https://glam-workbench.net/trove-books/#ocrd-text-from-trove-books-and-ephemera\">text from 26,762 works</a>. You can explore the results <a href=\"https://trove-digital-books.glitch.me/data/trove-digital-books\">using this database</a>.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-journals/#harvest-parliament-press-releases-from-trove\">Harvest parliamentary press releases from Trove</a></strong> ‚Äì Trove includes more than 380,000 press releases, speeches, and interview transcripts issued by Australian federal politicians and saved by the Parliamentary Library. This notebook shows you how to harvest both metadata and fulltext from a search of the parliamentary press releases. For example, here‚Äôs a collection of <a href=\"https://glam-workbench.net/trove-journals/#politicians-talking-about-immigrants-and-refugees\">politicians talking about ‚Äòrefugees‚Äô</a>, and another <a href=\"https://glam-workbench.net/trove-journals/#politicians-talking-about-covid\">relating to COVID-19</a>.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-music/#harvest-abc-radio-national-records-from-trove\">Harvest details of Radio National programs from Trove</a></strong> ‚Äì Trove creates records for programs broadcast on ABC Radio National, for the major current affairs programs these records at at segment level. Even though they don‚Äôt provide full transcripts, this data provide a rich, fine-grained record of Australia‚Äôs recent political, social, and economic history. This notebook shows you how to download the Radio National data. If you just want to dive straight in, there‚Äôs also a <a href=\"https://glam-workbench.net/trove-music/#abc-radio-national-programs\">pre-harvested collection</a> containing more than 400,000 records, with separate downloads for some of the main programs.</li>\n<li><strong><a href=\"https://glam-workbench.net/web-archives/#find-all-the-archived-versions-of-a-web-page\">Find all the versions of an archived web page in Trove</a></strong> ‚Äì Many of the tools in the <a href=\"https://glam-workbench.net/web-archives/\">Web Archives section</a> of the GLAM Workbench will work with the Australian Web Archive, which is part of Trove. This notebook shows you how to get data about the number of times a web page has been archived over time.</li>\n<li><strong><a href=\"https://glam-workbench.net/web-archives/#harvesting-collections-of-text-from-archived-web-pages\">Harvesting collections of text from archived web pages in Trove</a></strong> ‚Äì If you want to explore how the content of a web page changes over time, you can use this notebook to capture the text content of every archived version of a web page.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-lists/#convert-a-trove-list-into-a-csv-file\">Convert a Trove list into a CSV file</a></strong> ‚Äì While Trove provides a data download option for lists, it leaves out a lot of useful data. This notebook downloads full details of newspaper articles and other works in a list and saves them as CSV files. Like the Trove Newspaper Harvester, it lets you download OCRd text and images from newspaper articles.</li>\n<li><strong>Collecting information about Trove user activity</strong> ‚Äì It‚Äôs not just the content of Trove that provides interesting research data, it‚Äôs also the way people engage with it. Using the Trove API it‚Äôs possible to harvest details of <a href=\"https://glam-workbench.net/trove-lists/\">all user created lists and tags</a>. And yes, there‚Äôs pre-harvested collections of <a href=\"https://glam-workbench.net/trove-lists/#trove-lists-metadata\">lists</a> and <a href=\"https://glam-workbench.net/trove-lists/#trove-public-tags\">tags</a> for the impatient.</li>\n</ul>\n\n<p>While I‚Äôm focusing here on Trove, there‚Äôs also tools to create datasets from the <a href=\"https://glam-workbench.net/recordsearch/\">National Archives of Australia</a>, <a href=\"https://glam-workbench.net/digitalnz/\">Digital NZ and Papers Past</a>, the <a href=\"https://glam-workbench.net/nma/\">National Museum of Australia</a> and more. And there‚Äôs a <a href=\"https://glam-workbench.net/glam-data-list/\">big list of readily downloadable datasets</a> from Australian GLAM organisations.</p>\n\n<h2 id=\"visualisation-and-analysis\">Visualisation and analysis</h2>\n\n<p>Many of the notebooks listed above include examples that demonstrate ways of exploring and analysing your harvested data. There are also a number of companion notebooks that examine some possibilities in more detail, for example:</p>\n\n<ul>\n<li><a href=\"https://glam-workbench.net/trove-harvester/#exploring-your-troveharvester-data\">Explore your Trove newspaper harvests</a></li>\n<li><a href=\"https://glam-workbench.net/trove-harvester/#display-the-results-of-a-harvest-as-a-searchable-database-using-datasette\">Load your Trove newspaper harvest in Datasette</a></li>\n<li><a href=\"https://glam-workbench.net/trove-music/#exploring-abc-radio-national-metadata\">Exploring ABC Radio National metadata</a></li>\n<li><a href=\"https://glam-workbench.net/trove-lists/#analyse-public-tags-added-to-trove\">Analyse public tags added to Trove</a></li>\n</ul>\n\n<p>But there are also many other notebooks that demonstrate methods for analysing Trove‚Äôs content, for example:</p>\n\n<ul>\n<li><strong><a href=\"https://glam-workbench.net/trove-newspapers/#querypic\">QueryPic</a></strong> ‚Äì Another tool that‚Äôs been around in different forms for a decade, QueryPic visualises searches in Trove‚Äôs newspapers. The latest web app couldn‚Äôt be simpler, just paste in your API key and a search url and create charts showing the number of matching articles over time. You can combine queries, change time scales, and download the data and visualisations.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-newspapers/#visualise-trove-newspaper-searches-over-time\">Visualise Trove newspaper searches over time</a></strong> ‚Äì This is like a deconstructed version of QueryPic that walks you through the process of using Trove‚Äôs facets to assemble a dataset of results over time. It provide a lot of detail on the sorts of data available, and the questions we can ask of it.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-newspapers/#visualise-the-total-number-of-newspaper-articles-in-trove-by-year-and-state\">Visualise the total number of newspaper articles in Trove by year and state</a></strong> ‚Äì This notebook uses a modified version of the code above to analyse the construction and context of Trove‚Äôs newspaper corpus itself. What are you actually searching? Meet the WWI effect and the copyright cliff of death! This is a great place to start if you want to get people thinking critically about digital resources are constructed.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-newspapers/#analyse-rates-of-ocr-correction\">Analyse rates of OCR correction</a></strong> ‚Äì Some more meta-analysis of the Trove corpus itself, this time focusing on patterns of OCR correction by Trove users.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-newspapers/#finding-non-english-newspapers-in-trove\">Identifying non-English language newspapers in Trove</a></strong> ‚Äì There are a growing number of non-English language newspapers digitised in Trove. However, if you&rsquo;re only searching using English keywords, you might never know that they&rsquo;re there. This notebook analyses a sample of articles from every newspaper in Trove to identify non-English content.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-newspapers/#beyond-the-copyright-cliff-of-death\">Beyond the copyright cliff of death</a></strong> ‚Äì Most of the newspaper articles on Trove were published before 1955, but there are some from the later period. This notebook helps you find out how many, and which newspapers they were published in.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-newspapers/#map-trove-newspaper-results-by-state\">Map Trove newspaper results by state</a></strong> ‚Äì This notebook uses the Trove <code>state</code> facet to create a choropleth map that visualises the number of search results per state.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-newspapers/#map-trove-newspaper-results-by-place-of-publication\">Map Trove newspaper results by place of publication</a></strong> ‚Äì This notebook uses the Trove <code>title</code> facet to find the number of results per newspaper, then merges the results with a dataset of geolocated newspapers to map where articles were published.</li>\n<li><strong><a href=\"https://glam-workbench.net/web-archives/#compare-two-versions-of-an-archived-web-page\">Compare two versions of an archived web page</a></strong> ‚Äì This notebook demonstrates a number of different ways of comparing versions of archived web pages. Just choose a repository, enter a url, and select two dates to see comparisons based on: page metadata, basic statistics such as file size and number of words, numbers of internal and external links, cosine similarity of text, line by line differences in text or code, and screenshots.</li>\n<li><strong><a href=\"https://glam-workbench.net/web-archives/#display-changes-in-the-text-of-an-archived-web-page-over-time\">Display changes in the text of an archived web page over time</a></strong> ‚Äì This web app gathers all the available versions of a web page and then visualises changes in its content between versions ‚Äì what‚Äôs been added, removed, and changed?</li>\n<li><strong><a href=\"https://glam-workbench.net/web-archives/#using-screenshots-to-visualise-change-in-a-page-over-time\">Use screenshots to visualise change in a page over time</a></strong>‚Äì Create a series of full page screenshots of a web page over time, then assemble them into a time series.</li>\n</ul>\n\n<p>There are also possibilities for using Trove data creatively. For example you can <a href=\"https://glam-workbench.net/trove-newspapers/#create-scissors-and-paste-messages-from-trove-newspaper-articles\">create &lsquo;scissors and paste&rsquo; messages from Trove newspaper articles</a>.</p>\n\n<h2 id=\"documentation-and-examples\">Documentation and examples</h2>\n\n<p>All the Trove notebooks in the GLAM Workbench help document the possibilities and limits of the Trove API. The examples above can be modified and reworked to suit different research interests. Some notebooks also explore particular aspects of the API, for example:</p>\n\n<ul>\n<li><strong><a href=\"https://glam-workbench.net/trove/\">Trove API Introduction</a></strong> ‚Äì Some very basic examples of making requests and understanding results.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-newspapers/#todays-news-yesterday\">Today‚Äôs news yesterday</a></strong> ‚Äì Uses the <code>date</code> index and the <code>firstpageseq</code> parameter to find articles from exactly 100 years ago that were published on the front page. It then selects one of the articles at random and downloads and displays an image of the front page.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-images/#the-use-of-standard-licences-and-rights-statements-in-trove-image-records\">The use of standard licences and rights statements in Trove image records</a></strong> ‚Äì Version 2.1 of the Trove API introduced a new rights index that you can use to limit your search results to records that include one of a list of standard licences and rights statements. We can also use this index to build a picture of which rights statements are currently being used, and by who.</li>\n<li><strong><a href=\"https://glam-workbench.net/trove-random/\">Random items from Trove</a></strong> ‚Äì Changes to the Trove API meant that techniques you could previously use to select resources at random no longer work. This section documents some alternative ways of retrieving random-ish works and newspaper articles from Trove.</li>\n</ul>\n\n<p>And while it‚Äôs not officially part of the GLAM Workbench, I also maintain the <a href=\"https://troveconsole.herokuapp.com/\">Trove API Console</a> which provides lots of examples of the API in action.</p>\n\n<h2 id=\"pathways\">Pathways</h2>\n\n<p>In developing the GLAM Workbench I‚Äôm very aware that people will arrive with different levels of digital skill, confidence, and experience. That‚Äôs why I‚Äôve been putting a lot of thought and effort into ways of providing a range of entry points.</p>\n\n<p>Someone who might not identify as a ‚Äòdigital‚Äô researcher can, with a single click, start up QueryPic and start exploring changes over time in Trove‚Äôs newspapers. This is possible because the GLAM Workbench is configured to <a href=\"https://glam-workbench.net/using-binder/\">make use of Binder</a>, a service that spins up customised computing environments as needed.</p>\n\n<p>Another researcher might start running the Trove Newspaper Harvester using Binder, but find that they want to run bigger and longer harvests. In that case, the GLAM Workbench offers a one-click installation of the Trove Newspaper Harvester on <a href=\"https://glam-workbench.net/using-reclaim-cloud/\">Reclaim Cloud</a>. Unlike Binder, Reclaim Cloud environments are persistent, so you can run the harvester for as long as you want without the worry of interruptions.</p>\n\n<p>Yet another researcher might want to understand how the Trove API works and the sorts of data that it makes available. By exploring the various notebooks they‚Äôll find useful snippets of code they can try out in their own projects.</p>\n\n<p>The GLAM Workbench connects outwards to make use of a range of other services ‚Äì the notebooks run in Binder, Reclaim Cloud, and Docker; the code is all openly licensed and publicly available through GitHub and Zenodo; data is hosted on GitHub, CloudStor, and Zenodo; datasets can be explored using Datasette running on Glitch or Google CloudRun. I‚Äôm hoping that the new investments in HASS research infrastructure will embed a similar philosophy, connecting up existing services rather than starting from scratch.</p>\n\n<h2 id=\"the-future\">The future</h2>\n\n<p>This is just an outline on what the GLAM Workbench currently offers researchers wanting to make use of the data available from Trove. It&rsquo;s all there now, publicly accessible, openly licensed, and ready to use ‚Äì take it, use it, change it, share it. But there&rsquo;s <strong>much more</strong> I&rsquo;d like to do, both in regard to Trove and to encourage use of GLAM data more generally. I&rsquo;m also interested in your ideas for new tools, examples, or data sources ‚Äì what would help your research? You can <a href=\"https://glam-workbench.net/suggest-a-topic/\">add a suggestion</a> in GitHub, or post a comment in the <a href=\"https://ozglam.chat/c/glam-workbench/8\">GLAM Workbench channel</a> of OzGLAM Help.</p>\n\n<p>See the <a href=\"https://glam-workbench.net/getting-started/\">Getting Started section</a> of the GLAM Workbench for more hints and examples. And keep an eye on the <a href=\"https://updates.timsherratt.org/categories/glamworkbench/\">news feed</a> for the latest additions and updates.</p>\n",
				"content_text": "We‚Äôre in the midst of planning for the [HASS Research Data Commons](https://ardc.edu.au/collaborations/strategic-activities/hass-and-indigenous-research-data-commons/), which will deliver some much-needed investment in digital research infrastructure for the humanities and social sciences. Amongst the funded programs are tools for text analysis as part of the Linguistics Data Commons, and a platform for more advanced research using Trove. I‚Äôm hoping that this will be an opportunity to take stock of existing tools and resources, and build flexible pathways for researchers that enable them to collect, move, analyse, preserve, and share data across different platforms and services. \n\nTo this end, I thought it might be useful to try and summarise what the [GLAM Workbench](https://glam-workbench.net/) offers, particularly for [Trove](https://trove.nla.gov.au/) researchers. The GLAM Workbench doesn‚Äôt really have an institutional home, and is mostly unfunded ‚Äì it‚Äôs my passion project. That means that it‚Äôs easy to overlook, particularly when the big grants are being doled out. But I think it has a lot to offer and I‚Äôm looking forward to exploring ways it can connect with these new initiatives.\n\n## Getting and moving data\nThere‚Äôs lots of fabulous data in Trove and other GLAM collections. In fact, there‚Äôs so much data that it can be difficult for researchers to find and collect what‚Äôs relevant to their interests. There are many tools in the GLAM Workbench to help researchers assemble their own datasets. For example:\n\n* **[Get newspaper articles in bulk with the Trove Newspaper and Gazette Harvester](https://glam-workbench.net/trove-harvester/)** ‚Äì This has been around in some form for more than ten years (it pre-dates the Trove API!). Give it the url of a search in Trove‚Äôs newspapers and gazettes and the harvester will save all the metadata in a CSV file, and optionally download the complete articles as OCRd text, images, or PDFs. The amount of data you harvest is really only limited by your patience and disk space. I‚Äôve harvested more than a million articles in the past. The GLAM Workbench includes a web app version of the harvester that runs live in the cloud ‚Äì just paste in your Trove API key and the search url, and click the button. \n*  **Get Trove newspaper pages as images** ‚Äì If you need a nice, high-resolution version of a newspaper page you can [use this web app](https://glam-workbench.net/trove-newspapers/#download-a-page-image). If you want to harvest every front page (or some other particular page) here‚Äôs an example that [gets all the covers of the *Australian Women‚Äôs Weekly*](https://glam-workbench.net/trove-newspapers/#harvest-australian-womens-weekly-covers-or-the-front-pages-of-any-newspaper). A pre-harvested [collection of the AWW covers](https://glam-workbench.net/trove-newspapers/#australian-womens-weekly-front-covers-1933-to-1982) is included as a bonus extra.\n*  **[Get Trove newspaper articles as images](https://glam-workbench.net/trove-newspapers/#save-a-trove-newspaper-article-as-an-image)** ‚Äì The Trove web interface makes it difficult to download complete images of articles, but this tool will do the job. There‚Äôs a handy web app to grab individual images, but the code from this tool is reused in other places such as the Trove Newspaper Harvester and the Omeka uploader, and could be built-in to your own research workflows.\n* **[Upload Trove newspaper articles to Omeka](https://glam-workbench.net/trove-newspapers/#upload-trove-newspaper-articles-to-omeka-s)** ‚Äì Whether you‚Äôre creating on online exhibition or building a research database, Omeka can be very useful. This notebook connects Trove‚Äôs newspapers to Omeka for easy upload. Your selected articles can come from a search query, a Trove list, a Zotero library, or just a list of article ids. Metadata records are created in Omeka for each article and newspaper, and an image of each article is attached.\n* **[Get OCRd text from digitised periodicals in Trove](https://glam-workbench.net/trove-journals/#get-ocrd-text-from-a-digitised-journal-in-trove)** ‚Äì They‚Äôre often overshadowed by the newspapers, but there‚Äôs now lots of digitised journals, magazines, and parliamentary papers in Trove. You can get article-level data from the API, but not issue data. This notebook enables researchers to get metadata and OCRd text from every available issue of a periodical. To make researchers‚Äô lives even easier, I regularly harvest [**all** the available OCRd text](https://glam-workbench.net/trove-journals/#ocrd-text-from-trove-digitised-journals) from digitised periodicals in Trove. The latest harvest downloaded 51,928 issues from 1,163 periodicals ‚Äì that‚Äôs about 10gb of text. You can [browse the list of periodicals](https://github.com/GLAM-Workbench/trove-journals/blob/master/digital-journals-with-text.md) with OCRd text, or [search this database](https://trove-digital-periodicals.glitch.me/data/trove-digital-journals). All the OCRd text is stored in a public repository on CloudStor.\n* **[Get page images from digitised periodicals in Trove](https://glam-workbench.net/trove-journals/#get-covers-or-any-other-pages-from-a-digitised-journal-in-trove)** ‚Äì There‚Äôs more than text in digitised periodicals, and you might want to download images of pages for visual analysis. This notebook shows you how to get cover images, but could be easily modified to get another page, or a PDF. I used a modified version of this to create [a collection of 3,471 full page editorial cartoons](https://glam-workbench.net/trove-journals/#editorial-cartoons-from-the-bulletin-1886-to-1952) from _The Bulletin_, 1886 to 1952 ‚Äì all available to download from CloudStor.\n* **[Get OCRd text from digitised books in Trove](https://glam-workbench.net/trove-books/#harvesting-the-text-of-digitised-books-and-ephemera)** ‚Äì Yep, there‚Äôs digitised books as well as newspapers and periodicals. You can download OCRd text from an individual book using the Trove web interface, but how do you make a collection of books without all that pointing and clicking? This notebook downloads all the available OCRd text from digitised books in Trove. The latest harvest includes [text from 26,762 works](https://glam-workbench.net/trove-books/#ocrd-text-from-trove-books-and-ephemera). You can explore the results [using this database](https://trove-digital-books.glitch.me/data/trove-digital-books).\n* **[Harvest parliamentary press releases from Trove](https://glam-workbench.net/trove-journals/#harvest-parliament-press-releases-from-trove)** ‚Äì Trove includes more than 380,000 press releases, speeches, and interview transcripts issued by Australian federal politicians and saved by the Parliamentary Library. This notebook shows you how to harvest both metadata and fulltext from a search of the parliamentary press releases. For example, here‚Äôs a collection of [politicians talking about ‚Äòrefugees‚Äô](https://glam-workbench.net/trove-journals/#politicians-talking-about-immigrants-and-refugees), and another [relating to COVID-19](https://glam-workbench.net/trove-journals/#politicians-talking-about-covid).\n* **[Harvest details of Radio National programs from Trove](https://glam-workbench.net/trove-music/#harvest-abc-radio-national-records-from-trove)** ‚Äì Trove creates records for programs broadcast on ABC Radio National, for the major current affairs programs these records at at segment level. Even though they don‚Äôt provide full transcripts, this data provide a rich, fine-grained record of Australia‚Äôs recent political, social, and economic history. This notebook shows you how to download the Radio National data. If you just want to dive straight in, there‚Äôs also a [pre-harvested collection](https://glam-workbench.net/trove-music/#abc-radio-national-programs) containing more than 400,000 records, with separate downloads for some of the main programs.\n* **[Find all the versions of an archived web page in Trove](https://glam-workbench.net/web-archives/#find-all-the-archived-versions-of-a-web-page)** ‚Äì Many of the tools in the [Web Archives section](https://glam-workbench.net/web-archives/) of the GLAM Workbench will work with the Australian Web Archive, which is part of Trove. This notebook shows you how to get data about the number of times a web page has been archived over time.\n* **[Harvesting collections of text from archived web pages in Trove](https://glam-workbench.net/web-archives/#harvesting-collections-of-text-from-archived-web-pages)** ‚Äì If you want to explore how the content of a web page changes over time, you can use this notebook to capture the text content of every archived version of a web page.\n*  **[Convert a Trove list into a CSV file](https://glam-workbench.net/trove-lists/#convert-a-trove-list-into-a-csv-file)** ‚Äì While Trove provides a data download option for lists, it leaves out a lot of useful data. This notebook downloads full details of newspaper articles and other works in a list and saves them as CSV files. Like the Trove Newspaper Harvester, it lets you download OCRd text and images from newspaper articles.\n* **Collecting information about Trove user activity** ‚Äì It‚Äôs not just the content of Trove that provides interesting research data, it‚Äôs also the way people engage with it. Using the Trove API it‚Äôs possible to harvest details of [all user created lists and tags](https://glam-workbench.net/trove-lists/). And yes, there‚Äôs pre-harvested collections of [lists](https://glam-workbench.net/trove-lists/#trove-lists-metadata) and [tags](https://glam-workbench.net/trove-lists/#trove-public-tags) for the impatient.\n\nWhile I‚Äôm focusing here on Trove, there‚Äôs also tools to create datasets from the [National Archives of Australia](https://glam-workbench.net/recordsearch/), [Digital NZ and Papers Past](https://glam-workbench.net/digitalnz/), the [National Museum of Australia](https://glam-workbench.net/nma/) and more. And there‚Äôs a [big list of readily downloadable datasets](https://glam-workbench.net/glam-data-list/) from Australian GLAM organisations.\n\n## Visualisation and analysis\nMany of the notebooks listed above include examples that demonstrate ways of exploring and analysing your harvested data. There are also a number of companion notebooks that examine some possibilities in more detail, for example:\n\n* [Explore your Trove newspaper harvests](https://glam-workbench.net/trove-harvester/#exploring-your-troveharvester-data)\n* [Load your Trove newspaper harvest in Datasette](https://glam-workbench.net/trove-harvester/#display-the-results-of-a-harvest-as-a-searchable-database-using-datasette)\n* [Exploring ABC Radio National metadata](https://glam-workbench.net/trove-music/#exploring-abc-radio-national-metadata)\n* [Analyse public tags added to Trove](https://glam-workbench.net/trove-lists/#analyse-public-tags-added-to-trove)\n\nBut there are also many other notebooks that demonstrate methods for analysing Trove‚Äôs content, for example:\n\n* **[QueryPic](https://glam-workbench.net/trove-newspapers/#querypic)** ‚Äì Another tool that‚Äôs been around in different forms for a decade, QueryPic visualises searches in Trove‚Äôs newspapers. The latest web app couldn‚Äôt be simpler, just paste in your API key and a search url and create charts showing the number of matching articles over time. You can combine queries, change time scales, and download the data and visualisations.\n* **[Visualise Trove newspaper searches over time](https://glam-workbench.net/trove-newspapers/#visualise-trove-newspaper-searches-over-time)** ‚Äì This is like a deconstructed version of QueryPic that walks you through the process of using Trove‚Äôs facets to assemble a dataset of results over time. It provide a lot of detail on the sorts of data available, and the questions we can ask of it.\n*  **[Visualise the total number of newspaper articles in Trove by year and state](https://glam-workbench.net/trove-newspapers/#visualise-the-total-number-of-newspaper-articles-in-trove-by-year-and-state)** ‚Äì This notebook uses a modified version of the code above to analyse the construction and context of Trove‚Äôs newspaper corpus itself. What are you actually searching? Meet the WWI effect and the copyright cliff of death! This is a great place to start if you want to get people thinking critically about digital resources are constructed.\n*  **[Analyse rates of OCR correction](https://glam-workbench.net/trove-newspapers/#analyse-rates-of-ocr-correction)** ‚Äì Some more meta-analysis of the Trove corpus itself, this time focusing on patterns of OCR correction by Trove users.\n*  **[Identifying non-English language newspapers in Trove](https://glam-workbench.net/trove-newspapers/#finding-non-english-newspapers-in-trove)** ‚Äì There are a growing number of non-English language newspapers digitised in Trove. However, if you're only searching using English keywords, you might never know that they're there. This notebook analyses a sample of articles from every newspaper in Trove to identify non-English content.\n*  **[Beyond the copyright cliff of death](https://glam-workbench.net/trove-newspapers/#beyond-the-copyright-cliff-of-death)** ‚Äì Most of the newspaper articles on Trove were published before 1955, but there are some from the later period. This notebook helps you find out how many, and which newspapers they were published in.\n*  **[Map Trove newspaper results by state](https://glam-workbench.net/trove-newspapers/#map-trove-newspaper-results-by-state)** ‚Äì This notebook uses the Trove `state` facet to create a choropleth map that visualises the number of search results per state. \n*  **[Map Trove newspaper results by place of publication](https://glam-workbench.net/trove-newspapers/#map-trove-newspaper-results-by-place-of-publication)** ‚Äì This notebook uses the Trove `title` facet to find the number of results per newspaper, then merges the results with a dataset of geolocated newspapers to map where articles were published.\n*  **[Compare two versions of an archived web page](https://glam-workbench.net/web-archives/#compare-two-versions-of-an-archived-web-page)** ‚Äì This notebook demonstrates a number of different ways of comparing versions of archived web pages. Just choose a repository, enter a url, and select two dates to see comparisons based on: page metadata, basic statistics such as file size and number of words, numbers of internal and external links, cosine similarity of text, line by line differences in text or code, and screenshots.\n*  **[Display changes in the text of an archived web page over time](https://glam-workbench.net/web-archives/#display-changes-in-the-text-of-an-archived-web-page-over-time)** ‚Äì This web app gathers all the available versions of a web page and then visualises changes in its content between versions ‚Äì what‚Äôs been added, removed, and changed?\n* **[Use screenshots to visualise change in a page over time](https://glam-workbench.net/web-archives/#using-screenshots-to-visualise-change-in-a-page-over-time)**‚Äì Create a series of full page screenshots of a web page over time, then assemble them into a time series.\n\nThere are also possibilities for using Trove data creatively. For example you can [create 'scissors and paste' messages from Trove newspaper articles](https://glam-workbench.net/trove-newspapers/#create-scissors-and-paste-messages-from-trove-newspaper-articles).\n\n## Documentation and examples\nAll the Trove notebooks in the GLAM Workbench help document the possibilities and limits of the Trove API. The examples above can be modified and reworked to suit different research interests. Some notebooks also explore particular aspects of the API, for example:\n\n* **[Trove API Introduction](https://glam-workbench.net/trove/)** ‚Äì Some very basic examples of making requests and understanding results.\n*  **[Today‚Äôs news yesterday](https://glam-workbench.net/trove-newspapers/#todays-news-yesterday)** ‚Äì Uses the `date` index and the `firstpageseq` parameter to find articles from exactly 100 years ago that were published on the front page. It then selects one of the articles at random and downloads and displays an image of the front page.\n*  **[The use of standard licences and rights statements in Trove image records](https://glam-workbench.net/trove-images/#the-use-of-standard-licences-and-rights-statements-in-trove-image-records)** ‚Äì Version 2.1 of the Trove API introduced a new rights index that you can use to limit your search results to records that include one of a list of standard licences and rights statements. We can also use this index to build a picture of which rights statements are currently being used, and by who.\n*  **[Random items from Trove](https://glam-workbench.net/trove-random/)** ‚Äì Changes to the Trove API meant that techniques you could previously use to select resources at random no longer work. This section documents some alternative ways of retrieving random-ish works and newspaper articles from Trove. \n\nAnd while it‚Äôs not officially part of the GLAM Workbench, I also maintain the [Trove API Console](https://troveconsole.herokuapp.com/) which provides lots of examples of the API in action.\n\n## Pathways\nIn developing the GLAM Workbench I‚Äôm very aware that people will arrive with different levels of digital skill, confidence, and experience. That‚Äôs why I‚Äôve been putting a lot of thought and effort into ways of providing a range of entry points.\n\nSomeone who might not identify as a ‚Äòdigital‚Äô researcher can, with a single click, start up QueryPic and start exploring changes over time in Trove‚Äôs newspapers. This is possible because the GLAM Workbench is configured to [make use of Binder](https://glam-workbench.net/using-binder/), a service that spins up customised computing environments as needed.\n\nAnother researcher might start running the Trove Newspaper Harvester using Binder, but find that they want to run bigger and longer harvests. In that case, the GLAM Workbench offers a one-click installation of the Trove Newspaper Harvester on [Reclaim Cloud](https://glam-workbench.net/using-reclaim-cloud/). Unlike Binder, Reclaim Cloud environments are persistent, so you can run the harvester for as long as you want without the worry of interruptions.\n\nYet another researcher might want to understand how the Trove API works and the sorts of data that it makes available. By exploring the various notebooks they‚Äôll find useful snippets of code they can try out in their own projects.\n\nThe GLAM Workbench connects outwards to make use of a range of other services ‚Äì the notebooks run in Binder, Reclaim Cloud, and Docker; the code is all openly licensed and publicly available through GitHub and Zenodo; data is hosted on GitHub, CloudStor, and Zenodo; datasets can be explored using Datasette running on Glitch or Google CloudRun. I‚Äôm hoping that the new investments in HASS research infrastructure will embed a similar philosophy, connecting up existing services rather than starting from scratch.\n\n## The future\n\nThis is just an outline on what the GLAM Workbench currently offers researchers wanting to make use of the data available from Trove. It's all there now, publicly accessible, openly licensed, and ready to use ‚Äì take it, use it, change it, share it. But there's **much more** I'd like to do, both in regard to Trove and to encourage use of GLAM data more generally. I'm also interested in your ideas for new tools, examples, or data sources ‚Äì what would help your research? You can [add a suggestion](https://glam-workbench.net/suggest-a-topic/) in GitHub, or post a comment in the [GLAM Workbench channel](https://ozglam.chat/c/glam-workbench/8) of OzGLAM Help.\n\nSee the [Getting Started section](https://glam-workbench.net/getting-started/) of the GLAM Workbench for more hints and examples. And keep an eye on the [news feed](https://updates.timsherratt.org/categories/glamworkbench/) for the latest additions and updates. \n\n\n",
				"date_published": "2021-08-26T17:31:00+11:00",
				"url": "https://updates.timsherratt.org/2021/08/26/glam-workbench-a.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/08/23/a-family-history.html",
				"title": "A Family History Month experiment ‚Äì search millions of name records from GLAM organisations",
				"content_html": "<p>There‚Äôs a lot of rich historical data contained within the indexes that Australian GLAM organisations provide to help people navigate their records. These indexes, often created by volunteers, allow access by key fields such as name, date or location. They aid discovery, but also allow new forms of analysis and visualisation. Kate Bagnall and I wrote about some of the possibilities, and the difficulties, in this <a href=\"http://doi.org/10.1353/jwh.2021.0025\">recently published article</a>.</p>\n\n<p>Many of these indexes can be downloaded from government data portals. The GLAM Workbench demonstrates <a href=\"https://glam-workbench.net/glam-data-portals/\">how these can be harvested</a>, and provides a <a href=\"https://glam-workbench.net/glam-datasets-from-gov-portals/\">list of available datasets</a> to browse. But what‚Äôs inside them? The <a href=\"https://glam-workbench.net/csv-explorer/\">GLAM CSV Explorer</a> visualises the contents of the indexes to give you a sneak peek and encourage you to dig deeper.</p>\n\n<p>There‚Äôs even more indexes available from the NSW State Archives. Most of these aren‚Äôt accessible thought the NSW government data portal yet, but I managed to <a href=\"https://glam-workbench.net/nsw-state-archives/\">scrape them from the website</a> a couple of years ago and made them <a href=\"https://glam-workbench.net/nsw-state-archives/#nsw-state-archives-online-indexes\">available as CSVs</a> for easy download.</p>\n\n<p>It‚Äôs <a href=\"https://familyhistorymonth.org.au/\">Family History Month</a> at the moment, and the other night I thought of an interesting little experiment using the indexes. I‚Äôve been playing round with <a href=\"https://datasette.io/\">Datasette</a> lately. It‚Äôs a fabulous tool for exploring tabular data, like CSVs. I also noticed that Datasette‚Äôs creator Simon Willison had added a <a href=\"https://simonwillison.net/2020/Mar/9/datasette-search-all/\">search-all plugin</a> that enabled you to run a full text search across multiple databases and tables. Hmmm, I wondered, would it be possible to use Datasette to provide a way of searching for names across <strong>all</strong> those GLAM indexes?</p>\n\n<p>After a few nights work, I found the answer was <strong>yes</strong>.</p>\n\n<p><strong><a href=\"https://glam-workbench.net/name-search/\">Try out my new aggregated search interface here!</a></strong>.</p>\n\n<p>(The cloud service it uses runs on demand, so if it has gone to sleep, it might take a little while to wake up again ‚Äì just be patient for a few seconds.)</p>\n\n<p><a href=\"https://glam-workbench.net/name-search/\"><img src=\"https://updates.timsherratt.org/uploads/2021/bf9da8208a.png\" alt=\"\" title=\"Scrrenshot of GLAM Name index search\" /></a></p>\n\n<p>Currently, the <a href=\"https://glam-workbench.net/name-search/\">GLAM Name Search</a> interface lets you search for names across 195 indexes from eight GLAM organisations. All together, there‚Äôs a total of more than <strong>9.2 million rows of data</strong> to explore!</p>\n\n<p>It‚Äôs simple to use ‚Äì just enter a name in the search box and Datasette will search each index in turn, displaying the first five matching results. You can click through to view all results from a specific index. Not surprisingly, the aggregated name search only searches columns containing names. However, once you click through to an individual table, you can apply additional filters or facets.</p>\n\n<p>To create the aggregated search interface I worked through the <a href=\"https://github.com/GLAM-Workbench/ozglam-data/blob/master/glam-datasets-from-gov-portals-csvs.csv\">list of CSVs</a> I‚Äôd harvested from government data portals to identify those that contained names of people, and discard those that contained administrative, rather than historical data. I also made a note of the columns that contained the names so I could index their contents once they‚Äôd been added to the database. Usually these were fields such as <code>Surname</code> or <code>Given names</code>, but sometimes names were in the record title or notes.</p>\n\n<p>Datasette uses SQLite databases to store its data. I decided to create one database for each GLAM organisation. I wrote some code to work through my list of datasets, saving them into an SQLite database, indexing the name columns, and writing information about the dataset to a <code>metadata.json</code> file. This file is used by Datasette to display information such as the title, source, licence, and last modified date of each of the indexes.</p>\n\n<p>Once that was done, I could fire up Datasette and feed it all the SQLite databases. Amazingly it all worked ‚Äì searching across all the indexes was remarkably quick! To make it publicly available I used the Datasette <a href=\"https://docs.datasette.io/en/stable/publish.html\"><code>publish</code></a> to push everything to Google CloudRun (about 1.4 gb of data). The first time I used CloudRun it took some time to get the authentication and other settings working properly. This time was much smoother. Before long it was live!</p>\n\n<p>Once I knew it all worked, I decided to add in another 59 indexes from the NSW State Archives. I also plugged in a few extra indexes from the Public Record Office of Victoria. These datasets are stored as ZIP files in the Victorian government data portal, so it took a little bit of extra manual processing to get everything sorted. But finally I had all <strong>195 indexes</strong> loaded.</p>\n\n<p>What now? That depends on whether people find this experiment useful. I have a few ideas for improvements. But if people do use it, then the costs will go up. I‚Äôm going to have to monitor this over the next couple of months to see if I can afford to keep it going. If you want to help with the running costs, you might like to sign up as a <a href=\"https://github.com/sponsors/wragge?o=esb\">GitHub sponsor</a>.</p>\n\n<p><strong>And please let me know if you think it‚Äôs worth developing!</strong> #dhhacks</p>\n",
				"content_text": "There‚Äôs a lot of rich historical data contained within the indexes that Australian GLAM organisations provide to help people navigate their records. These indexes, often created by volunteers, allow access by key fields such as name, date or location. They aid discovery, but also allow new forms of analysis and visualisation. Kate Bagnall and I wrote about some of the possibilities, and the difficulties, in this [recently published article](http://doi.org/10.1353/jwh.2021.0025).\n\nMany of these indexes can be downloaded from government data portals. The GLAM Workbench demonstrates [how these can be harvested](https://glam-workbench.net/glam-data-portals/), and provides a [list of available datasets](https://glam-workbench.net/glam-datasets-from-gov-portals/) to browse. But what‚Äôs inside them? The [GLAM CSV Explorer](https://glam-workbench.net/csv-explorer/) visualises the contents of the indexes to give you a sneak peek and encourage you to dig deeper. \n\nThere‚Äôs even more indexes available from the NSW State Archives. Most of these aren‚Äôt accessible thought the NSW government data portal yet, but I managed to [scrape them from the website](https://glam-workbench.net/nsw-state-archives/) a couple of years ago and made them [available as CSVs](https://glam-workbench.net/nsw-state-archives/#nsw-state-archives-online-indexes) for easy download.\n\nIt‚Äôs [Family History Month](https://familyhistorymonth.org.au/) at the moment, and the other night I thought of an interesting little experiment using the indexes. I‚Äôve been playing round with [Datasette](https://datasette.io/) lately. It‚Äôs a fabulous tool for exploring tabular data, like CSVs. I also noticed that Datasette‚Äôs creator Simon Willison had added a [search-all plugin](https://simonwillison.net/2020/Mar/9/datasette-search-all/) that enabled you to run a full text search across multiple databases and tables. Hmmm, I wondered, would it be possible to use Datasette to provide a way of searching for names across **all** those GLAM indexes?\n\nAfter a few nights work, I found the answer was **yes**. \n\n**[Try out my new aggregated search interface here!](https://glam-workbench.net/name-search/)**.\n\n(The cloud service it uses runs on demand, so if it has gone to sleep, it might take a little while to wake up again ‚Äì just be patient for a few seconds.)\n\n[![](https://updates.timsherratt.org/uploads/2021/bf9da8208a.png \"Scrrenshot of GLAM Name index search\")](https://glam-workbench.net/name-search/)\n\nCurrently, the [GLAM Name Search](https://glam-workbench.net/name-search/) interface lets you search for names across 195 indexes from eight GLAM organisations. All together, there‚Äôs a total of more than **9.2 million rows of data** to explore!\n\nIt‚Äôs simple to use ‚Äì just enter a name in the search box and Datasette will search each index in turn, displaying the first five matching results. You can click through to view all results from a specific index. Not surprisingly, the aggregated name search only searches columns containing names. However, once you click through to an individual table, you can apply additional filters or facets.\n\nTo create the aggregated search interface I worked through the [list of CSVs](https://github.com/GLAM-Workbench/ozglam-data/blob/master/glam-datasets-from-gov-portals-csvs.csv) I‚Äôd harvested from government data portals to identify those that contained names of people, and discard those that contained administrative, rather than historical data. I also made a note of the columns that contained the names so I could index their contents once they‚Äôd been added to the database. Usually these were fields such as `Surname` or `Given names`, but sometimes names were in the record title or notes.\n\nDatasette uses SQLite databases to store its data. I decided to create one database for each GLAM organisation. I wrote some code to work through my list of datasets, saving them into an SQLite database, indexing the name columns, and writing information about the dataset to a `metadata.json` file. This file is used by Datasette to display information such as the title, source, licence, and last modified date of each of the indexes.\n\nOnce that was done, I could fire up Datasette and feed it all the SQLite databases. Amazingly it all worked ‚Äì searching across all the indexes was remarkably quick! To make it publicly available I used the Datasette [`publish`](https://docs.datasette.io/en/stable/publish.html) to push everything to Google CloudRun (about 1.4 gb of data). The first time I used CloudRun it took some time to get the authentication and other settings working properly. This time was much smoother. Before long it was live!\n\nOnce I knew it all worked, I decided to add in another 59 indexes from the NSW State Archives. I also plugged in a few extra indexes from the Public Record Office of Victoria. These datasets are stored as ZIP files in the Victorian government data portal, so it took a little bit of extra manual processing to get everything sorted. But finally I had all **195 indexes** loaded.\n\nWhat now? That depends on whether people find this experiment useful. I have a few ideas for improvements. But if people do use it, then the costs will go up. I‚Äôm going to have to monitor this over the next couple of months to see if I can afford to keep it going. If you want to help with the running costs, you might like to sign up as a [GitHub sponsor](https://github.com/sponsors/wragge?o=esb). \n\n**And please let me know if you think it‚Äôs worth developing!** #dhhacks\n\n\n",
				"date_published": "2021-08-23T11:05:00+11:00",
				"url": "https://updates.timsherratt.org/2021/08/23/a-family-history.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/08/16/explore-troves-digitised.html",
				"title": "Explore Trove‚Äôs digitised books",
				"content_html": "<p>The <a href=\"https://glam-workbench.net/trove-books/\">Trove books section of the GLAM Workbench¬†</a>has been updated! There‚Äôs freshly-harvested data, as well as updated Python packages, integration with Reclaim Cloud, and automated Docker builds.</p>\n\n<p>Included is <a href=\"https://glam-workbench.net/trove-books/#harvesting-the-text-of-digitised-books-and-ephemera\">a notebook to harvest details of all books</a> available from Trove in digital form. This includes both digitised books, that have been scanned and OCRd, as well as born digital publications, such as PDFs and epubs. The definition of ‚Äòbooks‚Äô is pretty loose ‚Äì I‚Äôve harvested details of anything that has been assigned the format ‚ÄòBook‚Äô in Trove, but this includes <a href=\"https://updates.timsherratt.org/2021/08/13/a-miscellany-of.html\">ephemera, such as posters, pamphlets, and advertising</a>.</p>\n\n<p>In the latest harvest, I ended up with details of 42,174 ‚Äòbooks‚Äô. This includes some duplicates, because multiple metadata entries can point to the same digital object. I thought it was best to preserve the duplicates, rather than discard the metadata.</p>\n\n<p>Once I‚Äôd harvested the details of the books, I tried to see if there was any OCRd text available for download. If there was, I saved it to a <a href=\"https://cloudstor.aarnet.edu.au/plus/s/ugiw3gdijSKaoTL\">public folder on CloudStor</a>. In total, I was able to download 26,762 files of OCRd text.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/7b5774a071.png\" alt=\"Screenshot of database showing details of digital book\" /></p>\n\n<p>The easiest way to explore the books is <a href=\"https://trove-digital-books.glitch.me/data/trove-digital-books\">using this searchable database</a>. It‚Äôs created using Datasette and is running on Glitch. Full text search is available on the ‚Äòtitle‚Äô and ‚Äòcontributors‚Äô fields, and you can filter on things like date, copyright status, number of pages, and whether OCRd text is available for download. If there is OCRd text, a direct link to the file on CloudStor is included. You can use the database to filter the titles, creating your own dataset that you can download in CSV or JSON format.</p>\n\n<p>If you just want the full list of books as a CSV file, you can <a href=\"https://nbviewer.jupyter.org/github/GLAM-Workbench/trove-books/blob/master/trove_digitised_books_with_ocr.csv\">download it here</a>. And if you want <em>all</em> the OCRd text, you can go straight to the <a href=\"https://cloudstor.aarnet.edu.au/plus/s/ugiw3gdijSKaoTL\">public folder on CloudStor</a> ‚Äì there‚Äôs about 3.6gb of text files to explore! #dhhacks</p>\n",
				"content_text": "The [Trove books section of the GLAM Workbench¬†](https://glam-workbench.net/trove-books/)has been updated! There‚Äôs freshly-harvested data, as well as updated Python packages, integration with Reclaim Cloud, and automated Docker builds.\n\nIncluded is [a notebook to harvest details of all books](https://glam-workbench.net/trove-books/#harvesting-the-text-of-digitised-books-and-ephemera) available from Trove in digital form. This includes both digitised books, that have been scanned and OCRd, as well as born digital publications, such as PDFs and epubs. The definition of ‚Äòbooks‚Äô is pretty loose ‚Äì I‚Äôve harvested details of anything that has been assigned the format ‚ÄòBook‚Äô in Trove, but this includes [ephemera, such as posters, pamphlets, and advertising](https://updates.timsherratt.org/2021/08/13/a-miscellany-of.html).\n\nIn the latest harvest, I ended up with details of 42,174 ‚Äòbooks‚Äô. This includes some duplicates, because multiple metadata entries can point to the same digital object. I thought it was best to preserve the duplicates, rather than discard the metadata.\n\nOnce I‚Äôd harvested the details of the books, I tried to see if there was any OCRd text available for download. If there was, I saved it to a [public folder on CloudStor](https://cloudstor.aarnet.edu.au/plus/s/ugiw3gdijSKaoTL). In total, I was able to download 26,762 files of OCRd text.\n\n![Screenshot of database showing details of digital book](https://updates.timsherratt.org/uploads/2021/7b5774a071.png)\n\nThe easiest way to explore the books is [using this searchable database](https://trove-digital-books.glitch.me/data/trove-digital-books). It‚Äôs created using Datasette and is running on Glitch. Full text search is available on the ‚Äòtitle‚Äô and ‚Äòcontributors‚Äô fields, and you can filter on things like date, copyright status, number of pages, and whether OCRd text is available for download. If there is OCRd text, a direct link to the file on CloudStor is included. You can use the database to filter the titles, creating your own dataset that you can download in CSV or JSON format.\n\nIf you just want the full list of books as a CSV file, you can [download it here](https://nbviewer.jupyter.org/github/GLAM-Workbench/trove-books/blob/master/trove_digitised_books_with_ocr.csv). And if you want *all* the OCRd text, you can go straight to the [public folder on CloudStor](https://cloudstor.aarnet.edu.au/plus/s/ugiw3gdijSKaoTL) ‚Äì there‚Äôs about 3.6gb of text files to explore! #dhhacks\n\n",
				"date_published": "2021-08-16T16:40:15+11:00",
				"url": "https://updates.timsherratt.org/2021/08/16/explore-troves-digitised.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/08/13/a-miscellany-of.html",
				"title": "A miscellany of ephemera, oddities, \u0026 estrays",
				"content_html": "<p>I‚Äôm just in the midst of updating my harvest of OCRd text from Trove‚Äôs digitised books (more about that soon!). But amongst the items catalogued as ‚Äòbooks‚Äô are a wide assortment of ephemera, posters, advertisements, and other oddities. There‚Äôs no consistent way of identifying these items through the search interface, but because I‚Äôve found the number of pages in each ‚Äòbook‚Äô as part of the harvesting process, I can limit results to items with just a single digitised page ‚Äì there‚Äôs more than 1,500! To make it easy to explore this collection of odds and ends, I‚Äôve downloaded all the single page images and compiled them into <a href=\"https://www.dropbox.com/s/xi84y12zz6iryfu/trove-ephemera.pdf?dl=0\">one big PDF</a> with links back to their entries in Trove. Enjoy your browsing!</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/1f185ad85f.png\" alt=\"\" title=\"Screenshot from PDF showing a 'To let' poster\" /></p>\n\n<p>This is another example of the ways in which we can extend and enrich existing collection interfaces using simple technologies like PDFs and CSVs. We can create slices across existing categories to expose interesting features, and provide new entry points for researchers. Some other examples in the GLAM Workbench are the collection of <a href=\"https://glam-workbench.net/trove-journals/#editorial-cartoons-from-the-bulletin-1886-to-1952\">editorial cartoons from <em>The Bulletin</em></a>, the list of Trove newspapers with <a href=\"https://glam-workbench.net/trove-newspapers/#trove-newspapers-with-non-english-language-content\">non-English content</a>, the harvest of <a href=\"https://glam-workbench.net/trove-music/#abc-radio-national-programs\">ABC Radio National programs</a>, and the recent collection of <a href=\"https://glam-workbench.net/trove-journals/#politicians-talking-about-covid\">politicians talking about COVID</a>. <a href=\"https://glam-workbench.net/suggest-a-topic/\">Let me know</a> if you have any ideas for additional slices! #dhhacks</p>\n",
				"content_text": "I‚Äôm just in the midst of updating my harvest of OCRd text from Trove‚Äôs digitised books (more about that soon!). But amongst the items catalogued as ‚Äòbooks‚Äô are a wide assortment of ephemera, posters, advertisements, and other oddities. There‚Äôs no consistent way of identifying these items through the search interface, but because I‚Äôve found the number of pages in each ‚Äòbook‚Äô as part of the harvesting process, I can limit results to items with just a single digitised page ‚Äì there‚Äôs more than 1,500! To make it easy to explore this collection of odds and ends, I‚Äôve downloaded all the single page images and compiled them into [one big PDF](https://www.dropbox.com/s/xi84y12zz6iryfu/trove-ephemera.pdf?dl=0) with links back to their entries in Trove. Enjoy your browsing!\n\n![](https://updates.timsherratt.org/uploads/2021/1f185ad85f.png \"Screenshot from PDF showing a 'To let' poster\")\n\nThis is another example of the ways in which we can extend and enrich existing collection interfaces using simple technologies like PDFs and CSVs. We can create slices across existing categories to expose interesting features, and provide new entry points for researchers. Some other examples in the GLAM Workbench are the collection of [editorial cartoons from _The Bulletin_](https://glam-workbench.net/trove-journals/#editorial-cartoons-from-the-bulletin-1886-to-1952), the list of Trove newspapers with [non-English content](https://glam-workbench.net/trove-newspapers/#trove-newspapers-with-non-english-language-content), the harvest of [ABC Radio National programs](https://glam-workbench.net/trove-music/#abc-radio-national-programs), and the recent collection of [politicians talking about COVID](https://glam-workbench.net/trove-journals/#politicians-talking-about-covid). [Let me know](https://glam-workbench.net/suggest-a-topic/) if you have any ideas for additional slices! #dhhacks\n\n",
				"date_published": "2021-08-13T12:02:00+11:00",
				"url": "https://updates.timsherratt.org/2021/08/13/a-miscellany-of.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/08/09/everyday-heritage-and.html",
				"title": "Everyday heritage and the GLAM Workbench",
				"content_html": "<p>Some good news on the funding front with the success of the <a href=\"https://dataportal.arc.gov.au/NCGP/Web/Grant/Grant/LP200301446\">Everyday Heritage project</a> in the latest round of ARC Linkage grants. The project aims to look beyond the formal discourses of ‚Äònational‚Äô heritage to develop a more diverse range of heritage narratives. Working at the intersection of place, digital collections, and material culture, team members will develop a series of ‚Äòheritage biographies‚Äô, that document everyday experience, and provide new models for the heritage sector.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/37dbda004e.png\" alt=\"Screen capture of project details in ARC grants database\" /></p>\n\n<p>Digital methods will play a major role in the project. I‚Äôll be leading the ‚ÄòHeritage Hacks‚Äô work package that will support the creation of the heritage biographies and develop a range of new tools and tutorials for use in heritage management contexts. All the tools, methods, and data generated through the project will be documented using Jupyter notebooks and published through the <a href=\"https://glam-workbench.net/\">GLAM Workbench</a>. Watch this space!</p>\n\n<p>The project is led by <a href=\"https://researchprofiles.canberra.edu.au/en/persons/tracy-ireland\">Tracy Ireland</a> (University of Canberra), with <a href=\"https://research-repository.uwa.edu.au/en/persons/jane-lydon\">Jane Lydon</a> (UWA), <a href=\"https://www.utas.edu.au/profiles/staff/humanities/kate-bagnall\">Kate Bagnall</a> (UTAS), and me as chief investigators. Our industry partner is <a href=\"https://www.gml.com.au/\">GML Heritage</a>.</p>\n",
				"content_text": "Some good news on the funding front with the success of the [Everyday Heritage project](https://dataportal.arc.gov.au/NCGP/Web/Grant/Grant/LP200301446) in the latest round of ARC Linkage grants. The project aims to look beyond the formal discourses of ‚Äònational‚Äô heritage to develop a more diverse range of heritage narratives. Working at the intersection of place, digital collections, and material culture, team members will develop a series of ‚Äòheritage biographies‚Äô, that document everyday experience, and provide new models for the heritage sector.\n\n![Screen capture of project details in ARC grants database](https://updates.timsherratt.org/uploads/2021/37dbda004e.png)\n\nDigital methods will play a major role in the project. I‚Äôll be leading the ‚ÄòHeritage Hacks‚Äô work package that will support the creation of the heritage biographies and develop a range of new tools and tutorials for use in heritage management contexts. All the tools, methods, and data generated through the project will be documented using Jupyter notebooks and published through the [GLAM Workbench](https://glam-workbench.net/). Watch this space!\n\nThe project is led by [Tracy Ireland](https://researchprofiles.canberra.edu.au/en/persons/tracy-ireland) (University of Canberra), with [Jane Lydon](https://research-repository.uwa.edu.au/en/persons/jane-lydon) (UWA), [Kate Bagnall](https://www.utas.edu.au/profiles/staff/humanities/kate-bagnall) (UTAS), and me as chief investigators. Our industry partner is [GML Heritage](https://www.gml.com.au/).\n\n\n",
				"date_published": "2021-08-09T12:26:38+11:00",
				"url": "https://updates.timsherratt.org/2021/08/09/everyday-heritage-and.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/08/06/recent-glam-workbench.html",
				"title": "Recent GLAM Workbench presentations",
				"content_html": "<p>So far this year I‚Äôve given eight workshops or presentations relating to the GLAM Workbench, with probably a few more yet to come. Here‚Äôs the latest:</p>\n\n<ul>\n<li><a href=\"https://slides.com/wragge/gcscr-2021\">Introducing the GLAM Workbench</a>, presentation for the Griffith University Centre for Social and Cultural Research, Digital Humanities Seminar Series, 6 August 2021</li>\n<li><a href=\"https://youtu.be/pkC-seP00Kc\">Exploring the GLAM Workbench</a> (<a href=\"https://slides.com/wragge/uts-dh-2021\">slides</a>), presentation for the UTS Digital Histories Seminar Series, 8 July 2021</li>\n<li><a href=\"https://doi.org/10.5281/zenodo.5121188\">The GLAM Workbench: A Labs approach?</a>, presentation for the panel &lsquo;Research use of web archives: A labs approach&rsquo;, at the IIPC Web Archiving Conference, 15 June 2021</li>\n<li><a href=\"https://slides.com/wragge/pha-workshop-may-2021\">Hands-on introduction to the GLAM Workbench</a>, workshop for the Professional Historians Association of Victoria and Tasmania, 27 May 2021</li>\n<li><a href=\"https://doi.org/10.5281/zenodo.5121224\">Exploring collections through the GLAM Workbench</a>, keynote presentation for the XVIII Congr√©s d&rsquo;Arxv√≠stica i Gesti√≥ de Documents de Catalunya, 11 May 2021</li>\n<li><a href=\"https://slides.com/wragge/aha-ecr-workshop\">Quick hacks and DIY data: Innovations for the discerning historian</a>, presentation for AHA ECR digital skills seminar, 5 March 2021</li>\n</ul>\n\n<p>You can view <a href=\"https://glam-workbench.net/presentations/\">all the GLAM Workbench presentations</a> here.</p>\n",
				"content_text": "So far this year I‚Äôve given eight workshops or presentations relating to the GLAM Workbench, with probably a few more yet to come. Here‚Äôs the latest:\n\n* [Introducing the GLAM Workbench](https://slides.com/wragge/gcscr-2021), presentation for the Griffith University Centre for Social and Cultural Research, Digital Humanities Seminar Series, 6 August 2021\n* [Exploring the GLAM Workbench](https://youtu.be/pkC-seP00Kc) ([slides](https://slides.com/wragge/uts-dh-2021)), presentation for the UTS Digital Histories Seminar Series, 8 July 2021\n* [The GLAM Workbench: A Labs approach?](https://doi.org/10.5281/zenodo.5121188), presentation for the panel 'Research use of web archives: A labs approach', at the IIPC Web Archiving Conference, 15 June 2021\n* [Hands-on introduction to the GLAM Workbench](https://slides.com/wragge/pha-workshop-may-2021), workshop for the Professional Historians Association of Victoria and Tasmania, 27 May 2021\n* [Exploring collections through the GLAM Workbench](https://doi.org/10.5281/zenodo.5121224), keynote presentation for the XVIII Congr√©s d'Arxv√≠stica i Gesti√≥ de Documents de Catalunya, 11 May 2021\n* [Quick hacks and DIY data: Innovations for the discerning historian](https://slides.com/wragge/aha-ecr-workshop), presentation for AHA ECR digital skills seminar, 5 March 2021\n\nYou can view [all the GLAM Workbench presentations](https://glam-workbench.net/presentations/) here.\n\n",
				"date_published": "2021-08-06T18:42:17+11:00",
				"url": "https://updates.timsherratt.org/2021/08/06/recent-glam-workbench.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/08/06/updated-lots-and.html",
				"title": "Updated! Lots and lots of text freshly harvested from Trove periodicals",
				"content_html": "<p>For a few years now I‚Äôve been harvesting downloadable text from digitised periodicals in Trove and making it easily available for exploration and research. I‚Äôve just completed the latest harvest ‚Äì here‚Äôs the summary:</p>\n\n<ul>\n<li>1,163 digitised periodicals had text available for download</li>\n<li>Text was downloaded from 51,928 individual issues</li>\n<li>Adding up to a total of around 12gb of text</li>\n</ul>\n\n<p>If you want to dive straight in, here‚Äôs a <a href=\"https://github.com/GLAM-Workbench/trove-journals/blob/master/digital-journals-with-text.md\">list of all the harvested periodicals</a>, with links to download a summary of available issues, as well as all the harvested text (there‚Äôs one file per issue). You‚Äôll notice that the list includes a large number of parliamentary papers and government reports as well as published journals.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/008359faba.png\" alt=\"List of Trove periodicals with downloadable text\" /></p>\n\n<p>All of the harvested text is available from a <a href=\"https://cloudstor.aarnet.edu.au/plus/s/QOmnqpGQCNCSC2h\">public folder on CloudStor</a>.</p>\n\n<p>The harvesting process involves a few different steps:</p>\n\n<ul>\n<li>First I generate a list of periodicals available in digital form from Trove. This includes digitised titles, as well as born-digital titles submitted through e-Legal Deposit. This produced <a href=\"https://glam-workbench.net/trove-journals/#csv-formatted-list-of-journals-available-from-trove-in-digital-form\">a CSV file</a> containing the details of 7,270 titles. See <a href=\"https://glam-workbench.net/trove-journals/#create-a-list-of-troves-digitised-journals\">this notebook</a> for details.</li>\n<li>Then I work through this list of titles to find out how many issues of each title are available through Trove. This information isn‚Äôt accessible through the API, so I have to do some screen scraping.</li>\n<li>Next I work through the list of issues and try to download the text contents. Most of the born-digital titles don‚Äôt have downloadable text.</li>\n<li>Once I‚Äôve downloaded all the text I can from a title, I create a CSV file for it that lists the available issues and notes whether text is available for each. This file is stored with the text on CloudStor.</li>\n<li>Once I‚Äôve checked all the titles, I generate <a href=\"https://glam-workbench.net/trove-journals/#csv-formatted-list-of-journals-with-ocrd-text\">another CSV file</a> that lists the details of all the periodicals that have downloadable text.</li>\n<li>The code to harvest and document the downloaded text is <a href=\"https://glam-workbench.net/trove-journals/#download-the-ocrd-text-for-all-the-digitised-journals-in-trove\">available in this notebook</a>. #dhhacks</li>\n</ul>\n",
				"content_text": "For a few years now I‚Äôve been harvesting downloadable text from digitised periodicals in Trove and making it easily available for exploration and research. I‚Äôve just completed the latest harvest ‚Äì here‚Äôs the summary:\n\n*  1,163 digitised periodicals had text available for download\n* Text was downloaded from 51,928 individual issues\n* Adding up to a total of around 12gb of text\n\nIf you want to dive straight in, here‚Äôs a [list of all the harvested periodicals](https://github.com/GLAM-Workbench/trove-journals/blob/master/digital-journals-with-text.md), with links to download a summary of available issues, as well as all the harvested text (there‚Äôs one file per issue). You‚Äôll notice that the list includes a large number of parliamentary papers and government reports as well as published journals.\n\n![List of Trove periodicals with downloadable text](https://updates.timsherratt.org/uploads/2021/008359faba.png)\n\nAll of the harvested text is available from a [public folder on CloudStor](https://cloudstor.aarnet.edu.au/plus/s/QOmnqpGQCNCSC2h).\n\nThe harvesting process involves a few different steps:\n\n* First I generate a list of periodicals available in digital form from Trove. This includes digitised titles, as well as born-digital titles submitted through e-Legal Deposit. This produced [a CSV file](https://glam-workbench.net/trove-journals/#csv-formatted-list-of-journals-available-from-trove-in-digital-form) containing the details of 7,270 titles. See [this notebook](https://glam-workbench.net/trove-journals/#create-a-list-of-troves-digitised-journals) for details.\n* Then I work through this list of titles to find out how many issues of each title are available through Trove. This information isn‚Äôt accessible through the API, so I have to do some screen scraping.\n* Next I work through the list of issues and try to download the text contents. Most of the born-digital titles don‚Äôt have downloadable text.\n* Once I‚Äôve downloaded all the text I can from a title, I create a CSV file for it that lists the available issues and notes whether text is available for each. This file is stored with the text on CloudStor.\n* Once I‚Äôve checked all the titles, I generate [another CSV file](https://glam-workbench.net/trove-journals/#csv-formatted-list-of-journals-with-ocrd-text) that lists the details of all the periodicals that have downloadable text.\n* The code to harvest and document the downloaded text is [available in this notebook](https://glam-workbench.net/trove-journals/#download-the-ocrd-text-for-all-the-digitised-journals-in-trove). #dhhacks\n\n\n",
				"date_published": "2021-08-06T10:49:54+11:00",
				"url": "https://updates.timsherratt.org/2021/08/06/updated-lots-and.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/08/02/new-dataset-politicians.html",
				"title": "New dataset ‚Äì Politicians talking about COVID",
				"content_html": "<p>The <a href=\"https://glam-workbench.net/trove-journals/\">Trove Journals</a> section of the GLAM Workbench includes <a href=\"https://glam-workbench.net/trove-journals/#harvest-parliament-press-releases-from-trove\">a notebook</a> that helps you download press releases, speeches, and interview transcripts by Australian federal politicians. These documents are compiled and published by the Parliamentary Library, and the details are regularly harvested into Trove.</p>\n\n<p>Using this notebook, I‚Äôve created a collection of documents that include the words ‚ÄòCOVID‚Äô or ‚ÄòCoronavirus‚Äô. It includes all the <strong>metadata</strong> from Trove, as well as the <strong>full text</strong> of each document downloaded from the Parliamentary Library. There‚Äôs <strong>3,995 documents in total</strong>, covering the period up until early April 2021. You can <strong><a href=\"https://github.com/GLAM-Workbench/trove-journals/raw/6f4d805186716853b81c7d93cac6754685b384bf/press-releases/press-releases-coronavirus-or-covid.zip\">download them all as a zip file</a></strong> (12 mb).</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/44a7f87b2c.png\" alt=\"\" title=\"Screenshot showing a sample of the harvested metadata\" /></p>\n\n<p>While I was compiling this dataset, I also made a few improvements to the notebook. You can now filter the results to weed out false positives, and identify duplicates. #dhhacks</p>\n",
				"content_text": "The [Trove Journals](https://glam-workbench.net/trove-journals/) section of the GLAM Workbench includes [a notebook](https://glam-workbench.net/trove-journals/#harvest-parliament-press-releases-from-trove) that helps you download press releases, speeches, and interview transcripts by Australian federal politicians. These documents are compiled and published by the Parliamentary Library, and the details are regularly harvested into Trove.\n\nUsing this notebook, I‚Äôve created a collection of documents that include the words ‚ÄòCOVID‚Äô or ‚ÄòCoronavirus‚Äô. It includes all the **metadata** from Trove, as well as the **full text** of each document downloaded from the Parliamentary Library. There‚Äôs **3,995 documents in total**, covering the period up until early April 2021. You can **[download them all as a zip file](https://github.com/GLAM-Workbench/trove-journals/raw/6f4d805186716853b81c7d93cac6754685b384bf/press-releases/press-releases-coronavirus-or-covid.zip)** (12 mb).\n\n![](https://updates.timsherratt.org/uploads/2021/44a7f87b2c.png \"Screenshot showing a sample of the harvested metadata\")\n\nWhile I was compiling this dataset, I also made a few improvements to the notebook. You can now filter the results to weed out false positives, and identify duplicates. #dhhacks\n\n",
				"date_published": "2021-08-02T11:23:00+11:00",
				"url": "https://updates.timsherratt.org/2021/08/02/new-dataset-politicians.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/07/14/million-trove-tags.html",
				"title": "8 million Trove tags to explore!",
				"content_html": "<p>I‚Äôve always been interested in the way people add value to resources in Trove. OCR correction tends to get all the attention, but Trove users have also been busy organising resources using tags, lists, and comments. I used to refer to tagging quite often in <a href=\"http://discontents.com.au/myths-mega-projects-and-making/\">presentations</a>, pointing to the different ways they were used. For example, ‚ÄòTBD‚Äô is a workflow marker, used by text correctors to label articles that are ‚ÄòTo Be Done‚Äô. My favourite was ‚ÄòLRRSA‚Äô, one of the most heavily-used tags across the whole of Trove. What does it mean? It stands for the Light Rail Research Society of Australia, and the tag is used by members to mark items of shared interest. It‚Äôs a great example of how something as simple as plain text tags can be used to support collaboration and build communities.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/f76b2e110b.png\" alt=\"Word cloud showing the top 200 Trove tags\" /></p>\n\n<p>Until its update last year, Trove used to provide some basic stats about user activity. There was also a tag cloud that let you explore the most commonly-used tags. It‚Äôs now much harder to access this sort of information. However, you can extract some basic information about tags from the Trove API. First of all, you can filter a search using ‚Äòhas:tags‚Äô to limit the results to items that have tags attached to them. Then to find out what the tags actually are, you can add the <code>include=tags</code> parameter. This embeds the tags within the item record, so you can work through a set of results, extracting all the tags as you go. To save you the trouble, I‚Äôve done this for the whole of Trove, and ended up with <strong>a dataset containing more than 8 million tags</strong>!</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/6ef630ccef.png\" alt=\"Chart showing the number of tags per year and zone.\" /></p>\n\n<p>The dataset is saved as a 500mb CSV file, and contains the following fields:</p>\n\n<ul>\n<li><code>tag</code> ‚Äì lower-cased version of the tag</li>\n<li><code>date</code> ‚Äì date the tag was added</li>\n<li><code>zone</code> ‚Äì the API zone that contains the tagged resource</li>\n<li><code>resource_id</code> ‚Äì the identifier of he tagged resource</li>\n</ul>\n\n<p>There‚Äôs a few things to note about the data:</p>\n\n<ul>\n<li>Works (such as books) in Trove can have tags attached at either work or version level. This dataset aggregates all tags at the work level, removing any duplicates.</li>\n<li>A single resource in Trove can appear in multiple zones ‚Äì for example, a book that includes maps and illustrations might appear in the &lsquo;book&rsquo;, &lsquo;picture&rsquo;, and &lsquo;map&rsquo; zones. This means that some of the tags will essentially be duplicates ‚Äì harvested from different zones, but relating to the same resource. Depending on your interests, you might want to remove these duplicates.</li>\n<li>While most of the tags were added by Trove users, more than 500,000 tags were added by Trove itself in November 2009. I think these tags were automatically generated from related Wikipedia pages. Depending on your interests, you might want to exclude these by limiting the date range or zones.</li>\n<li>User content added to Trove, including tags, is available for reuse under a CC-BY-NC licence.</li>\n</ul>\n\n<p>You can download the complete dataset from <a href=\"https://doi.org/10.5281/zenodo.5094314\">Zenodo</a>, or from <a href=\"https://cloudstor.aarnet.edu.au/plus/s/YiWStNrhnTo18JI\">CloudStor</a>. For more information on how I harvested the data, and some of its limits and complexities, see the notebooks in the new <a href=\"https://glam-workbench.net/trove-lists/#tags\">‚ÄòTags‚Äô section in the GLAM Workbench</a>. There‚Äôs also some examples of analysing and visualising the tags. As an extra bonus, there‚Äôs a more compact <a href=\"https://github.com/GLAM-Workbench/trove-lists/blob/master/trove_tag_counts_20210710.csv\">50mb CSV dataset</a> which lists each unique tag and the number of times it has been used.</p>\n\n<p>Of course, it‚Äôs worth remembering that this sort of dataset is out of date before the harvest is even finished. More tags are being added all the time! But hopefully this data will help us better understand the way people work to organise and enrich complex resources like Trove. #dhhacks</p>\n",
				"content_text": "I‚Äôve always been interested in the way people add value to resources in Trove. OCR correction tends to get all the attention, but Trove users have also been busy organising resources using tags, lists, and comments. I used to refer to tagging quite often in [presentations](http://discontents.com.au/myths-mega-projects-and-making/), pointing to the different ways they were used. For example, ‚ÄòTBD‚Äô is a workflow marker, used by text correctors to label articles that are ‚ÄòTo Be Done‚Äô. My favourite was ‚ÄòLRRSA‚Äô, one of the most heavily-used tags across the whole of Trove. What does it mean? It stands for the Light Rail Research Society of Australia, and the tag is used by members to mark items of shared interest. It‚Äôs a great example of how something as simple as plain text tags can be used to support collaboration and build communities.\n\n![Word cloud showing the top 200 Trove tags](https://updates.timsherratt.org/uploads/2021/f76b2e110b.png)\n\nUntil its update last year, Trove used to provide some basic stats about user activity. There was also a tag cloud that let you explore the most commonly-used tags. It‚Äôs now much harder to access this sort of information. However, you can extract some basic information about tags from the Trove API. First of all, you can filter a search using ‚Äòhas:tags‚Äô to limit the results to items that have tags attached to them. Then to find out what the tags actually are, you can add the `include=tags` parameter. This embeds the tags within the item record, so you can work through a set of results, extracting all the tags as you go. To save you the trouble, I‚Äôve done this for the whole of Trove, and ended up with **a dataset containing more than 8 million tags**!\n\n![Chart showing the number of tags per year and zone.](https://updates.timsherratt.org/uploads/2021/6ef630ccef.png)\n\nThe dataset is saved as a 500mb CSV file, and contains the following fields:\n\n* `tag` ‚Äì lower-cased version of the tag\n* `date` ‚Äì date the tag was added\n* `zone` ‚Äì the API zone that contains the tagged resource\n* `resource_id` ‚Äì the identifier of he tagged resource\n\nThere‚Äôs a few things to note about the data:\n\n* Works (such as books) in Trove can have tags attached at either work or version level. This dataset aggregates all tags at the work level, removing any duplicates.\n* A single resource in Trove can appear in multiple zones ‚Äì for example, a book that includes maps and illustrations might appear in the 'book', 'picture', and 'map' zones. This means that some of the tags will essentially be duplicates ‚Äì harvested from different zones, but relating to the same resource. Depending on your interests, you might want to remove these duplicates.\n* While most of the tags were added by Trove users, more than 500,000 tags were added by Trove itself in November 2009. I think these tags were automatically generated from related Wikipedia pages. Depending on your interests, you might want to exclude these by limiting the date range or zones.\n* User content added to Trove, including tags, is available for reuse under a CC-BY-NC licence.\n\nYou can download the complete dataset from [Zenodo](https://doi.org/10.5281/zenodo.5094314), or from [CloudStor](https://cloudstor.aarnet.edu.au/plus/s/YiWStNrhnTo18JI). For more information on how I harvested the data, and some of its limits and complexities, see the notebooks in the new [‚ÄòTags‚Äô section in the GLAM Workbench](https://glam-workbench.net/trove-lists/#tags). There‚Äôs also some examples of analysing and visualising the tags. As an extra bonus, there‚Äôs a more compact [50mb CSV dataset](https://github.com/GLAM-Workbench/trove-lists/blob/master/trove_tag_counts_20210710.csv) which lists each unique tag and the number of times it has been used.\n\nOf course, it‚Äôs worth remembering that this sort of dataset is out of date before the harvest is even finished. More tags are being added all the time! But hopefully this data will help us better understand the way people work to organise and enrich complex resources like Trove. #dhhacks\n\n",
				"date_published": "2021-07-14T18:06:00+11:00",
				"url": "https://updates.timsherratt.org/2021/07/14/million-trove-tags.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/07/01/integrating-glam-workbench.html",
				"title": "Integrating GLAM Workbench news and discussion",
				"content_html": "<p>I‚Äôve spent a lot of time this year working on ways of improving the GLAM Workbench‚Äôs documentation and its integration with other services. Last year I created <a href=\"https://ozglam.chat/\">OzGLAM Help</a> to provide a space where users of GLAM collections could ask questions and share discoveries ‚Äì including a dedicated <a href=\"https://ozglam.chat/c/glam-workbench/8\">GLAM Workbench channel</a>. Earlier this year, I tweaked my Micro.blog powered updates to include a dedicated <a href=\"https://updates.timsherratt.org/categories/glamworkbench\">GLAM Workbench news feed</a>. Now I‚Äôve brought the two together! What does this mean?</p>\n\n<ul>\n<li>Any GLAM Workbench news that I post to my updates feed is now automatically added to OzGLAM Help</li>\n<li>Links are automatically added to items in the news feed that let you add comments or questions in OzGLAM Help</li>\n</ul>\n\n<p>So now there‚Äôs two-way communication between the services providing more ways for people to discover and discuss how the GLAM Workbench can help them.</p>\n",
				"content_text": "I‚Äôve spent a lot of time this year working on ways of improving the GLAM Workbench‚Äôs documentation and its integration with other services. Last year I created [OzGLAM Help](https://ozglam.chat/) to provide a space where users of GLAM collections could ask questions and share discoveries ‚Äì including a dedicated [GLAM Workbench channel](https://ozglam.chat/c/glam-workbench/8). Earlier this year, I tweaked my Micro.blog powered updates to include a dedicated [GLAM Workbench news feed](https://updates.timsherratt.org/categories/glamworkbench). Now I‚Äôve brought the two together! What does this mean?\n\n* Any GLAM Workbench news that I post to my updates feed is now automatically added to OzGLAM Help\n* Links are automatically added to items in the news feed that let you add comments or questions in OzGLAM Help\n\nSo now there‚Äôs two-way communication between the services providing more ways for people to discover and discuss how the GLAM Workbench can help them.\n\n\n",
				"date_published": "2021-07-01T16:18:41+11:00",
				"url": "https://updates.timsherratt.org/2021/07/01/integrating-glam-workbench.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/07/01/glam-workbench-now.html",
				"title": "GLAM Workbench now on YouTube!",
				"content_html": "<p>I‚Äôve started creating short videos to introduce or explain various components of the <a href=\"https://glam-workbench.net/\">GLAM Workbench</a>. The first video shows how you can visualise searches in Trove‚Äôs digitised newspapers using the latest version of QueryPic. It‚Äôs a useful introduction to the way access to collection data enables us to ask different types of questions of historical sources.</p>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/vdyKNowv9gw\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n<p>As with all GLAM Workbench resources, the video is openly-licensed ‚Äì so feel free to stop it into your own course materials or workshops. It could, for example, provide an interesting little digital methods task in an Australian history unit.</p>\n\n<p>I‚Äôll be creating a second QueryPic video shortly, demonstrating how you can work with complex queries and differing timescales. Let me know if you find it useful, or if you have any ideas for future topics. #dhhacks</p>\n",
				"content_text": "I‚Äôve started creating short videos to introduce or explain various components of the [GLAM Workbench](https://glam-workbench.net/). The first video shows how you can visualise searches in Trove‚Äôs digitised newspapers using the latest version of QueryPic. It‚Äôs a useful introduction to the way access to collection data enables us to ask different types of questions of historical sources.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/vdyKNowv9gw\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\nAs with all GLAM Workbench resources, the video is openly-licensed ‚Äì so feel free to stop it into your own course materials or workshops. It could, for example, provide an interesting little digital methods task in an Australian history unit.\n\nI‚Äôll be creating a second QueryPic video shortly, demonstrating how you can work with complex queries and differing timescales. Let me know if you find it useful, or if you have any ideas for future topics. #dhhacks\n\n",
				"date_published": "2021-07-01T15:51:00+11:00",
				"url": "https://updates.timsherratt.org/2021/07/01/glam-workbench-now.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/06/28/glam-workbench-office.html",
				"title": "GLAM Workbench office hours",
				"content_html": "<p>To help you make use of the <a href=\"https://glam-workbench.net/\">GLAM Workbench</a>, I‚Äôve set up an ‚Äòoffice hours‚Äô time slot every Friday when people can book in for 30 minute chats via Zoom. Want to talk about how you might use the GLAM Workbench in your latest research project? Are you having trouble getting started with GLAM data? Or perhaps you have some ideas for future notebooks you‚Äôd like to share? Just click on the ‚ÄòBook a chat‚Äô link in the GLAM Workbench, or head straight to the <a href=\"https://calendly.com/timsherratt/30minchat\">scheduling page</a> to set up a time!</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/94822f8fd4.png\" alt=\"Book a chat!\" title=\"Screenshot of booking pop up in the GLAM Workbench\" /></p>\n\n<p>This is yet another experiment to see how I can support the use of GLAM data and the development of digital skills with the GLAM Workbench. Let me know if you think it‚Äôs worthwhile. #dhhacks</p>\n",
				"content_text": "To help you make use of the [GLAM Workbench](https://glam-workbench.net/), I‚Äôve set up an ‚Äòoffice hours‚Äô time slot every Friday when people can book in for 30 minute chats via Zoom. Want to talk about how you might use the GLAM Workbench in your latest research project? Are you having trouble getting started with GLAM data? Or perhaps you have some ideas for future notebooks you‚Äôd like to share? Just click on the ‚ÄòBook a chat‚Äô link in the GLAM Workbench, or head straight to the [scheduling page](https://calendly.com/timsherratt/30minchat) to set up a time!\n\n![Book a chat!](https://updates.timsherratt.org/uploads/2021/94822f8fd4.png \"Screenshot of booking pop up in the GLAM Workbench\")\n\nThis is yet another experiment to see how I can support the use of GLAM data and the development of digital skills with the GLAM Workbench. Let me know if you think it‚Äôs worthwhile. #dhhacks\n\n",
				"date_published": "2021-06-28T15:04:56+11:00",
				"url": "https://updates.timsherratt.org/2021/06/28/glam-workbench-office.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/06/28/missing-links-new.html",
				"title": "‚ÄòMissing Links‚Äô ‚Äì new open access article!",
				"content_html": "<p>An <a href=\"http://doi.org/10.1353/jwh.2021.0025\">article written by Kate Bagnall and me</a> has just been published in a special issue of the <em>Journal of World History</em> focusing on digital history. And it‚Äôs open access!</p>\n\n<p>The article is ‚ÄòMissing Links: Data Stories from the Archive of British Settler Colonial Citizenship‚Äô. In it we document our efforts to assemble a number of different datasets relating to naturalization. Here‚Äôs the abstract:</p>\n\n<blockquote>\n<p>Digitized sources and digital methods are changing the way that we do history. For historians of the British Empire, the digital age offers new possibilities for investigating the lives of those who moved around the empire and across the world. However, much discussion of the possibilities and problems of digital history have focused on the creation and use of full text resources, skipping over the analytical opportunities offered by the descriptive systems in which those texts are embedded. This article is an attempt to fill this gap by documenting a journey through archival data relating to nineteenth-century Chinese naturalization in the Pacific Rim settler colonies of Australia, New Zealand, and Canada. We argue that such data stories are critical if we are to understand both possibilities and pitfalls of research in digital collections.</p>\n</blockquote>\n\n<p>There‚Äôs also an <a href=\"https://github.com/wragge/naturalization-data-stories\">GitHub repository</a> with code and data related to the article.</p>\n",
				"content_text": "An [article written by Kate Bagnall and me](http://doi.org/10.1353/jwh.2021.0025) has just been published in a special issue of the *Journal of World History* focusing on digital history. And it‚Äôs open access!\n\nThe article is ‚ÄòMissing Links: Data Stories from the Archive of British Settler Colonial Citizenship‚Äô. In it we document our efforts to assemble a number of different datasets relating to naturalization. Here‚Äôs the abstract:\n\n> Digitized sources and digital methods are changing the way that we do history. For historians of the British Empire, the digital age offers new possibilities for investigating the lives of those who moved around the empire and across the world. However, much discussion of the possibilities and problems of digital history have focused on the creation and use of full text resources, skipping over the analytical opportunities offered by the descriptive systems in which those texts are embedded. This article is an attempt to fill this gap by documenting a journey through archival data relating to nineteenth-century Chinese naturalization in the Pacific Rim settler colonies of Australia, New Zealand, and Canada. We argue that such data stories are critical if we are to understand both possibilities and pitfalls of research in digital collections.\n\nThere‚Äôs also an [GitHub repository](https://github.com/wragge/naturalization-data-stories) with code and data related to the article.\n\n",
				"date_published": "2021-06-28T14:08:10+11:00",
				"url": "https://updates.timsherratt.org/2021/06/28/missing-links-new.html"
			},
			{
				"id": "http://wragge.micro.blog/2021/06/21/querypic-the-next.html",
				"title": "QueryPic: The Next Generation",
				"content_html": "<p>QueryPic is a tool to visualise searches in Trove‚Äôs digitised newspapers. I created the first version <a href=\"http://discontents.com.au/mining-the-treasures-of-trove-part-2/\">way back in 2011</a>, and since then it‚Äôs taken a number of different forms. The latest version introduces some new features:</p>\n\n<ul>\n<li><strong>Automatic query creation</strong> ‚Äì construct your search in the Trove web interface, then just copy and paste the url into QueryPic. This means you can take advantage of Trove‚Äôs advanced search and facets to build complex queries.</li>\n<li><strong>Multiple time scales</strong> ‚Äì previous versions only aggregated search results by year, but now you can also aggregate by month, or by day. QueryPic will automatically choose a time unit based on the date range of your query, but if you‚Äôre not happy with the result you can change it!</li>\n<li><strong>Links back to Trove</strong> ‚Äì click on any of the points on the chart to search Trove within that time period. This enables you to zoom in and out of your results, from the high-level visualisation, to individual articles.</li>\n</ul>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/b02780ed6c.png\" alt=\"Screenshot of QueryPic chart\" /></p>\n\n<p>This version of QueryPic is built within a Jupyter notebook, and designed to run using Voila (which hides all the code and makes the notebook look like a web app). See the <a href=\"https://glam-workbench.net/trove-newspapers/#querypic\">Trove Newspapers section</a> of the GLAM Workbench for more information. If you‚Äôd like to give it a try, just click the button below to run it live using Binder.</p>\n\n<p><a href=\"https://mybinder.org/v2/gh/GLAM-Workbench/trove-newspapers/master?urlpath=voila/render/querypic.ipynb\"><img src=\"https://static.mybinder.org/badge_logo.svg\" alt=\"Binder badge\" /></a></p>\n\n<p>Hope you find it useful! #dhhacks</p>\n",
				"content_text": "QueryPic is a tool to visualise searches in Trove‚Äôs digitised newspapers. I created the first version [way back in 2011](http://discontents.com.au/mining-the-treasures-of-trove-part-2/), and since then it‚Äôs taken a number of different forms. The latest version introduces some new features:\n\n* **Automatic query creation** ‚Äì construct your search in the Trove web interface, then just copy and paste the url into QueryPic. This means you can take advantage of Trove‚Äôs advanced search and facets to build complex queries.\n* **Multiple time scales** ‚Äì previous versions only aggregated search results by year, but now you can also aggregate by month, or by day. QueryPic will automatically choose a time unit based on the date range of your query, but if you‚Äôre not happy with the result you can change it!\n* **Links back to Trove** ‚Äì click on any of the points on the chart to search Trove within that time period. This enables you to zoom in and out of your results, from the high-level visualisation, to individual articles.\n\n![Screenshot of QueryPic chart](https://updates.timsherratt.org/uploads/2021/b02780ed6c.png)\n\nThis version of QueryPic is built within a Jupyter notebook, and designed to run using Voila (which hides all the code and makes the notebook look like a web app). See the [Trove Newspapers section](https://glam-workbench.net/trove-newspapers/#querypic) of the GLAM Workbench for more information. If you‚Äôd like to give it a try, just click the button below to run it live using Binder.\n\n[![Binder badge](https://static.mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GLAM-Workbench/trove-newspapers/master?urlpath=voila/render/querypic.ipynb)\n\nHope you find it useful! #dhhacks\n\n",
				"date_published": "2021-06-21T11:50:19+11:00",
				"url": "https://updates.timsherratt.org/2021/06/21/querypic-the-next.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/06/21/everyone-gets-a.html",
				"title": "Everyone gets a Lab!",
				"content_html": "<p>I recently took part in a panel at the <a href=\"https://netpreserve.org/ga2021/\">IIPC Web Archiving Conference</a> discussing ‚ÄòResearch use of web archives: a Labs approach‚Äô. My fellow panellists described some amazing stuff going on in European cultural heritage organisations to support researchers who want to make use of web archives. My ‚Äòlab‚Äô doesn‚Äôt have a physical presence, or an institutional home, but it does provide a starting point for researchers, and with the latest Reclaim Cloud and Docker integrations, everyone can have their own web archives lab! Here‚Äôs my 8 minute video. The slides are <a href=\"https://slides.com/wragge/wac-labs-panel\">available here</a>.</p>\n\n<iframe src=\"https://player.vimeo.com/video/563996783\" width=\"640\" height=\"360\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen></iframe>\n",
				"content_text": "I recently took part in a panel at the [IIPC Web Archiving Conference](https://netpreserve.org/ga2021/) discussing ‚ÄòResearch use of web archives: a Labs approach‚Äô. My fellow panellists described some amazing stuff going on in European cultural heritage organisations to support researchers who want to make use of web archives. My ‚Äòlab‚Äô doesn‚Äôt have a physical presence, or an institutional home, but it does provide a starting point for researchers, and with the latest Reclaim Cloud and Docker integrations, everyone can have their own web archives lab! Here‚Äôs my 8 minute video. The slides are [available here](https://slides.com/wragge/wac-labs-panel).\n\n<iframe src=\"https://player.vimeo.com/video/563996783\" width=\"640\" height=\"360\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen></iframe>\n\n",
				"date_published": "2021-06-21T11:00:30+11:00",
				"url": "https://updates.timsherratt.org/2021/06/21/everyone-gets-a.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/06/14/minor-change-to.html",
				"title": "Minor change to Reclaim Cloud config",
				"content_html": "<p>When the 1-click installer for Reclaim Cloud works its magic and turns GLAM Workbench repositories into your own, personal digital labs, it creates a new <code>work</code> directory mounted inside of your main Jupyter directory. This new directory is independent of the Docker image used to run Jupyter, so it‚Äôs a handy place to copy things if you ever want to update the Docker image. However, I just realised that there was a permissions problem with the <code>work</code> directory which meant you couldn‚Äôt write files to it from within Jupyter.</p>\n\n<p>To fix the problem, I‚Äôve added an extra line to the <code>reclaim-manifest.jps</code> config file to make the Jupyter user the owner of the <code>work</code> directory:</p>\n\n<pre><code>\t- cmd[cp]: chown -R jovyan:jovyan /home/jovyan/work\n</code></pre>\n\n<p>This takes care of any new installations. If you have an existing installation, you can either just create a completely new environment using the updated config, or you can manually change the permissions:</p>\n\n<ul>\n<li>Hover over the name of your environment in the control panel to display the option buttons.</li>\n<li>Click on the Settings button. A new box will open at the bottom of the control panel with all the settings options.</li>\n<li>Click on &lsquo;SSH Access&rsquo; in the left hand menu of the settings box.</li>\n<li>Click on the &lsquo;SSH Connection&rsquo; tab.</li>\n<li>Under &lsquo;Web SSH&rsquo; click on the Connect button and select the default node.</li>\n\n<li><p>A terminal session will open. At the command line enter the following:</p>\n\n<pre><code>\tchown -R jovyan:jovyan /home/jovyan/work\n</code></pre></li>\n</ul>\n\n<p>Done! See the <a href=\"https://glam-workbench.net/using-reclaim-cloud/\">Using Reclaim Cloud</a> section of the GLAM Workbench for more information.</p>\n",
				"content_text": "When the 1-click installer for Reclaim Cloud works its magic and turns GLAM Workbench repositories into your own, personal digital labs, it creates a new `work` directory mounted inside of your main Jupyter directory. This new directory is independent of the Docker image used to run Jupyter, so it‚Äôs a handy place to copy things if you ever want to update the Docker image. However, I just realised that there was a permissions problem with the `work` directory which meant you couldn‚Äôt write files to it from within Jupyter. \n\nTo fix the problem, I‚Äôve added an extra line to the `reclaim-manifest.jps` config file to make the Jupyter user the owner of the `work` directory:\n\n```\n\t- cmd[cp]: chown -R jovyan:jovyan /home/jovyan/work\n```\n\nThis takes care of any new installations. If you have an existing installation, you can either just create a completely new environment using the updated config, or you can manually change the permissions:\n\n* Hover over the name of your environment in the control panel to display the option buttons.\n* Click on the Settings button. A new box will open at the bottom of the control panel with all the settings options.\n* Click on 'SSH Access' in the left hand menu of the settings box.\n* Click on the 'SSH Connection' tab.\n* Under 'Web SSH' click on the Connect button and select the default node.\n* A terminal session will open. At the command line enter the following:\n\n```\n\tchown -R jovyan:jovyan /home/jovyan/work\n```\n\nDone! See the [Using Reclaim Cloud](https://glam-workbench.net/using-reclaim-cloud/) section of the GLAM Workbench for more information.\n\n",
				"date_published": "2021-06-14T15:44:00+11:00",
				"url": "https://updates.timsherratt.org/2021/06/14/minor-change-to.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/06/14/preprint-the-limits.html",
				"title": "Preprint! The limits and affordances of online collections",
				"content_html": "<p>I‚Äôve been working on an essay for publication in a forthcoming edited collection. I wanted to explore how the practice of history in Australia had been changed by GLAM organisations making their collections available online ‚Äì both the new possibilities that had emerged, and the problems that remained. In the end I focused on three areas ‚Äì discovery, digitisation, and research infrastructure. If you‚Äôre interested, I‚Äôve <a href=\"https://doi.org/10.5281/zenodo.4925423\">shared a preprint on Zenodo</a>.</p>\n\n<p>Here‚Äôs a taste:</p>\n\n<blockquote>\n<p>Just twenty years ago, historical research often entailed long hours spent at a microfilm reader, browsing newspaper after newspaper in the hope of finding something relevant. The changes wrought by Trove, and other digital collections, seem revolutionary, but as with all revolutions there have been gains and losses. Alongside the wonders wrought by digitisation, this chapter has tried to highlight some of the paths not taken. The online resources we now use daily are not simply the products of technology ‚Äì priorities have been set, funding has been distributed, decisions made about what to include and what to leave out. Cultural heritage collections are not just put online, they are placed within specific contexts of discovery and use. Each object, each version, each interface comes with a set of limitations and affordances that together determine what is possible. We do not know yet how these decisions will shape the sorts of histories that we write.</p>\n</blockquote>\n\n<p>I enjoyed reminding myself about some early digital initiatives in the GLAM sector, but as is usual with these sorts of projects, I had to leave a lot out. It‚Äôs made me think about developing a larger project documenting our gains and losses.</p>\n",
				"content_text": "I‚Äôve been working on an essay for publication in a forthcoming edited collection. I wanted to explore how the practice of history in Australia had been changed by GLAM organisations making their collections available online ‚Äì both the new possibilities that had emerged, and the problems that remained. In the end I focused on three areas ‚Äì discovery, digitisation, and research infrastructure. If you‚Äôre interested, I‚Äôve [shared a preprint on Zenodo](https://doi.org/10.5281/zenodo.4925423).\n\nHere‚Äôs a taste:\n\n> Just twenty years ago, historical research often entailed long hours spent at a microfilm reader, browsing newspaper after newspaper in the hope of finding something relevant. The changes wrought by Trove, and other digital collections, seem revolutionary, but as with all revolutions there have been gains and losses. Alongside the wonders wrought by digitisation, this chapter has tried to highlight some of the paths not taken. The online resources we now use daily are not simply the products of technology ‚Äì priorities have been set, funding has been distributed, decisions made about what to include and what to leave out. Cultural heritage collections are not just put online, they are placed within specific contexts of discovery and use. Each object, each version, each interface comes with a set of limitations and affordances that together determine what is possible. We do not know yet how these decisions will shape the sorts of histories that we write.\n\nI enjoyed reminding myself about some early digital initiatives in the GLAM sector, but as is usual with these sorts of projects, I had to leave a lot out. It‚Äôs made me think about developing a larger project documenting our gains and losses.\n\n",
				"date_published": "2021-06-14T14:13:45+11:00",
				"url": "https://updates.timsherratt.org/2021/06/14/preprint-the-limits.html"
			},
			{
				"id": "http://wragge.micro.blog/2021/06/14/trove-query-parser.html",
				"title": "Trove Query Parser",
				"content_html": "<p>Here‚Äôs a <a href=\"https://github.com/wragge/trove_query_parser/\">new little Python package</a> that you might find useful. It simply takes a search url from Trove‚Äôs Newspapers &amp; Gazettes category and converts it into a set of parameters that you can use to request data from the Trove API. While some parameters are used both in the web interface and the API, there are a lot of variations ‚Äì this package means you don‚Äôt have to keep track of all the differences!</p>\n\n<p>It‚Äôs very simple to use.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/5b7e85ea88.png\" alt=\"How to use the Trove Query Parser.\" /></p>\n\n<p>The code for the parser has been basically lifted from the <a href=\"https://pypi.org/project/troveharvester/\">Trove Newspaper Harvester</a>. I wanted to separate it out so that I could use it at various spots in the <a href=\"https://glam-workbench.net/\">GLAM Workbench</a> and in other projects.</p>\n\n<p>This package, the documentation, and the tests were all created using <a href=\"https://github.com/fastai/nbdev\">nbdev</a>, which is really quite a fun way to develop Python packages. #dhhacks</p>\n",
				"content_text": "Here‚Äôs a [new little Python package](https://github.com/wragge/trove_query_parser/) that you might find useful. It simply takes a search url from Trove‚Äôs Newspapers & Gazettes category and converts it into a set of parameters that you can use to request data from the Trove API. While some parameters are used both in the web interface and the API, there are a lot of variations ‚Äì this package means you don‚Äôt have to keep track of all the differences! \n\nIt‚Äôs very simple to use.\n\n![How to use the Trove Query Parser.](https://updates.timsherratt.org/uploads/2021/5b7e85ea88.png)\n\nThe code for the parser has been basically lifted from the [Trove Newspaper Harvester](https://pypi.org/project/troveharvester/). I wanted to separate it out so that I could use it at various spots in the [GLAM Workbench](https://glam-workbench.net/) and in other projects.\n\nThis package, the documentation, and the tests were all created using [nbdev](https://github.com/fastai/nbdev), which is really quite a fun way to develop Python packages. #dhhacks\n\n",
				"date_published": "2021-06-14T13:46:01+11:00",
				"url": "https://updates.timsherratt.org/2021/06/14/trove-query-parser.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/06/13/some-glam-workbench.html",
				"title": "Some GLAM Workbench stats",
				"content_html": "<p>I deliberately don‚Äôt keep any stats about GLAM Workbench visits, because I think they‚Äôre pretty meaningless. On the other hand, I‚Äôm always interested to see how often GLAM Workbench repositories are launched on <a href=\"https://archive.analytics.mybinder.org/\">Binder</a>. Rather than just random clicks, these numbers represent the number of times users started new computing sessions using the GLAM Workbench. I just compiled these stats for the past year, and I was very pleased to see that the <a href=\"https://glam-workbench.net/web-archives/\">Web Archives</a> section has been launched over 1,000 times in the past twelve months! The <a href=\"https://glam-workbench.net/trove-newspapers/\">Trove Newspapers</a> and <a href=\"https://glam-workbench.net/trove-harvester/\">Trove Newspaper Harvester</a> repositories are also well used ‚Äì on average these are both being launched more than once a day.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/3aa3ee045b.png\" alt=\"Binder launches of GLAM Workbench repositories, 1 June 2020 to 2 June 2021.\" /></p>\n\n<p>The GLAM Workbench is never going to attract massive numbers of users ‚Äì it‚Äôs all about <em>being there</em> when a researcher needs help to use GLAM collections. One or two launches per day means one or two researchers from somewhere around the world are able to explore new datasets, or ask new questions. I think that‚Äôs pretty important.</p>\n",
				"content_text": "I deliberately don‚Äôt keep any stats about GLAM Workbench visits, because I think they‚Äôre pretty meaningless. On the other hand, I‚Äôm always interested to see how often GLAM Workbench repositories are launched on [Binder](https://archive.analytics.mybinder.org/). Rather than just random clicks, these numbers represent the number of times users started new computing sessions using the GLAM Workbench. I just compiled these stats for the past year, and I was very pleased to see that the [Web Archives](https://glam-workbench.net/web-archives/) section has been launched over 1,000 times in the past twelve months! The [Trove Newspapers](https://glam-workbench.net/trove-newspapers/) and [Trove Newspaper Harvester](https://glam-workbench.net/trove-harvester/) repositories are also well used ‚Äì on average these are both being launched more than once a day. \n\n![Binder launches of GLAM Workbench repositories, 1 June 2020 to 2 June 2021.](https://updates.timsherratt.org/uploads/2021/3aa3ee045b.png)\n\nThe GLAM Workbench is never going to attract massive numbers of users ‚Äì it‚Äôs all about *being there* when a researcher needs help to use GLAM collections. One or two launches per day means one or two researchers from somewhere around the world are able to explore new datasets, or ask new questions. I think that‚Äôs pretty important.\n\n",
				"date_published": "2021-06-13T19:01:23+11:00",
				"url": "https://updates.timsherratt.org/2021/06/13/some-glam-workbench.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/06/13/more-reclaim-cloud.html",
				"title": "More Reclaim Cloud integrations!",
				"content_html": "<p>Five of the GLAM Workbench repositories now have automatically built Docker images and 1-click integration with <a href=\"https://reclaim.cloud/\">Reclaim Cloud</a> ‚Äì <a href=\"https://glam-workbench.net/anu-archives/\">ANU Archives</a>, <a href=\"https://glam-workbench.net/trove-newspapers/\">Trove Newspapers</a>, <a href=\"https://glam-workbench.net/trove-harvester/\">Trove Newspaper Harvester</a>, <a href=\"https://glam-workbench.net/recordsearch/\">NAA RecordSearch</a>, &amp; <a href=\"https://glam-workbench.net/web-archives/\">Web Archives</a>.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/45605b531f.png\" alt=\"\" title=\"Screencap showing Reclaim Cloud details\" /></p>\n\n<p>This means you can launch your very own version of these GLAM Workbench repositories in the cloud, where all your downloads and experiments will be saved! Find out more on the <a href=\"https://glam-workbench.net/using-reclaim-cloud/\">Using Reclaim Cloud</a> page.</p>\n",
				"content_text": "Five of the GLAM Workbench repositories now have automatically built Docker images and 1-click integration with [Reclaim Cloud](https://reclaim.cloud/) ‚Äì [ANU Archives](https://glam-workbench.net/anu-archives/), [Trove Newspapers](https://glam-workbench.net/trove-newspapers/), [Trove Newspaper Harvester](https://glam-workbench.net/trove-harvester/), [NAA RecordSearch](https://glam-workbench.net/recordsearch/), & [Web Archives](https://glam-workbench.net/web-archives/). \n\n![](https://updates.timsherratt.org/uploads/2021/45605b531f.png \"Screencap showing Reclaim Cloud details\")\n\nThis means you can launch your very own version of these GLAM Workbench repositories in the cloud, where all your downloads and experiments will be saved! Find out more on the [Using Reclaim Cloud](https://glam-workbench.net/using-reclaim-cloud/) page.\n\n",
				"date_published": "2021-06-13T18:28:12+11:00",
				"url": "https://updates.timsherratt.org/2021/06/13/more-reclaim-cloud.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/06/13/get-your-glam.html",
				"title": "Get your GLAM datasets here!",
				"content_html": "<p>I‚Äôve updated my harvest of Australian GLAM datasets from state/national government open data portals. There‚Äôs now 387 datasets, containing 1049 files (including 684 CSVs). <a href=\"https://glam-workbench.net/glam-datasets-from-gov-portals/\">There‚Äôs a list</a> if you want to browse, and <a href=\"https://github.com/GLAM-Workbench/ozglam-data/blob/master/glam-datasets-from-gov-portals.csv\">a CSV file</a> if you want to download all the metadata. For more more information see the <a href=\"https://glam-workbench.net/glam-data-portals/\">data portals section</a> of the GLAM Workbench.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/ef977dfcfc.png\" alt=\"Number of datatsets by institution\" title=\"Screencap showing number of datasets per institution\" /></p>\n\n<p>If you‚Äôre interested in finding out what‚Äôs inside all those 684 CVS files, take the <a href=\"https://glam-workbench.net/csv-explorer/\">GLAM CSV Explorer</a> for a spin! It‚Äôs also been given a refresh, with new data and a new interface. #dhhacks</p>\n",
				"content_text": "I‚Äôve updated my harvest of Australian GLAM datasets from state/national government open data portals. There‚Äôs now 387 datasets, containing 1049 files (including 684 CSVs). [There‚Äôs a list](https://glam-workbench.net/glam-datasets-from-gov-portals/) if you want to browse, and [a CSV file](https://github.com/GLAM-Workbench/ozglam-data/blob/master/glam-datasets-from-gov-portals.csv) if you want to download all the metadata. For more more information see the [data portals section](https://glam-workbench.net/glam-data-portals/) of the GLAM Workbench.\n\n![Number of datatsets by institution](https://updates.timsherratt.org/uploads/2021/ef977dfcfc.png \"Screencap showing number of datasets per institution\")\n\nIf you‚Äôre interested in finding out what‚Äôs inside all those 684 CVS files, take the [GLAM CSV Explorer](https://glam-workbench.net/csv-explorer/) for a spin! It‚Äôs also been given a refresh, with new data and a new interface. #dhhacks\n\n\n",
				"date_published": "2021-06-13T18:12:37+11:00",
				"url": "https://updates.timsherratt.org/2021/06/13/get-your-glam.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/05/24/naa-recordsearch-section.html",
				"title": "NAA RecordSearch section of the GLAM Workbench updated!",
				"content_html": "\n\n<p>If you work with the collections of the National Archives of Australia, you might find the <a href=\"https://glam-workbench.net/recordsearch/\">RecordSearch section</a> of the GLAM Workbench helpful. I‚Äôve just updated the repository to add new options for running the notebooks, including 1-click installation on Reclaim Cloud. There‚Äôs also a few new notebooks.</p>\n\n<h2 id=\"new-notebooks-and-datasets\">New notebooks and datasets</h2>\n\n<ul>\n<li><a href=\"https://glam-workbench.net/recordsearch/#harvest-details-of-all-series-in-recordsearch\">Harvest details of all series in RecordSearch</a> ‚Äì get details of all series registered in RecordSearch, also generates a summary dataset with the total number of items digitised, described and in each access category</li>\n<li><a href=\"https://glam-workbench.net/recordsearch/#exploring-harvested-series-data\">Exploring harvested series data</a>  ‚Äì generates some basic statistics from the harvest of series data</li>\n<li><a href=\"https://github.com/GLAM-Workbench/recordsearch/blob/master/series_totals_May_2021.csv\">Summary data about all series in RecordSearch</a>  (15mb CSV) ‚Äì contains basic descriptive information about all the series currently registered on RecordSearch (May 2021) as well as the total number of items described, digitised, and in each access category</li>\n</ul>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/4239169ca4.png\" width=\"594\" height=\"678\" alt=\"\" /></p>\n\n<h2 id=\"updated\">Updated</h2>\n\n<p>I‚Äôve started (but not completed) updating all the notebooks in this repository to use my new <a href=\"https://wragge.github.io/recordsearch_data_scraper/\">RecordSearch Data Scraper</a>. The new scraper is simpler and more efficient, and enables me to get rid of a lot of boilerplate code. Updated notebooks include:</p>\n\n<ul>\n<li><a href=\"https://glam-workbench.net/recordsearch/#harvest-items-from-a-search-in-recordsearch\">Harvest items from a search in RecordSearch</a> ‚Äì save the results of an item search in RecordSearch as a downloadable dataset, you can also save images and PDFs from digitised files (PDF saving is new!)</li>\n<li><a href=\"https://glam-workbench.net/recordsearch/#harvest-files-with-the-access-status-of-closed\">Harvest files with the access status of ‚Äòclosed‚Äô</a> ‚Äì find out what we‚Äôre not allowed to see by harvesting details of ‚Äòclosed‚Äô files</li>\n</ul>\n\n<p>Other updates include:</p>\n\n<ul>\n<li>Python packages updated</li>\n<li>Integration with Reclaim Cloud allowing 1-click installation of the whole repository and environment</li>\n<li>Automatic creation of Docker images when the repository is updated</li>\n<li>Updated <a href=\"https://github.com/GLAM-Workbench/recordsearch#readme\">README</a> and repository index with list of all notebooks</li>\n<li>Notebooks intended to run as apps now use Voila rather than Appmode for better integration with Jupyter Lab</li>\n<li><code>requirements-unpinned.txt</code> added to repository for people who want to develop the notebooks in their own clean environment</li>\n</ul>\n\n<p>Hope you find these changes useful! #dhhacks</p>\n",
				"content_text": "If you work with the collections of the National Archives of Australia, you might find the [RecordSearch section](https://glam-workbench.net/recordsearch/) of the GLAM Workbench helpful. I‚Äôve just updated the repository to add new options for running the notebooks, including 1-click installation on Reclaim Cloud. There‚Äôs also a few new notebooks.\n\n## New notebooks and datasets\n*  [Harvest details of all series in RecordSearch](https://glam-workbench.net/recordsearch/#harvest-details-of-all-series-in-recordsearch) ‚Äì get details of all series registered in RecordSearch, also generates a summary dataset with the total number of items digitised, described and in each access category\n* [Exploring harvested series data](https://glam-workbench.net/recordsearch/#exploring-harvested-series-data)  ‚Äì generates some basic statistics from the harvest of series data\n* [Summary data about all series in RecordSearch](https://github.com/GLAM-Workbench/recordsearch/blob/master/series_totals_May_2021.csv)  (15mb CSV) ‚Äì contains basic descriptive information about all the series currently registered on RecordSearch (May 2021) as well as the total number of items described, digitised, and in each access category\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/4239169ca4.png\" width=\"594\" height=\"678\" alt=\"\" />\n\n## Updated\nI‚Äôve started (but not completed) updating all the notebooks in this repository to use my new [RecordSearch Data Scraper](https://wragge.github.io/recordsearch_data_scraper/). The new scraper is simpler and more efficient, and enables me to get rid of a lot of boilerplate code. Updated notebooks include:\n\n* [Harvest items from a search in RecordSearch](https://glam-workbench.net/recordsearch/#harvest-items-from-a-search-in-recordsearch) ‚Äì save the results of an item search in RecordSearch as a downloadable dataset, you can also save images and PDFs from digitised files (PDF saving is new!)\n* [Harvest files with the access status of ‚Äòclosed‚Äô](https://glam-workbench.net/recordsearch/#harvest-files-with-the-access-status-of-closed) ‚Äì find out what we‚Äôre not allowed to see by harvesting details of ‚Äòclosed‚Äô files\n\nOther updates include:\n\n* Python packages updated\n* Integration with Reclaim Cloud allowing 1-click installation of the whole repository and environment\n* Automatic creation of Docker images when the repository is updated\n* Updated [README](https://github.com/GLAM-Workbench/recordsearch#readme) and repository index with list of all notebooks\n* Notebooks intended to run as apps now use Voila rather than Appmode for better integration with Jupyter Lab\n* `requirements-unpinned.txt` added to repository for people who want to develop the notebooks in their own clean environment \n\nHope you find these changes useful! #dhhacks\n",
				"date_published": "2021-05-24T11:50:00+11:00",
				"url": "https://updates.timsherratt.org/2021/05/24/naa-recordsearch-section.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/05/17/web-archives-section.html",
				"title": "Web archives section of GLAM Workbench updated!",
				"content_html": "<p>My program of rolling out new features and integrations across the GLAM Workbench continues. The latest section to be updated is the <a href=\"https://glam-workbench.net/web-archives/\">Web Archives</a> section!</p>\n\n<p>There are no new notebooks with this update, but some important changes under the hood. If you haven‚Äôt used it before, the Web Archives section contains 16 notebooks providing documentation, tools, apps, and examples to help you make use of web archives in your research. The notebooks are grouped by the following topics: <strong>Types of data</strong>, <strong>Harvesting data and creating datasets</strong>, and <strong>Exploring change over time</strong>.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/51d0d97ca3.png\" width=\"721\" height=\"622\" alt=\"\" /></p>\n\n<p>I‚Äôve updated all the Python packages used in this repository and changed the app-ified notebooks to run using Voila (which is better integrated with Jupyter Lab than Appmode). But most importantly, you can now install the repository into your own persistent environment using <a href=\"https://reclaim.cloud/\">Reclaim Cloud</a> or Docker.</p>\n\n<p>As <a href=\"https://circulatingnow.nlm.nih.gov/2021/05/13/exploring-the-data-of-web-archives-as-part-of-data-science-nlm/\">Christie Moffatt noted recently</a> harvesting data from web archives can take a long time, and you might hit the limits of the free Binder service. These new integrations mean you don‚Äôt have to worry about your notebooks timing out. Just click on the <strong>Launch on Reclaim Cloud</strong> button and you can have your own fully-provisioned, persistent environment up and running in minutes!</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/bf594af78e.png\" width=\"553\" height=\"343\" alt=\"\" /></p>\n\n<p>This is possible because every change to the Web Archives repository now triggers the build of a new Docker image with all the software that you need pre-installed. You can also run this Docker image on your own computer, or using another cloud service.</p>\n\n<p>The Web Archives section now <a href=\"https://glam-workbench.net/web-archives/#run-these-notebooks\">includes documentation</a> on running the notebooks using Binder, Reclaim, Cloud or Docker. #dhhacks</p>\n",
				"content_text": "My program of rolling out new features and integrations across the GLAM Workbench continues. The latest section to be updated is the [Web Archives](https://glam-workbench.net/web-archives/) section!\n\nThere are no new notebooks with this update, but some important changes under the hood. If you haven‚Äôt used it before, the Web Archives section contains 16 notebooks providing documentation, tools, apps, and examples to help you make use of web archives in your research. The notebooks are grouped by the following topics: **Types of data**, **Harvesting data and creating datasets**, and **Exploring change over time**.\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/51d0d97ca3.png\" width=\"721\" height=\"622\" alt=\"\" />\n\nI‚Äôve updated all the Python packages used in this repository and changed the app-ified notebooks to run using Voila (which is better integrated with Jupyter Lab than Appmode). But most importantly, you can now install the repository into your own persistent environment using [Reclaim Cloud](https://reclaim.cloud/) or Docker.\n\nAs [Christie Moffatt noted recently](https://circulatingnow.nlm.nih.gov/2021/05/13/exploring-the-data-of-web-archives-as-part-of-data-science-nlm/) harvesting data from web archives can take a long time, and you might hit the limits of the free Binder service. These new integrations mean you don‚Äôt have to worry about your notebooks timing out. Just click on the **Launch on Reclaim Cloud** button and you can have your own fully-provisioned, persistent environment up and running in minutes!\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/bf594af78e.png\" width=\"553\" height=\"343\" alt=\"\" />\n\nThis is possible because every change to the Web Archives repository now triggers the build of a new Docker image with all the software that you need pre-installed. You can also run this Docker image on your own computer, or using another cloud service.\n\nThe Web Archives section now [includes documentation](https://glam-workbench.net/web-archives/#run-these-notebooks) on running the notebooks using Binder, Reclaim, Cloud or Docker. #dhhacks\n",
				"date_published": "2021-05-17T13:22:00+11:00",
				"url": "https://updates.timsherratt.org/2021/05/17/web-archives-section.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/05/12/using-web-archives.html",
				"title": "Using web archives to find out when newspapers were added to Trove",
				"content_html": "<p>There‚Äôs no doubt that Trove‚Äôs digitised newspapers have had a significant impact on the practice of history in Australia. But analysing that impact is difficult when Trove itself is always changing ‚Äì more newspapers and articles are being added all the time.</p>\n\n<p>In an attempt to chart the development of Trove, I‚Äôve created a dataset that shows (approximately) when particular newspaper titles were first added. This gives a rough snapshot of what Trove contained at any point in the last 12 years.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/a272374b48.png\" width=\"519\" height=\"242\" alt=\"\" /></p>\n\n<p>I say <em>approximately</em> because the only public source of this information are web archives like the <a href=\"https://archive.org/web/\">Internet Archive‚Äôs Wayback Machine</a> and <a href=\"https://webarchive.nla.gov.au/collection\">Trove itself</a>. By downloading <a href=\"https://web.archive.org/web/*/http://trove.nla.gov.au/ndp/del/titles\">captures of Trove‚Äôs browse page</a>, I was able to extract a list of newspaper titles available <strong>when that capture was made</strong>. Depending on the frequency of captures, the titles may have been first made available some time earlier.</p>\n\n<p>The <a href=\"https://glam-workbench.net/trove-newspapers/#gathering-historical-data-about-the-addition-of-newspaper-titles-to-trove\">method I used</a> to create the dataset is documented in the Trove Newspapers section of the GLAM Workbench. I used the Internet Archive as my source rather than Trove just because there were more captures available. Most of the code I could conveniently copy from the <a href=\"https://glam-workbench.net/web-archives/\">Web Archives</a> section of the GLAM Workbench, in particular the <a href=\"https://glam-workbench.net/web-archives/#find-all-the-archived-versions-of-a-web-page\">Find all the archived versions of a particular web page</a> notebook.</p>\n\n<p>The result was actually two datasets:</p>\n\n<ul>\n<li><a href=\"https://github.com/GLAM-Workbench/trove-newspapers/blob/master/trove_newspaper_titles_2009_2021.csv\">trove_newspaper_titles_2009_2021.csv</a>  ‚Äì complete dataset of captures and titles</li>\n<li><a href=\"https://github.com/GLAM-Workbench/trove-newspapers/blob/master/trove_newspaper_titles_first_appearance_2009_2021.csv\">trove_newspaper_titles_first_appearance_2009_2021.csv</a>  ‚Äì filtered dataset, showing only the first appearance of each title / place / date range combination</li>\n</ul>\n\n<p>There‚Äôs also an <a href=\"https://gist.github.com/wragge/7d80507c3e7957e271c572b8f664031a\">alphabetical list of newspaper titles</a> for easy browsing. The list shows the date of the capture in which the title was first recorded, as well as any changes to its date range. #dhhacks</p>\n",
				"content_text": "There‚Äôs no doubt that Trove‚Äôs digitised newspapers have had a significant impact on the practice of history in Australia. But analysing that impact is difficult when Trove itself is always changing ‚Äì more newspapers and articles are being added all the time.\n\nIn an attempt to chart the development of Trove, I‚Äôve created a dataset that shows (approximately) when particular newspaper titles were first added. This gives a rough snapshot of what Trove contained at any point in the last 12 years.\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/a272374b48.png\" width=\"519\" height=\"242\" alt=\"\" />\n\nI say *approximately* because the only public source of this information are web archives like the [Internet Archive‚Äôs Wayback Machine](https://archive.org/web/) and [Trove itself](https://webarchive.nla.gov.au/collection). By downloading [captures of Trove‚Äôs browse page](https://web.archive.org/web/*/http://trove.nla.gov.au/ndp/del/titles), I was able to extract a list of newspaper titles available **when that capture was made**. Depending on the frequency of captures, the titles may have been first made available some time earlier.\n\nThe [method I used](https://glam-workbench.net/trove-newspapers/#gathering-historical-data-about-the-addition-of-newspaper-titles-to-trove) to create the dataset is documented in the Trove Newspapers section of the GLAM Workbench. I used the Internet Archive as my source rather than Trove just because there were more captures available. Most of the code I could conveniently copy from the [Web Archives](https://glam-workbench.net/web-archives/) section of the GLAM Workbench, in particular the [Find all the archived versions of a particular web page](https://glam-workbench.net/web-archives/#find-all-the-archived-versions-of-a-web-page) notebook.\n\nThe result was actually two datasets:\n\n*  [trove_newspaper\\_titles\\_2009\\_2021.csv](https://github.com/GLAM-Workbench/trove-newspapers/blob/master/trove_newspaper_titles_2009_2021.csv)  ‚Äì complete dataset of captures and titles\n*  [trove\\_newspaper\\_titles\\_first\\_appearance\\_2009\\_2021.csv](https://github.com/GLAM-Workbench/trove-newspapers/blob/master/trove_newspaper_titles_first_appearance_2009_2021.csv)  ‚Äì filtered dataset, showing only the first appearance of each title / place / date range combination\n\nThere‚Äôs also an [alphabetical list of newspaper titles](https://gist.github.com/wragge/7d80507c3e7957e271c572b8f664031a) for easy browsing. The list shows the date of the capture in which the title was first recorded, as well as any changes to its date range. #dhhacks\n",
				"date_published": "2021-05-12T12:36:00+11:00",
				"url": "https://updates.timsherratt.org/2021/05/12/using-web-archives.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/05/12/glam-jupyter-resources.html",
				"title": "GLAM Jupyter Resources",
				"content_html": "<p>To make it easier for people to suggest additions, I‚Äôve created a <a href=\"https://github.com/GLAM-Workbench/GLAM-jupyter-resources\">GitHub repository</a> for my list of GLAM Jupyter examples and resources. Contributions are welcome!</p>\n\n<p>This list is automatically pulled into the <a href=\"https://glam-workbench.net/more-glam-notebooks/\">GLAM Workbench&rsquo;s help documentation</a>. #dhhacks</p>\n",
				"content_text": "To make it easier for people to suggest additions, I‚Äôve created a [GitHub repository](https://github.com/GLAM-Workbench/GLAM-jupyter-resources) for my list of GLAM Jupyter examples and resources. Contributions are welcome!\n\nThis list is automatically pulled into the [GLAM Workbench's help documentation](https://glam-workbench.net/more-glam-notebooks/). #dhhacks\n",
				"date_published": "2021-05-12T11:58:29+11:00",
				"url": "https://updates.timsherratt.org/2021/05/12/glam-jupyter-resources.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/05/12/running-notebooks-a.html",
				"title": "Running notebooks ‚Äì a sign of things to come in the GLAM Workbench",
				"content_html": "<p>I recently made some changes in the GLAM Workbench‚Äôs Help documentation, adding a new <strong>Running notebooks</strong> section. This section provides detailed information of running and managing GLAM Workbench repositories using <a href=\"https://glam-workbench.net/using-reclaim-cloud/\">Reclaim Cloud</a> and <a href=\"https://glam-workbench.net/using-docker/\">Docker</a>.</p>\n\n<p>I‚Äôm still rolling out this functionality across all the repositories, but it‚Äôs going to take a while. When I‚Äôm finished you‚Äôll be able to create your own persistent environment on Reclaim Cloud from any repository with just the click of a button. See the <a href=\"https://glam-workbench.net/trove-newspapers/\">Trove Newspapers</a> section to try this out now! #dhhacks</p>\n",
				"content_text": "I recently made some changes in the GLAM Workbench‚Äôs Help documentation, adding a new **Running notebooks** section. This section provides detailed information of running and managing GLAM Workbench repositories using [Reclaim Cloud](https://glam-workbench.net/using-reclaim-cloud/) and [Docker](https://glam-workbench.net/using-docker/).\n\nI‚Äôm still rolling out this functionality across all the repositories, but it‚Äôs going to take a while. When I‚Äôm finished you‚Äôll be able to create your own persistent environment on Reclaim Cloud from any repository with just the click of a button. See the [Trove Newspapers](https://glam-workbench.net/trove-newspapers/) section to try this out now! #dhhacks\n",
				"date_published": "2021-05-12T11:51:11+11:00",
				"url": "https://updates.timsherratt.org/2021/05/12/running-notebooks-a.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/05/12/sponsor-my-work.html",
				"title": "Sponsor my work on GitHub!",
				"content_html": "<p>As I <a href=\"https://updates.timsherratt.org/2021/03/26/moving-on-from.html\">foreshadowed some weeks ago</a>, I‚Äôve shut down my Patreon page. Thanks to everyone who has supported me there over the last few years!</p>\n\n<p>I‚Äôve now shifted across to GitHub Sponsors, which is focused on supporting open source projects. This seems like a much better fit for the things that I do, which are all <strong>free</strong> and <strong>open</strong> by default.</p>\n\n<p>So if you think things like the <a href=\"https://glam-workbench.net/\">GLAM Workbench</a>, <a href=\"https://historichansard.net/\">Historic Hansard</a>, <a href=\"https://ozglam.chat/\">OzGLAM Help</a>, and <a href=\"https://www.realfaceofwhiteaustralia.net/\">The Real Face of White Australia</a> are worth supporting, you can sign up using my <a href=\"https://github.com/sponsors/wragge?o=esb\"><strong>GitHub Sponsors page</strong></a>. Sponsorship tiers start at just $1 a month. Financially, your contributions help pay some of my cloud hosting bills and keep everything online. But just as important is the encouragement and motivation I get from knowing that there are people out there who think this work is important and useful.</p>\n\n<iframe src=\"https://github.com/sponsors/wragge/card\" title=\"Sponsor wragge\" height=\"225\" width=\"600\" style=\"border: 0;\"></iframe>\n\n<p>To recognise my GitHub sponsors, I&rsquo;ve also created a <a href=\"https://glam-workbench.net/supporters/\">new Supporters page</a> in the GLAM Workbench.</p>\n\n<p>Thanks!</p>\n",
				"content_text": "As I [foreshadowed some weeks ago](https://updates.timsherratt.org/2021/03/26/moving-on-from.html), I‚Äôve shut down my Patreon page. Thanks to everyone who has supported me there over the last few years!\n\nI‚Äôve now shifted across to GitHub Sponsors, which is focused on supporting open source projects. This seems like a much better fit for the things that I do, which are all **free** and **open** by default.\n\nSo if you think things like the [GLAM Workbench](https://glam-workbench.net/), [Historic Hansard](https://historichansard.net/), [OzGLAM Help](https://ozglam.chat/), and [The Real Face of White Australia](https://www.realfaceofwhiteaustralia.net/) are worth supporting, you can sign up using my [**GitHub Sponsors page**](https://github.com/sponsors/wragge?o=esb). Sponsorship tiers start at just $1 a month. Financially, your contributions help pay some of my cloud hosting bills and keep everything online. But just as important is the encouragement and motivation I get from knowing that there are people out there who think this work is important and useful.\n\n<iframe src=\"https://github.com/sponsors/wragge/card\" title=\"Sponsor wragge\" height=\"225\" width=\"600\" style=\"border: 0;\"></iframe>\n\nTo recognise my GitHub sponsors, I've also created a [new Supporters page](https://glam-workbench.net/supporters/) in the GLAM Workbench. \n\nThanks!\n",
				"date_published": "2021-05-12T11:25:00+11:00",
				"url": "https://updates.timsherratt.org/2021/05/12/sponsor-my-work.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/05/12/updates-to-the.html",
				"title": "Updates to the Trove Newspapers section of GLAM Workbench",
				"content_html": "<p>I‚Äôve updated, refreshed, and reorganised the <a href=\"https://glam-workbench.net/trove-newspapers/\">Trove newspapers section</a> of the GLAM Workbench.  There‚Äôs currently 22 Jupyter notebooks organised under the following headings:</p>\n\n<ul>\n<li><a href=\"https://glam-workbench.net/trove-newspapers/#trove-newspapers-in-context\"><strong>Trove newspapers in context</strong></a> ‚Äì Notebooks in this section look at the Trove newspaper corpus as a whole, to try and understand what‚Äôs there, and what‚Äôs not.</li>\n<li><a href=\"https://glam-workbench.net/trove-newspapers/#visualising-searches\"><strong>Visualising searches</strong></a> ‚Äì Notebooks in this section demonstrate some ways of visualising searches in Trove newspapers ‚Äì seeing everything rather than just a list of search results.</li>\n<li><a href=\"https://glam-workbench.net/trove-newspapers/#useful-tools\"><strong>Useful tools</strong></a> ‚Äì Notebooks in this section provide useful tools that extend or enhance the Trove web interface and API.</li>\n<li><a href=\"https://glam-workbench.net/trove-newspapers/#tips-and-tricks\"><strong>Tips and tricks</strong></a> ‚Äì Notebooks in this section provide some useful hints to use with the Trove API.</li>\n<li><a href=\"https://glam-workbench.net/trove-newspapers/#get-creative\"><strong>Get creative</strong></a> ‚Äì Notebooks in this section look at ways you can use data from Trove newspapers in creative ways.</li>\n</ul>\n\n<p>There‚Äôs also a number of pre-harvested datasets.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/78c376493d.png\" width=\"702\" height=\"550\" alt=\"\" /></p>\n\n<p>Recently refreshed analyses, visualisations, and datasets include:</p>\n\n<ul>\n<li><a href=\"https://nbviewer.jupyter.org/github/GLAM-Workbench/trove-newspapers/blob/master/visualise-total-newspaper-articles-by-state-year.ipynb\">Number of Trove newspaper articles by year and state</a> (notebook)</li>\n<li><a href=\"https://nbviewer.jupyter.org/github/GLAM-Workbench/trove-newspapers/blob/master/Analysing_OCR_corrections.ipynb\">Analysing OCR correction in Trove‚Äôs newspapers</a> (notebook)</li>\n<li><a href=\"https://gist.github.com/wragge/9aa385648cff5f0de0c7d4837896df97\">List of Trove newspapers in languages other than English</a> (markdown formatted list)</li>\n<li><a href=\"https://github.com/GLAM-Workbench/trove-newspapers/blob/master/newspapers_post_54.csv\">Newspapers with content from beyond the 1954 copyright ‚Äòcliff of death‚Äô</a> (CSV file)</li>\n</ul>\n\n<p>As part of the update, notebooks that are intended to run as apps (with all the code hidden) have been updated to use Voila. But perhaps the thing I‚Äôm most excited about are the new options for <strong>running</strong> the notebooks. As well as being able to launch the notebooks on Binder, you can now create your very own, <strong>persistent</strong> environment on Reclaim Cloud with just a click of a button.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/c39e0d2441.png\" width=\"532\" height=\"337\" alt=\"\" /></p>\n\n<p>There‚Äôs also an automatically-built Docker image of this repository, containing everything you need to run the notebooks on your own computer. Check out the new <a href=\"https://glam-workbench.net/trove-newspapers/#run-these-notebooks\">Run these notebooks</a>  section for details. I‚Äôm gradually rolling this out across all the repositories in the GLAM Workbench. #dhhacks</p>\n",
				"content_text": "I‚Äôve updated, refreshed, and reorganised the [Trove newspapers section](https://glam-workbench.net/trove-newspapers/) of the GLAM Workbench.  There‚Äôs currently 22 Jupyter notebooks organised under the following headings:\n\n* [**Trove newspapers in context**](https://glam-workbench.net/trove-newspapers/#trove-newspapers-in-context) ‚Äì Notebooks in this section look at the Trove newspaper corpus as a whole, to try and understand what‚Äôs there, and what‚Äôs not.\n* [**Visualising searches**](https://glam-workbench.net/trove-newspapers/#visualising-searches) ‚Äì Notebooks in this section demonstrate some ways of visualising searches in Trove newspapers ‚Äì seeing everything rather than just a list of search results.\n* [**Useful tools**](https://glam-workbench.net/trove-newspapers/#useful-tools) ‚Äì Notebooks in this section provide useful tools that extend or enhance the Trove web interface and API.\n* [**Tips and tricks**](https://glam-workbench.net/trove-newspapers/#tips-and-tricks) ‚Äì Notebooks in this section provide some useful hints to use with the Trove API.\n* [**Get creative**](https://glam-workbench.net/trove-newspapers/#get-creative) ‚Äì Notebooks in this section look at ways you can use data from Trove newspapers in creative ways.\n\nThere‚Äôs also a number of pre-harvested datasets.\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/78c376493d.png\" width=\"702\" height=\"550\" alt=\"\" />\n\nRecently refreshed analyses, visualisations, and datasets include:\n\n* [Number of Trove newspaper articles by year and state](https://nbviewer.jupyter.org/github/GLAM-Workbench/trove-newspapers/blob/master/visualise-total-newspaper-articles-by-state-year.ipynb) (notebook)\n* [Analysing OCR correction in Trove‚Äôs newspapers](https://nbviewer.jupyter.org/github/GLAM-Workbench/trove-newspapers/blob/master/Analysing_OCR_corrections.ipynb) (notebook)\n* [List of Trove newspapers in languages other than English](https://gist.github.com/wragge/9aa385648cff5f0de0c7d4837896df97) (markdown formatted list)\n* [Newspapers with content from beyond the 1954 copyright ‚Äòcliff of death‚Äô](https://github.com/GLAM-Workbench/trove-newspapers/blob/master/newspapers_post_54.csv) (CSV file)\n\nAs part of the update, notebooks that are intended to run as apps (with all the code hidden) have been updated to use Voila. But perhaps the thing I‚Äôm most excited about are the new options for **running** the notebooks. As well as being able to launch the notebooks on Binder, you can now create your very own, **persistent** environment on Reclaim Cloud with just a click of a button. \n\n<img src=\"https://updates.timsherratt.org/uploads/2021/c39e0d2441.png\" width=\"532\" height=\"337\" alt=\"\" />\n\nThere‚Äôs also an automatically-built Docker image of this repository, containing everything you need to run the notebooks on your own computer. Check out the new [Run these notebooks](https://glam-workbench.net/trove-newspapers/#run-these-notebooks)  section for details. I‚Äôm gradually rolling this out across all the repositories in the GLAM Workbench. #dhhacks \n\n\n\n\n\n",
				"date_published": "2021-05-12T10:52:00+11:00",
				"url": "https://updates.timsherratt.org/2021/05/12/updates-to-the.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/04/27/introducing-the-new.html",
				"title": "Introducing the new, improved RecordSearch Data Scraper!",
				"content_html": "<p>It was way back in 2009 that I created <a href=\"http://discontents.com.au/some-archives-hacking/\">my first scraper</a> for getting machine-readable data out of the National Archives of Australia&rsquo;s online database, RecordSearch. Since then I‚Äôve used versions of this scraper in a number of different projects such as <a href=\"https://www.realfaceofwhiteaustralia.net/\">The Real Face of White Australia</a>, <a href=\"https://closedaccess.herokuapp.com/\">Closed Access</a>, and <a href=\"https://owebrowse.herokuapp.com/redactions/\">Redacted</a> (including the <a href=\"https://updates.timsherratt.org/2021/04/21/secrets-and-lives.html\">recent update</a>). The scraper is also embedded in many of the notebooks that I‚Äôve created for the <a href=\"https://glam-workbench.net/recordsearch/\">RecordSearch section</a> of the GLAM Workbench.</p>\n\n<p>However, the scraper was showing its age. The main problem was that one of its dependencies, Robobrowser, is no longer maintained. This made it difficult to update. I&rsquo;d put off a major rewrite, thinking that RecordSearch itself might be getting a much-needed overhaul, but I could wait no longer. Introducing the brand new <a href=\"https://github.com/wragge/recordsearch_data_scraper\">RecordSearch Data Scraper</a>.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/ab67b3d0c3.png\" width=\"806\" height=\"422\" alt=\"\" /></p>\n\n<p>Just like the old version, the new scraper delivers machine-readable data relating to Items, Series and Agencies ‚Äì both from individual records, and search results. It also adds a little extra to the basic metadata, for example, if an Item is digitised, the data includes the number of pages in the file. Series records can include the number of digitised files, and the breakdown of files by access category.</p>\n\n<p>The new scraper adds in some additional search parameters for Series and Agencies. It also makes use of a simple caching system to improve speed and efficiency.  RecordSearch makes use of an odd assortment of sessions, redirects, and hidden forms, which make scraping a challenge. Hopefully I‚Äôve nailed down the idiosyncrasies, but I expect to catching bugs for a while.</p>\n\n<p>I created the new scraper in Jupyter using <a href=\"https://github.com/fastai/nbdev\">NBDev</a>. NBDev helps you to keep your code, examples, tests, and documentation all together in Jupyter notebooks. When you&rsquo;re ready, it converts the code from the notebooks  into distributable Python libraries, runs all your tests, and builds a <a href=\"https://wragge.github.io/recordsearch_data_scraper/\">documentation site</a>. It‚Äôs very cool.</p>\n\n<p>Having updated the scraper, I now need to update the notebooks in the GLAM Workbench ‚Äì more on that soon. The maintenance never ends! #dhhacks</p>\n",
				"content_text": "It was way back in 2009 that I created [my first scraper](http://discontents.com.au/some-archives-hacking/) for getting machine-readable data out of the National Archives of Australia's online database, RecordSearch. Since then I‚Äôve used versions of this scraper in a number of different projects such as [The Real Face of White Australia](https://www.realfaceofwhiteaustralia.net/), [Closed Access](https://closedaccess.herokuapp.com/), and [Redacted](https://owebrowse.herokuapp.com/redactions/) (including the [recent update](https://updates.timsherratt.org/2021/04/21/secrets-and-lives.html)). The scraper is also embedded in many of the notebooks that I‚Äôve created for the [RecordSearch section](https://glam-workbench.net/recordsearch/) of the GLAM Workbench.\n\nHowever, the scraper was showing its age. The main problem was that one of its dependencies, Robobrowser, is no longer maintained. This made it difficult to update. I'd put off a major rewrite, thinking that RecordSearch itself might be getting a much-needed overhaul, but I could wait no longer. Introducing the brand new [RecordSearch Data Scraper](https://github.com/wragge/recordsearch_data_scraper).\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/ab67b3d0c3.png\" width=\"806\" height=\"422\" alt=\"\" />\n\nJust like the old version, the new scraper delivers machine-readable data relating to Items, Series and Agencies ‚Äì both from individual records, and search results. It also adds a little extra to the basic metadata, for example, if an Item is digitised, the data includes the number of pages in the file. Series records can include the number of digitised files, and the breakdown of files by access category. \n\nThe new scraper adds in some additional search parameters for Series and Agencies. It also makes use of a simple caching system to improve speed and efficiency.  RecordSearch makes use of an odd assortment of sessions, redirects, and hidden forms, which make scraping a challenge. Hopefully I‚Äôve nailed down the idiosyncrasies, but I expect to catching bugs for a while.\n\nI created the new scraper in Jupyter using [NBDev](https://github.com/fastai/nbdev). NBDev helps you to keep your code, examples, tests, and documentation all together in Jupyter notebooks. When you're ready, it converts the code from the notebooks  into distributable Python libraries, runs all your tests, and builds a [documentation site](https://wragge.github.io/recordsearch_data_scraper/). It‚Äôs very cool.\n\nHaving updated the scraper, I now need to update the notebooks in the GLAM Workbench ‚Äì more on that soon. The maintenance never ends! #dhhacks\n",
				"date_published": "2021-04-27T10:55:00+11:00",
				"url": "https://updates.timsherratt.org/2021/04/27/introducing-the-new.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/04/21/secrets-and-lives.html",
				"title": "Secrets and lives",
				"content_html": "<p>Here‚Äôs the video of my presentation, ‚ÄòSecrets and lies‚Äô, for the (Re)create symposium at the University of Canberra, 21 April 2021. It‚Äôs mainly about finding and resting redactions in ASIO surveillance files held by the National Archives of Australia.</p>\n\n<p><iframe src=\"https://player.vimeo.com/video/538994726\" width=\"640\" height=\"360\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen></iframe>\n<p><a href=\"https://vimeo.com/538994726\">Secrets and lives</a> from <a href=\"https://vimeo.com/wragge\">Tim Sherratt</a> on <a href=\"https://vimeo.com\">Vimeo</a>.</p></p>\n\n<p>Here are links to the various sites and resources mentioned in the video:</p>\n\n<ul>\n<li>For more on records relating to the White Australia policy see <a href=\"https://www.realfaceofwhiteaustralia.net/\">The Real Face of White Australia</a></li>\n<li>Some <a href=\"https://glam-workbench.net/naa-asio/\">summary information</a> on ASIO records in the National Archives of Australia</li>\n<li>Jenny Holzer‚Äôs <a href=\"https://projects.jennyholzer.com/exhibitions/jenny-holzer-mass-moca--\">Mass MoCA exhibition</a>, including redaction paintings</li>\n<li><a href=\"https://politics.theonion.com/cia-realizes-its-been-using-black-highlighters-all-thes-1819568147\">CIA Realizes It‚Äôs Been Using Black Highlighters All These Years</a>, <em>The Onion</em>, 2005</li>\n<li><a href=\"https://trove.nla.gov.au/list/78998\">Fun with the Petrovs</a>, a Trove list that brings together photos from ASIO files in the NAA</li>\n<li><a href=\"https://www.muckrock.com/foiafacelift/\">FOIA Facelift</a>, <em>MuckRock</em>, 2020</li>\n<li><a href=\"https://www.muckrock.com/news/archives/2016/mar/14/muckrocks-redaction-hall-shame/\">Redaction Hall of Shame</a>, <em>MuckRock</em>, 2016</li>\n<li><a href=\"https://insidestory.org.au/withheld-pending-advice/\">Withheld Pending Advice</a>, <em>Inside Story</em>, 2017, looks at ‚Äòclosed‚Äô files in the NAA; the 2020 update is in <a href=\"https://twitter.com/wragge/status/1344805120261832705\">this Twitter thread</a></li>\n<li><a href=\"https://owebrowse.herokuapp.com/redactions/\">redacted</a>, 2017 ‚Äì browse my original collection of redactions</li>\n<li>The original #redactionart story, 2016-2017 ‚Äì <a href=\"https://wakelet.com/wake/e73ec48b-8a80-4678-8e53-b523e0601c39\">part 1</a> and <a href=\"https://wakelet.com/wake/b97e6ef7-174a-4b0b-aba2-a9229123add4\">part 2</a></li>\n<li><a href=\"https://vimeo.com/wragge/redactionart\">The Redaction Zoo</a>, 2017</li>\n<li><a href=\"https://github.com/wragge/diy-redactionart\">DIY #redactionart</a> , 2017 ‚Äì repository of images</li>\n<li>Edward Shaddow‚Äôs <a href=\"https://www.thingiverse.com/thing:2379810\">#redactionart cookie cutters</a></li>\n<li><a href=\"https://youtu.be/XhTzE67HrhE\">Wearing access</a>, 2018, talk by  Bonnie Wildie describing the creation of her #redactionart dress</li>\n<li><a href=\"https://www.jigsawexplorer.com/online-jigsaw-puzzle-player.html?url=aHR0cHM6Ly9kbC5kcm9wYm94LmNvbS9zL3I2MnRtMWp4OGtpNjZ5eC9yZWRhY3Rpb25zLmpwZw~~&amp;cred=UmVkYWN0aW9ucyBleHRyYWN0ZWQgZnJvbSBBU0lPIHN1cnZlaWxsYW5jZSBmaWxlcyBpbiB0aGUgTmF0aW9uYWwgQXJjaGl2ZXMgb2YgQXVzdHJhbGlh&amp;credu=aHR0cHM6Ly9vd2Vicm93c2UuaGVyb2t1YXBwLmNvbS9yZWRhY3Rpb25zLw~~&amp;nop=200&amp;color=charcoal\">#redactionart jigsaw</a></li>\n<li>Some <a href=\"https://twitter.com/wragge/status/1377491548762370049\">new #redactionart critters</a>, 2021</li>\n<li><a href=\"https://www.redbubble.com/i/notebook/Keep-your-secrets-safe-with-redactionart-by-wragge/76361765.RXH2R\">#redactionart hardcover journal</a>, 2021, Redbubble</li>\n<li><a href=\"https://www.redbubble.com/i/duvet-cover/Sleep-soundly-in-secret-with-redactionart-by-wragge/75032324.XWIXB\">#redactionart quilt cover</a>, 2021, Redbubble</li>\n<li><a href=\"https://www.redbubble.com/i/scarf/Step-out-in-secret-with-redactionart-by-wragge/75038934.B15PI\">#redactionart scarf</a>, 2021, Redbubble</li>\n<li><a href=\"https://mybinder.org/v2/gh/GLAM-Workbench/recordsearch/HEAD?urlpath=voila%2Frender%2Fdiy_redaction_collage.ipynb\">DIY #redactionart collage</a> ‚Äì make your own collages of recycled ASIO redactions (includes at least one redaction art critter)</li>\n</ul>\n\n<p>I haven‚Äôt yet written up the details of training my latest redaction finder. When I do, I‚Äôll post it here! #dhhacks</p>\n",
				"content_text": "Here‚Äôs the video of my presentation, ‚ÄòSecrets and lies‚Äô, for the (Re)create symposium at the University of Canberra, 21 April 2021. It‚Äôs mainly about finding and resting redactions in ASIO surveillance files held by the National Archives of Australia.\n\n<iframe src=\"https://player.vimeo.com/video/538994726\" width=\"640\" height=\"360\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen></iframe>\n<p><a href=\"https://vimeo.com/538994726\">Secrets and lives</a> from <a href=\"https://vimeo.com/wragge\">Tim Sherratt</a> on <a href=\"https://vimeo.com\">Vimeo</a>.</p>\n\nHere are links to the various sites and resources mentioned in the video:\n\n* For more on records relating to the White Australia policy see [The Real Face of White Australia](https://www.realfaceofwhiteaustralia.net/)\n* Some [summary information](https://glam-workbench.net/naa-asio/) on ASIO records in the National Archives of Australia\n* Jenny Holzer‚Äôs [Mass MoCA exhibition](https://projects.jennyholzer.com/exhibitions/jenny-holzer-mass-moca--), including redaction paintings\n* [CIA Realizes It‚Äôs Been Using Black Highlighters All These Years](https://politics.theonion.com/cia-realizes-its-been-using-black-highlighters-all-thes-1819568147), *The Onion*, 2005\n* [Fun with the Petrovs](https://trove.nla.gov.au/list/78998), a Trove list that brings together photos from ASIO files in the NAA\n* [FOIA Facelift](https://www.muckrock.com/foiafacelift/), *MuckRock*, 2020\n* [Redaction Hall of Shame](https://www.muckrock.com/news/archives/2016/mar/14/muckrocks-redaction-hall-shame/), *MuckRock*, 2016\n* [Withheld Pending Advice](https://insidestory.org.au/withheld-pending-advice/), *Inside Story*, 2017, looks at ‚Äòclosed‚Äô files in the NAA; the 2020 update is in [this Twitter thread](https://twitter.com/wragge/status/1344805120261832705)\n* [redacted](https://owebrowse.herokuapp.com/redactions/), 2017 ‚Äì browse my original collection of redactions\n* The original \\#redactionart story, 2016-2017 ‚Äì [part 1](https://wakelet.com/wake/e73ec48b-8a80-4678-8e53-b523e0601c39) and [part 2](https://wakelet.com/wake/b97e6ef7-174a-4b0b-aba2-a9229123add4)\n* [The Redaction Zoo](https://vimeo.com/wragge/redactionart), 2017\n* [DIY \\#redactionart](https://github.com/wragge/diy-redactionart) , 2017 ‚Äì repository of images\n* Edward Shaddow‚Äôs [\\#redactionart cookie cutters](https://www.thingiverse.com/thing:2379810)\n* [Wearing access](https://youtu.be/XhTzE67HrhE), 2018, talk by  Bonnie Wildie describing the creation of her \\#redactionart dress\n* [\\#redactionart jigsaw](https://www.jigsawexplorer.com/online-jigsaw-puzzle-player.html?url=aHR0cHM6Ly9kbC5kcm9wYm94LmNvbS9zL3I2MnRtMWp4OGtpNjZ5eC9yZWRhY3Rpb25zLmpwZw~~&cred=UmVkYWN0aW9ucyBleHRyYWN0ZWQgZnJvbSBBU0lPIHN1cnZlaWxsYW5jZSBmaWxlcyBpbiB0aGUgTmF0aW9uYWwgQXJjaGl2ZXMgb2YgQXVzdHJhbGlh&credu=aHR0cHM6Ly9vd2Vicm93c2UuaGVyb2t1YXBwLmNvbS9yZWRhY3Rpb25zLw~~&nop=200&color=charcoal)\n* Some [new \\#redactionart critters](https://twitter.com/wragge/status/1377491548762370049), 2021\n* [\\#redactionart hardcover journal](https://www.redbubble.com/i/notebook/Keep-your-secrets-safe-with-redactionart-by-wragge/76361765.RXH2R), 2021, Redbubble\n* [\\#redactionart quilt cover](https://www.redbubble.com/i/duvet-cover/Sleep-soundly-in-secret-with-redactionart-by-wragge/75032324.XWIXB), 2021, Redbubble\n* [\\#redactionart scarf](https://www.redbubble.com/i/scarf/Step-out-in-secret-with-redactionart-by-wragge/75038934.B15PI), 2021, Redbubble\n* [DIY \\#redactionart collage](https://mybinder.org/v2/gh/GLAM-Workbench/recordsearch/HEAD?urlpath=voila%2Frender%2Fdiy_redaction_collage.ipynb) ‚Äì make your own collages of recycled ASIO redactions (includes at least one redaction art critter)\n\nI haven‚Äôt yet written up the details of training my latest redaction finder. When I do, I‚Äôll post it here! #dhhacks\n",
				"date_published": "2021-04-21T11:02:52+11:00",
				"url": "https://updates.timsherratt.org/2021/04/21/secrets-and-lives.html"
			},
			{
				"id": "http://wragge.micro.blog/2021/03/29/recently-digitised-files.html",
				"title": "Recently digitised files in the National Archives of Australia",
				"content_html": "<p>I‚Äôm interested in understanding what gets digitised and when by our cultural institutions, but accessible data is scarce. The National Archives of Australia lists ‚Äònewly scanned&rsquo; records in RecordSearch, so I thought I‚Äôd see if I could convert that list into a machine-readable form for analysis. I‚Äôve had a lot of experience trying to <a href=\"https://glam-workbench.github.io/recordsearch/\">get data out of RecordSearch</a>, but even so it took me a while to figure out how the ‚Äònewly scanned‚Äô page worked. Eventually I was able to extract all the file metadata from the list and save it to a CSV file. The details are in <a href=\"https://glam-workbench.github.io/recordsearch/#harvest-recently-digitised-files-from-recordsearch\">this notebook in the GLAM Workbench</a>.</p>\n\n<p>I used the code to create a dataset of <a href=\"https://github.com/GLAM-Workbench/recordsearch/blob/master/data/recently-digitised-20210327\">all the files digitised in the past month</a>. The ‚Äònewly scanned&rsquo; list only displays a month&rsquo;s worth of additions, so that&rsquo;s as much as I could get in one hit. In the past month, 24,039 files were digitised. 22,500 of these (about 93%) come from just four series of military records. This is no surprise, as the NAA is currently undertaking a major project to digitise WW2 service records. What is perhaps more interesting is the long tail of series from which a small number of files were digitised. 357 of the 375 series represented in the dataset (about 95%) appear 20 or fewer times. 210 series have had only one file digitised in the last month. I‚Äôm assuming that this diversity represents research interests, refracted through the digitisation on demand  service. But this really needs more data, and more analysis.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/53a63e0de5.jpg\" width=\"600\" height=\"266\" alt=\"\" /></p>\n\n<p>As I mentioned, only one month&rsquo;s data is available from RecordSearch at any time. To try and capture a longer record of the digitisation process, I‚Äôve set up an automated <a href=\"https://simonwillison.net/2020/Oct/9/git-scraping/\">‚Äògit scraper‚Äô</a> that runs every Sunday and captures metadata of all the files digitised in the preceding week. The weekly datasets are saved as CSV files in a <a href=\"https://github.com/wragge/naa-recently-digitised\">public GitHub repository</a>. Over time, this should become a useful dataset for exploring long-term patterns in digitisation. #dhhacks</p>\n",
				"content_text": "I‚Äôm interested in understanding what gets digitised and when by our cultural institutions, but accessible data is scarce. The National Archives of Australia lists ‚Äònewly scanned' records in RecordSearch, so I thought I‚Äôd see if I could convert that list into a machine-readable form for analysis. I‚Äôve had a lot of experience trying to [get data out of RecordSearch](https://glam-workbench.github.io/recordsearch/), but even so it took me a while to figure out how the ‚Äònewly scanned‚Äô page worked. Eventually I was able to extract all the file metadata from the list and save it to a CSV file. The details are in [this notebook in the GLAM Workbench](https://glam-workbench.github.io/recordsearch/#harvest-recently-digitised-files-from-recordsearch).\n\nI used the code to create a dataset of [all the files digitised in the past month](https://github.com/GLAM-Workbench/recordsearch/blob/master/data/recently-digitised-20210327). The ‚Äònewly scanned' list only displays a month's worth of additions, so that's as much as I could get in one hit. In the past month, 24,039 files were digitised. 22,500 of these (about 93%) come from just four series of military records. This is no surprise, as the NAA is currently undertaking a major project to digitise WW2 service records. What is perhaps more interesting is the long tail of series from which a small number of files were digitised. 357 of the 375 series represented in the dataset (about 95%) appear 20 or fewer times. 210 series have had only one file digitised in the last month. I‚Äôm assuming that this diversity represents research interests, refracted through the digitisation on demand  service. But this really needs more data, and more analysis.\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/53a63e0de5.jpg\" width=\"600\" height=\"266\" alt=\"\" />\n\nAs I mentioned, only one month's data is available from RecordSearch at any time. To try and capture a longer record of the digitisation process, I‚Äôve set up an automated [‚Äògit scraper‚Äô](https://simonwillison.net/2020/Oct/9/git-scraping/) that runs every Sunday and captures metadata of all the files digitised in the preceding week. The weekly datasets are saved as CSV files in a [public GitHub repository](https://github.com/wragge/naa-recently-digitised). Over time, this should become a useful dataset for exploring long-term patterns in digitisation. #dhhacks\n",
				"date_published": "2021-03-29T10:00:00+11:00",
				"url": "https://updates.timsherratt.org/2021/03/29/recently-digitised-files.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/03/26/moving-on-from.html",
				"title": "Moving on from Patreon...",
				"content_html": "\n\n<p>Over the last few years, I&rsquo;ve been very grateful for the support of my Patreon subscribers. Financially, their contributions have helped me cover a substantial proportion of the cloud hosting costs associated with projects like <a href=\"https://historichansard.net/\">Historic Hansard</a> and <a href=\"https://www.realfaceofwhiteaustralia.net/\">The Real Face of White Australia</a>. But, more importantly, just knowing that they thought my work was of value has helped keep me going, and inspired me to develop a range of new resources.</p>\n\n<p>However, while I&rsquo;ve been grateful for the platform provided by Patreon, I&rsquo;ve increasingly felt that it&rsquo;s not a good fit for the sort of work I do. Patreon is geared towards providing special content to supporters, but, as you know, all my work is open. And that&rsquo;s really important to me.</p>\n\n<p>Recently GitHub opened up its own sponsorship program for the development of open source software. This program seems to align more closely with what I do. I already share and manage my code through GitHub, so integrating sponsorship seems to make a lot of sense. It&rsquo;s worth noting too, that, unlike Patreon, GitHub charges no fees and takes no cut of your contributions. As a result I&rsquo;ve decided to close my Patreon account by the end of April, and create a GitHub sponsors page.</p>\n\n<h2 id=\"what-does-this-mean-for-you\">What does this mean for you?</h2>\n\n<p><strong>If you&rsquo;re a Patreon subscriber and you&rsquo;d like to keep supporting me</strong>, you should cancel your Patreon contribution, then head over to my brand new <a href=\"https://github.com/sponsors/wragge\"><strong>GitHub sponsors page</strong></a> and sign up! Thanks for your continued support!</p>\n\n<p><strong>If you&rsquo;d prefer to let your contributions lapse</strong>, just do nothing. Your payments will stop when I close the account at the end of April. I understand that circumstances change ‚Äì thank you so much for your support over the years, and I hope you will continue to make use of the things I create.</p>\n\n<p><strong>If you make use of any of my tools or resources and would like to support their continued development</strong>, please think about <a href=\"https://github.com/sponsors/wragge\">becoming a sponsor</a>. For a sample of the sorts of things I&rsquo;ve been working on lately, see my <a href=\"https://updates.timsherratt.org/\">updates feed</a>.</p>\n\n<h2 id=\"the-future\">The future!</h2>\n\n<p>I&rsquo;m very excited about the possibilities ahead. The <a href=\"https://glam-workbench.github.io/\">GLAM Workbench</a> has received a lot of attention around the world (including a <a href=\"https://glam-workbench.github.io/awards/#british-library-lab-awards-2020\">Research Award</a> from the British Library Labs), and I&rsquo;m planning some <a href=\"https://updates.timsherratt.org/2021/03/25/reclaim-cloud-integration.html\">major developments</a> over coming months. And, of course, I won&rsquo;t forget all my other resources ‚Äì I spent a lot of time in 2020 migrating databases and platforms to keep everything chugging along.</p>\n\n<p>On my <a href=\"https://github.com/sponsors/wragge\">GitHub sponsors page</a>, I&rsquo;ve set an initial target of 50 sponsors. That might be ambitious, but as I said above, it&rsquo;s not just about money. Being able to point to a group of people who use and value this work will help me argue for new ways of enabling digital research in the humanities. So please help me spread the word ‚Äì let&rsquo;s make things together!</p>\n\n<iframe src=\"https://github.com/sponsors/wragge/card\" title=\"Sponsor wragge\" height=\"225\" width=\"600\" style=\"border: 0;\"></iframe>\n",
				"content_text": "Over the last few years, I've been very grateful for the support of my Patreon subscribers. Financially, their contributions have helped me cover a substantial proportion of the cloud hosting costs associated with projects like [Historic Hansard](https://historichansard.net/) and [The Real Face of White Australia](https://www.realfaceofwhiteaustralia.net/). But, more importantly, just knowing that they thought my work was of value has helped keep me going, and inspired me to develop a range of new resources.\n\nHowever, while I've been grateful for the platform provided by Patreon, I've increasingly felt that it's not a good fit for the sort of work I do. Patreon is geared towards providing special content to supporters, but, as you know, all my work is open. And that's really important to me. \n\nRecently GitHub opened up its own sponsorship program for the development of open source software. This program seems to align more closely with what I do. I already share and manage my code through GitHub, so integrating sponsorship seems to make a lot of sense. It's worth noting too, that, unlike Patreon, GitHub charges no fees and takes no cut of your contributions. As a result I've decided to close my Patreon account by the end of April, and create a GitHub sponsors page.\n\n## What does this mean for you? \n\n**If you're a Patreon subscriber and you'd like to keep supporting me**, you should cancel your Patreon contribution, then head over to my brand new [**GitHub sponsors page**](https://github.com/sponsors/wragge) and sign up! Thanks for your continued support!\n\n**If you'd prefer to let your contributions lapse**, just do nothing. Your payments will stop when I close the account at the end of April. I understand that circumstances change ‚Äì thank you so much for your support over the years, and I hope you will continue to make use of the things I create.\n\n**If you make use of any of my tools or resources and would like to support their continued development**, please think about [becoming a sponsor](https://github.com/sponsors/wragge). For a sample of the sorts of things I've been working on lately, see my [updates feed](https://updates.timsherratt.org/).\n\n## The future!\n\nI'm very excited about the possibilities ahead. The [GLAM Workbench](https://glam-workbench.github.io/) has received a lot of attention around the world (including a [Research Award](https://glam-workbench.github.io/awards/#british-library-lab-awards-2020) from the British Library Labs), and I'm planning some [major developments](https://updates.timsherratt.org/2021/03/25/reclaim-cloud-integration.html) over coming months. And, of course, I won't forget all my other resources ‚Äì I spent a lot of time in 2020 migrating databases and platforms to keep everything chugging along.\n\nOn my [GitHub sponsors page](https://github.com/sponsors/wragge), I've set an initial target of 50 sponsors. That might be ambitious, but as I said above, it's not just about money. Being able to point to a group of people who use and value this work will help me argue for new ways of enabling digital research in the humanities. So please help me spread the word ‚Äì let's make things together!\n\n<iframe src=\"https://github.com/sponsors/wragge/card\" title=\"Sponsor wragge\" height=\"225\" width=\"600\" style=\"border: 0;\"></iframe>\n",
				"date_published": "2021-03-26T13:37:00+11:00",
				"url": "https://updates.timsherratt.org/2021/03/26/moving-on-from.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/03/25/what-can-you.html",
				"title": "What can you do with the GLAM Workbench?",
				"content_html": "<p>You might have noticed some changes to the <a href=\"https://glam-workbench.github.io/\">GLAM Workbench</a> home page recently. One of the difficulties has always been trying to explain what the GLAM Workbench actually is, so I thought it might be useful to put more examples up front. The home page now lists about 25 notebooks under the headings:</p>\n\n<ul>\n<li><a href=\"https://glam-workbench.github.io/#finding-glam-data\">Finding GLAM data</a></li>\n<li><a href=\"https://glam-workbench.github.io/#asking-different-questions\">Asking different questions</a></li>\n<li><a href=\"https://glam-workbench.github.io/#hacking-heritage\">Hacking heritage</a></li>\n<li><a href=\"https://glam-workbench.github.io/#bringing-documentation-alive\">Bringing documentation alive</a></li>\n</ul>\n\n<p>Hopefully they give a decent representation of the sorts of things you can do using the GLAM Workbench. I‚Äôve also included a little rotating slideshow built using <a href=\"https://slides.com\">Slides.com</a>.</p>\n\n<iframe src=\"https://slides.com/wragge/gw-highlights/embed?byline=hidden&share=hidden\" width=\"576\" height=\"420\" scrolling=\"no\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>\n\n<p>Other recent additions include a new <a href=\"https://glam-workbench.github.io/awards/\">Grants and Awards</a> page. #dhhacks</p>\n",
				"content_text": "You might have noticed some changes to the [GLAM Workbench](https://glam-workbench.github.io/) home page recently. One of the difficulties has always been trying to explain what the GLAM Workbench actually is, so I thought it might be useful to put more examples up front. The home page now lists about 25 notebooks under the headings:\n\n* [Finding GLAM data](https://glam-workbench.github.io/#finding-glam-data)\n* [Asking different questions](https://glam-workbench.github.io/#asking-different-questions)\n* [Hacking heritage](https://glam-workbench.github.io/#hacking-heritage)\n* [Bringing documentation alive](https://glam-workbench.github.io/#bringing-documentation-alive)\n\nHopefully they give a decent representation of the sorts of things you can do using the GLAM Workbench. I‚Äôve also included a little rotating slideshow built using [Slides.com](https://slides.com).\n\n<iframe src=\"https://slides.com/wragge/gw-highlights/embed?byline=hidden&share=hidden\" width=\"576\" height=\"420\" scrolling=\"no\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>\n\nOther recent additions include a new [Grants and Awards](https://glam-workbench.github.io/awards/) page. #dhhacks\n\n",
				"date_published": "2021-03-25T11:43:47+11:00",
				"url": "https://updates.timsherratt.org/2021/03/25/what-can-you.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/03/25/reclaim-cloud-integration.html",
				"title": "Reclaim Cloud integration coming soon to the GLAM Workbench",
				"content_html": "<p>I‚Äôve been doing a bit of work behind the scenes lately to prepare for a major update to the <a href=\"https://glam-workbench.github.io/\">GLAM Workbench</a>. My plan is to provide one click installation of any of the GLAM Workbench repositories on the <a href=\"https://reclaim.cloud/\">Reclaim Cloud</a> platform. This will provide a useful step up from Binder for any researcher who wants to do large-scale or sustained work using the GLAM Workbench. Reclaim Cloud is a paid service, but they do a great job supporting digital scholarship in the humanities, and it‚Äôs fairly easy to minimise your costs by shutting down environments when they&rsquo;re not in use.</p>\n\n<p>I‚Äôve still got a lot of work to do to roll this out across the GLAM Workbench&rsquo;s 40 repositories, but if you&rsquo;d like a preview head to the <a href=\"https://github.com/GLAM-Workbench/trove-newspaper-harvester\">Trove Newspaper and Gazette Harvester repository</a> on GitHub. Get yourself a Reclaim Cloud account and click on the <strong>Launch on Reclaim Cloud</strong> button. It&rsquo;s that easy!</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/a2c7a079eb.jpg\" width=\"600\" height=\"270\" alt=\"\" /></p>\n\n<p>There&rsquo;s <a href=\"https://community.reclaimhosting.com/t/a-one-click-jupyter-install-example-for-the-glam-workbench/3676\">some technical notes</a> in the Reclaim Hosting forum, and <a href=\"https://bavatuesdays.com/reclaim-clouds-got-glam/\">a post</a> by Reclaim Hosting guru Jim Groom describing his own experience spinning up the GLAM Workbench.</p>\n\n<p>Watch this space for more news! #dhhacks</p>\n",
				"content_text": "I‚Äôve been doing a bit of work behind the scenes lately to prepare for a major update to the [GLAM Workbench](https://glam-workbench.github.io/). My plan is to provide one click installation of any of the GLAM Workbench repositories on the [Reclaim Cloud](https://reclaim.cloud/) platform. This will provide a useful step up from Binder for any researcher who wants to do large-scale or sustained work using the GLAM Workbench. Reclaim Cloud is a paid service, but they do a great job supporting digital scholarship in the humanities, and it‚Äôs fairly easy to minimise your costs by shutting down environments when they're not in use.\n\nI‚Äôve still got a lot of work to do to roll this out across the GLAM Workbench's 40 repositories, but if you'd like a preview head to the [Trove Newspaper and Gazette Harvester repository](https://github.com/GLAM-Workbench/trove-newspaper-harvester) on GitHub. Get yourself a Reclaim Cloud account and click on the **Launch on Reclaim Cloud** button. It's that easy!\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/a2c7a079eb.jpg\" width=\"600\" height=\"270\" alt=\"\" />\n\nThere's [some technical notes](https://community.reclaimhosting.com/t/a-one-click-jupyter-install-example-for-the-glam-workbench/3676) in the Reclaim Hosting forum, and [a post](https://bavatuesdays.com/reclaim-clouds-got-glam/) by Reclaim Hosting guru Jim Groom describing his own experience spinning up the GLAM Workbench. \n\nWatch this space for more news! #dhhacks\n",
				"date_published": "2021-03-25T11:18:00+11:00",
				"url": "https://updates.timsherratt.org/2021/03/25/reclaim-cloud-integration.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/03/25/some-recent-glam.html",
				"title": "Some recent GLAM Workbench presentations",
				"content_html": "<p>I‚Äôve given a couple of talks lately on the <a href=\"https://glam-workbench.github.io/\">GLAM Workbench</a> and some of my other work relating to the construction of online access to GLAM collections. Videos and slides are available for both:</p>\n\n<ul>\n<li><strong>From collections as data to collections as infrastructure: Building the GLAM Workbench</strong>, seminar for the Centre for Creative and Cultural Research, University of Canberra, 22 February 2021 ‚Äì <a href=\"https://vimeo.com/528145007\">video</a> (40 minutes) and <a href=\"https://slides.com/wragge/uc-cccr-glamworkbench\">slides</a></li>\n</ul>\n\n<iframe src=\"https://player.vimeo.com/video/528145007\" width=\"640\" height=\"360\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen></iframe>\n\n<ul>\n<li><strong>Building the GLAM Workbench</strong> (and various other projects such as <a href=\"https://www.realfaceofwhiteaustralia.net/\">The Real Face of White Australia</a>, <a href=\"http://closedaccess.herokuapp.com/\">Closed Access</a>, and <a href=\"https://owebrowse.herokuapp.com/redactions/\">redacted</a>), guest lecture for the <a href=\"https://wiki.epfl.ch/cultural.data.sculpting\">Cultural Data Sculpting</a> course, EPFL, Switzerland, 18 March 2021 ‚Äì <a href=\"https://vimeo.com/525872948\">video</a> (1hr 40mins) and <a href=\"https://slides.com/wragge/data-sculpting-2021/\">slides</a></li>\n</ul>\n\n<p>I‚Äôve also updated the <a href=\"https://glam-workbench.github.io/presentations/\">presentations</a> page in the GLAM Workbench. #dhhacks</p>\n",
				"content_text": "I‚Äôve given a couple of talks lately on the [GLAM Workbench](https://glam-workbench.github.io/) and some of my other work relating to the construction of online access to GLAM collections. Videos and slides are available for both:\n\n*  **From collections as data to collections as infrastructure: Building the GLAM Workbench**, seminar for the Centre for Creative and Cultural Research, University of Canberra, 22 February 2021 ‚Äì [video](https://vimeo.com/528145007) (40 minutes) and [slides](https://slides.com/wragge/uc-cccr-glamworkbench)\n\n<iframe src=\"https://player.vimeo.com/video/528145007\" width=\"640\" height=\"360\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen></iframe>\n\n* **Building the GLAM Workbench** (and various other projects such as [The Real Face of White Australia](https://www.realfaceofwhiteaustralia.net/), [Closed Access](http://closedaccess.herokuapp.com/), and [redacted](https://owebrowse.herokuapp.com/redactions/)), guest lecture for the [Cultural Data Sculpting](https://wiki.epfl.ch/cultural.data.sculpting) course, EPFL, Switzerland, 18 March 2021 ‚Äì [video](https://vimeo.com/525872948) (1hr 40mins) and [slides](https://slides.com/wragge/data-sculpting-2021/)\n\nI‚Äôve also updated the [presentations](https://glam-workbench.github.io/presentations/) page in the GLAM Workbench. #dhhacks\n",
				"date_published": "2021-03-25T10:40:00+11:00",
				"url": "https://updates.timsherratt.org/2021/03/25/some-recent-glam.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/03/08/some-glam-workbench.html",
				"title": "Some GLAM Workbench datasets to explore for Open Data Day",
				"content_html": "<p>It was Open Data Day on Saturday 6 March ‚Äì here‚Äôs some of the ready-to-go datasets you can find in the <a href=\"https://glam-workbench.github.io/\">GLAM Workbench</a> ‚Äì there‚Äôs something for historians, humanities researchers, teachers &amp; more!</p>\n\n<ul>\n<li><p>First here‚Äôs a <a href=\"https://glam-workbench.github.io/glam-data-list/\">list of Australian GLAM (that‚Äôs galleries, libraries, archives &amp; museums) data sources</a>. It includes APIs, portals, and downloadable datasets. Suggested additions welcome!</p></li>\n\n<li><p>There‚Äôs also a <a href=\"https://glam-workbench.github.io/glam-datasets-from-gov-portals/\">list of Australian GLAM datasets that are available through government open data portals</a>. There‚Äôs hundreds of them, but they‚Äôre not always easy to find. Convicts, immigration, hospitals, WWI ‚Äì includes lots of useful biographical data.</p></li>\n\n<li><p>If you‚Äôre not sure where to start with a list of 600 CSV files, have a look at the <a href=\"https://glam-workbench.github.io/csv-explorer/\">GLAM CSV Explorer</a>! Select a file and this Jupyter-powered app will build a series of visualisations based on the contents of each column.</p></li>\n\n<li><p>While they‚Äôre not yet in an open data portal, NSW State Archives has a rich collection of indexes transcribed by volunteers. I‚Äôve scraped 64 indexes, with over 1.4 million rows of data and <a href=\"https://glam-workbench.github.io/nsw-state-archives/#nsw-state-archives-online-indexes\">put them in a repository for easy download.</a> There‚Äôs even a <a href=\"https://glam-workbench.github.io/nsw-state-archives/#nsw-state-archives-index-explorer\">version of the CSV Explorer</a>, just for the NSW State Archives indexes.</p></li>\n\n<li><p>Here‚Äôs a <a href=\"https://glam-workbench.github.io/trove-newspapers/#csv-formatted-list-of-australian-womens-weekly-issues-1933-to-1982\">CSV file</a> containing details of every issue of the Australian Women‚Äôs Weekly in Trove.</p></li>\n\n<li><p>A <a href=\"https://glam-workbench.github.io/trove-newspapers/#australian-womens-weekly-front-covers-1933-to-1982\">collection of front covers from the Australian Women‚Äôs Weekly from 1933 to 1982</a>! That‚Äôs 2,566 images you can download from Cloudstor or browse in a series of convenient PDFs.</p></li>\n</ul>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/e829a7a078.jpg\" width=\"600\" height=\"376\" alt=\"\" /></p>\n\n<ul>\n<li><p>Here‚Äôs a <a href=\"https://glam-workbench.github.io/trove-newspapers/#trove-newspapers-with-non-english-language-content\">list of non-English language newspapers</a> in Trove.</p></li>\n\n<li><p>And another <a href=\"https://github.com/GLAM-Workbench/trove-newspapers/blob/master/newspapers_post_54.csv\">list of newspapers in Trove</a> with articles available from beyond the 1954 copyright cliff of death.</p></li>\n\n<li><p>While we‚Äôre on newspapers, here‚Äôs a <a href=\"https://docs.google.com/spreadsheets/d/1rURriHBSf3MocI8wsdl1114t0YeyU0BVSXWeg232MZs/edit?usp=sharing\">spreadsheet</a> that identifies places of publication or circulation of Trove newspapers, and provides geocordinates</p></li>\n\n<li><p>What about some text? Here‚Äôs <a href=\"https://glam-workbench.github.io/trove-books/#ocrd-text-from-trove-books-and-ephemera\">24,620 files of OCRd text from digitised books and ephemera</a> in Trove. There‚Äôs also a <a href=\"https://glam-workbench.github.io/trove-books/#csv-formatted-list-of-books-with-ocrd-text\">CSV-formatted list</a> with the basic details of each book.</p></li>\n\n<li><p>More text! Here‚Äôs <a href=\"https://glam-workbench.github.io/trove-journals/#ocrd-text-from-trove-digitised-journals\">OCRd text from 26,234 issues of 397 digitised journals</a> in Trove.</p></li>\n\n<li><p>Something different ‚Äì a <a href=\"https://glam-workbench.github.io/trove-journals/#politicians-talking-about-immigrants-and-refugees\">collection of 12,619 press releases &amp; speeches by Australian politicians</a> that include any of the terms ‚Äòimmigrant‚Äô, ‚Äòasylum seeker‚Äô, ‚Äòboat people‚Äô, ‚Äòillegal arrivals‚Äô, or &lsquo;boat arrivals&rsquo;.  From the Parliamentary Library via Trove.</p></li>\n\n<li><p>Some more images ‚Äì a <a href=\"https://glam-workbench.github.io/trove-journals/#editorial-cartoons-from-the-bulletin-1886-to-1952\">collection of 3,471 full-page editorial cartoons from The Bulletin</a>, 1886 to 1952 (with a warning for racist content). Available both as individual images and compiled into PDFs.</p></li>\n\n<li><p>From the ABC via Trove, there‚Äôs <a href=\"https://glam-workbench.github.io/trove-music/#abc-radio-national-programs\">400,000 records from Radio National programs broadcast since the late 1990s</a>. That includes every segment broadcast on AM, PM, RN Breakfast etc.</p></li>\n\n<li><p>This might be handy ‚Äì from some work I‚Äôm doing with ANU Archives, here‚Äôs a <a href=\"https://github.com/GLAM-Workbench/anu-archives/blob/master/nsw_holidays_1900_1950.csv\">CSV file containing details of holidays in NSW from 1901 to 1950</a>.</p></li>\n\n<li><p>The Department of Prime Minister and Cabinet provides XML versions of more than 20,000 speeches &amp; interviews from recent PMs for download. I‚Äôve <a href=\"https://glam-workbench.github.io/pm-transcripts/\">saved them to a repository and compiled some indexes</a>.</p></li>\n\n<li><p>And finally ‚Äì Commonwealth Hansard from the Parliamentary Library ‚Äì lots of well-structured XML files! I‚Äôve <a href=\"https://glam-workbench.github.io/hansard/\">created a repo</a> with one file for each sitting day from 1901 to 1980 &amp; 1998 to 2005 (hopefully the gap will be filled soon). There‚Äôs also a <a href=\"https://glam-workbench.github.io/hansard/#list-of-sitting-days-1901-to-2005\">CSV index to sitting days</a>.</p></li>\n</ul>\n\n<p>And if that‚Äôs not enough data, the GLAM Workbench provides tools to help you create your own datasets from Trove, the National Archives of Australia, the National Museum of Australia, Archives NZ, DigitalNZ, &amp; more! #dhhacks</p>\n",
				"content_text": "It was Open Data Day on Saturday 6 March ‚Äì here‚Äôs some of the ready-to-go datasets you can find in the [GLAM Workbench](https://glam-workbench.github.io/) ‚Äì there‚Äôs something for historians, humanities researchers, teachers & more!\n\n* First here‚Äôs a [list of Australian GLAM (that‚Äôs galleries, libraries, archives & museums) data sources](https://glam-workbench.github.io/glam-data-list/). It includes APIs, portals, and downloadable datasets. Suggested additions welcome! \n\n* There‚Äôs also a [list of Australian GLAM datasets that are available through government open data portals](https://glam-workbench.github.io/glam-datasets-from-gov-portals/). There‚Äôs hundreds of them, but they‚Äôre not always easy to find. Convicts, immigration, hospitals, WWI ‚Äì includes lots of useful biographical data. \n\n* If you‚Äôre not sure where to start with a list of 600 CSV files, have a look at the [GLAM CSV Explorer](https://glam-workbench.github.io/csv-explorer/)! Select a file and this Jupyter-powered app will build a series of visualisations based on the contents of each column. \n\n* While they‚Äôre not yet in an open data portal, NSW State Archives has a rich collection of indexes transcribed by volunteers. I‚Äôve scraped 64 indexes, with over 1.4 million rows of data and [put them in a repository for easy download.](https://glam-workbench.github.io/nsw-state-archives/#nsw-state-archives-online-indexes) There‚Äôs even a [version of the CSV Explorer](https://glam-workbench.github.io/nsw-state-archives/#nsw-state-archives-index-explorer), just for the NSW State Archives indexes. \n\n* Here‚Äôs a [CSV file](https://glam-workbench.github.io/trove-newspapers/#csv-formatted-list-of-australian-womens-weekly-issues-1933-to-1982) containing details of every issue of the Australian Women‚Äôs Weekly in Trove.\n\n* A [collection of front covers from the Australian Women‚Äôs Weekly from 1933 to 1982](https://glam-workbench.github.io/trove-newspapers/#australian-womens-weekly-front-covers-1933-to-1982)! That‚Äôs 2,566 images you can download from Cloudstor or browse in a series of convenient PDFs.\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/e829a7a078.jpg\" width=\"600\" height=\"376\" alt=\"\" />\n\n* Here‚Äôs a [list of non-English language newspapers](https://glam-workbench.github.io/trove-newspapers/#trove-newspapers-with-non-english-language-content) in Trove.\n\n* And another [list of newspapers in Trove](https://github.com/GLAM-Workbench/trove-newspapers/blob/master/newspapers_post_54.csv) with articles available from beyond the 1954 copyright cliff of death.\n\n* While we‚Äôre on newspapers, here‚Äôs a [spreadsheet](https://docs.google.com/spreadsheets/d/1rURriHBSf3MocI8wsdl1114t0YeyU0BVSXWeg232MZs/edit?usp=sharing) that identifies places of publication or circulation of Trove newspapers, and provides geocordinates\n\n* What about some text? Here‚Äôs [24,620 files of OCRd text from digitised books and ephemera](https://glam-workbench.github.io/trove-books/#ocrd-text-from-trove-books-and-ephemera) in Trove. There‚Äôs also a [CSV-formatted list](https://glam-workbench.github.io/trove-books/#csv-formatted-list-of-books-with-ocrd-text) with the basic details of each book.\n\n* More text! Here‚Äôs [OCRd text from 26,234 issues of 397 digitised journals](https://glam-workbench.github.io/trove-journals/#ocrd-text-from-trove-digitised-journals) in Trove.\n\n* Something different ‚Äì a [collection of 12,619 press releases & speeches by Australian politicians](https://glam-workbench.github.io/trove-journals/#politicians-talking-about-immigrants-and-refugees) that include any of the terms ‚Äòimmigrant‚Äô, ‚Äòasylum seeker‚Äô, ‚Äòboat people‚Äô, ‚Äòillegal arrivals‚Äô, or 'boat arrivals'.  From the Parliamentary Library via Trove.\n\n* Some more images ‚Äì a [collection of 3,471 full-page editorial cartoons from The Bulletin](https://glam-workbench.github.io/trove-journals/#editorial-cartoons-from-the-bulletin-1886-to-1952), 1886 to 1952 (with a warning for racist content). Available both as individual images and compiled into PDFs.\n\n* From the ABC via Trove, there‚Äôs [400,000 records from Radio National programs broadcast since the late 1990s](https://glam-workbench.github.io/trove-music/#abc-radio-national-programs). That includes every segment broadcast on AM, PM, RN Breakfast etc.\n\n* This might be handy ‚Äì from some work I‚Äôm doing with ANU Archives, here‚Äôs a [CSV file containing details of holidays in NSW from 1901 to 1950](https://github.com/GLAM-Workbench/anu-archives/blob/master/nsw_holidays_1900_1950.csv).\n\n* The Department of Prime Minister and Cabinet provides XML versions of more than 20,000 speeches & interviews from recent PMs for download. I‚Äôve [saved them to a repository and compiled some indexes](https://glam-workbench.github.io/pm-transcripts/).\n\n* And finally ‚Äì Commonwealth Hansard from the Parliamentary Library ‚Äì lots of well-structured XML files! I‚Äôve [created a repo](https://glam-workbench.github.io/hansard/) with one file for each sitting day from 1901 to 1980 & 1998 to 2005 (hopefully the gap will be filled soon). There‚Äôs also a [CSV index to sitting days](https://glam-workbench.github.io/hansard/#list-of-sitting-days-1901-to-2005).\n\nAnd if that‚Äôs not enough data, the GLAM Workbench provides tools to help you create your own datasets from Trove, the National Archives of Australia, the National Museum of Australia, Archives NZ, DigitalNZ, & more! #dhhacks\n",
				"date_published": "2021-03-08T14:54:00+11:00",
				"url": "https://updates.timsherratt.org/2021/03/08/some-glam-workbench.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/02/22/zotero-translator-for.html",
				"title": "Zotero translator for NAA RecordSearch updated",
				"content_html": "<p>The recent change of labels from ‚ÄòBarcode&rsquo; to ‚ÄòItemID‚Äô in the National Archives of Australia&rsquo;s RecordSearch database broke the Zotero translator. I‚Äôve now updated the translator, and the new version has been merged into the Zotero translators repository. It should be updated when you restart Zotero, but if not you can go to <strong>Preferences &gt; Advanced &gt; Files and folders</strong> and click on the <strong>Reset translators</strong> button.</p>\n\n<p>The translator lets you:</p>\n\n<ul>\n<li>Capture metadata from single items, series, or photos</li>\n<li>Capture multiple items, series, or photos from search results</li>\n<li>Save photos from PhotoSearch</li>\n<li>Save digitised files as PDFs</li>\n<li>Save page images from the digitised file viewer</li>\n</ul>\n\n<p>For more information or to ask questions, go to <a href=\"https://ozglam.chat/t/zotero-translator-for-recordsearch-updated/27\">OzGLAM Help</a>. #dhhacks</p>\n",
				"content_text": "The recent change of labels from ‚ÄòBarcode' to ‚ÄòItemID‚Äô in the National Archives of Australia's RecordSearch database broke the Zotero translator. I‚Äôve now updated the translator, and the new version has been merged into the Zotero translators repository. It should be updated when you restart Zotero, but if not you can go to **Preferences > Advanced > Files and folders** and click on the **Reset translators** button.\n\nThe translator lets you:\n\n* Capture metadata from single items, series, or photos\n* Capture multiple items, series, or photos from search results\n* Save photos from PhotoSearch\n* Save digitised files as PDFs\n* Save page images from the digitised file viewer\n\nFor more information or to ask questions, go to [OzGLAM Help](https://ozglam.chat/t/zotero-translator-for-recordsearch-updated/27). #dhhacks\n",
				"date_published": "2021-02-22T16:49:33+11:00",
				"url": "https://updates.timsherratt.org/2021/02/22/zotero-translator-for.html"
			},
			{
				"id": "http://wragge.micro.blog/2021/02/22/trovenewsbot-upgraded-now.html",
				"title": "TroveNewsBot upgraded ‚Äì now sharing articles published 'on this day'!",
				"content_html": "<p><a href=\"https://twitter.com/TroveNewsBot\">@TroveNewsBot</a> has been sharing Trove newspaper articles on Twitter for over 7 years. With its latest upgrade the bot now has an ‚Äòon this day‚Äô function. Every day at AEST9.00am, TroveNewsBot will share an article published on that day in the past.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/b2b25896d0.jpg\" width=\"600\" height=\"427\" alt=\"\" /></p>\n\n<p>Even better, you can make your own ‚Äòon this day&rsquo; queries by tweeting to @TroveNewsBot with the hashtag #onthisday. For example:</p>\n\n<ul>\n<li>Tweeting &lsquo;#onthisday #luckydip&rsquo; ‚Äì will return a random article published on this day in the past.</li>\n<li>Tweeting ‚Äòcat #onthisday #luckydip‚Äô ‚Äì will return a random article about cats published on this day in the past.</li>\n<li>Tweeting ‚Äò1920 #year #onthisday‚Äô ‚Äì will return an article published on this day in 1920.</li>\n</ul>\n\n<p>See @TroveNewsBot‚Äôs <a href=\"https://wragge.github.io/trovenewsbot2019/\">help page</a> for a full list of parameters. #dhhacks</p>\n",
				"content_text": "[@TroveNewsBot](https://twitter.com/TroveNewsBot) has been sharing Trove newspaper articles on Twitter for over 7 years. With its latest upgrade the bot now has an ‚Äòon this day‚Äô function. Every day at AEST9.00am, TroveNewsBot will share an article published on that day in the past.\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/b2b25896d0.jpg\" width=\"600\" height=\"427\" alt=\"\" />\n\nEven better, you can make your own ‚Äòon this day' queries by tweeting to @TroveNewsBot with the hashtag #onthisday. For example:\n\n* Tweeting '#onthisday #luckydip' ‚Äì will return a random article published on this day in the past.\n* Tweeting ‚Äòcat #onthisday #luckydip‚Äô ‚Äì will return a random article about cats published on this day in the past.\n* Tweeting ‚Äò1920 #year #onthisday‚Äô ‚Äì will return an article published on this day in 1920.\n\nSee @TroveNewsBot‚Äôs [help page](https://wragge.github.io/trovenewsbot2019/) for a full list of parameters. #dhhacks\n\n",
				"date_published": "2021-02-22T16:34:00+11:00",
				"url": "https://updates.timsherratt.org/2021/02/22/trovenewsbot-upgraded-now.html"
			},
			{
				"id": "http://wragge.micro.blog/2021/02/11/the-naa-recently.html",
				
				"content_html": "<p>The NAA recently changed field labels in RecordSearch, so that ‚ÄòBarcode&rsquo; is now ‚ÄòItem ID‚Äô. This required an update to my <a href=\"https://github.com/wragge/recordsearch_tools\"><code>recordsearch_tools</code> screen scraper</a>. I also had to make a few changes in the <a href=\"https://glam-workbench.github.io/recordsearch/\">RecordSearch section</a> of the GLAM Workbench. #dhhacks</p>\n",
				"content_text": "The NAA recently changed field labels in RecordSearch, so that ‚ÄòBarcode' is now ‚ÄòItem ID‚Äô. This required an update to my [`recordsearch_tools` screen scraper](https://github.com/wragge/recordsearch_tools). I also had to make a few changes in the [RecordSearch section](https://glam-workbench.github.io/recordsearch/) of the GLAM Workbench. #dhhacks\n",
				"date_published": "2021-02-11T10:24:00+11:00",
				"url": "https://updates.timsherratt.org/2021/02/11/the-naa-recently.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/02/11/open-access-publishing.html",
				"title": "Open access publishing for Australian historians",
				"content_html": "<p>After some <a href=\"https://nbviewer.jupyter.org/github/wragge/ozhist-openaccess/blob/master/open_access_versions_australian_hass_journals.ipynb\">recent investigations</a> of the availability of open access versions of articles published in paywalled Australian history journals, I‚Äôve <a href=\"https://docs.google.com/document/d/1BwAbmBOUke-RtDaCZYq8ZzeoBuzsOVe9RUMw-g3JD94/edit?usp=sharing\">started a Google doc</a> to capture useful links and information for Australian historians wanting to make their research open access. Comments and additions are welcome. #dhhacks</p>\n",
				"content_text": "After some [recent investigations](https://nbviewer.jupyter.org/github/wragge/ozhist-openaccess/blob/master/open_access_versions_australian_hass_journals.ipynb) of the availability of open access versions of articles published in paywalled Australian history journals, I‚Äôve [started a Google doc](https://docs.google.com/document/d/1BwAbmBOUke-RtDaCZYq8ZzeoBuzsOVe9RUMw-g3JD94/edit?usp=sharing) to capture useful links and information for Australian historians wanting to make their research open access. Comments and additions are welcome. #dhhacks\n",
				"date_published": "2021-02-11T10:10:00+11:00",
				"url": "https://updates.timsherratt.org/2021/02/11/open-access-publishing.html"
			},
			{
				"id": "http://wragge.micro.blog/2021/02/11/who-was-linking.html",
				"title": "Who was linking to Trove newspapers in 2014?",
				"content_html": "<p>In 2014 I pulled together a sample of web pages that included links back to digitised newspaper articles in Trove and created the ‚ÄòTrove Traces‚Äô app. It was interesting, and sometimes disturbing, to see the diversity of sites that made use of Trove. Amongst the family and local history enthusiasts were climate change deniers and racists who found ‚Äòevidence&rsquo; for their views in past newspapers. And of course, the sample only includes links in web pages, not social media sharing.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/6f4168855a.jpg\" width=\"600\" height=\"321\" alt=\"\" /></p>\n\n<p>The app has since disappeared, but I‚Äôve <a href=\"https://timsherratt.org/shed/trovetraces/traces/index.html\">now published a static version</a>. The search and sort functions won&rsquo;t work, but you can browse through the sample of backlinks by web page or by linked Trove newspaper article. There are also lists of the most frequently occurring pages and articles. #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/b9d2894048.jpg\" width=\"600\" height=\"462\" alt=\"\" /></p>\n",
				"content_text": "In 2014 I pulled together a sample of web pages that included links back to digitised newspaper articles in Trove and created the ‚ÄòTrove Traces‚Äô app. It was interesting, and sometimes disturbing, to see the diversity of sites that made use of Trove. Amongst the family and local history enthusiasts were climate change deniers and racists who found ‚Äòevidence' for their views in past newspapers. And of course, the sample only includes links in web pages, not social media sharing.\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/6f4168855a.jpg\" width=\"600\" height=\"321\" alt=\"\" />\n\nThe app has since disappeared, but I‚Äôve [now published a static version](https://timsherratt.org/shed/trovetraces/traces/index.html). The search and sort functions won't work, but you can browse through the sample of backlinks by web page or by linked Trove newspaper article. There are also lists of the most frequently occurring pages and articles. #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/b9d2894048.jpg\" width=\"600\" height=\"462\" alt=\"\" />\n",
				"date_published": "2021-02-11T10:01:00+11:00",
				"url": "https://updates.timsherratt.org/2021/02/11/who-was-linking.html"
			},
			{
				"id": "http://wragge.micro.blog/2021/02/03/new-digitalnz-api.html",
				"title": "New! DigitalNZ API Query Builder added to GLAM Workbench",
				"content_html": "<p>I‚Äôve added an API Query Builder to the <a href=\"https://glam-workbench.github.io/digitalnz/\">DigitalNZ section of the GLAM Workbench</a>. You can use it to learn about the different parameters available from the search API, and experiment with different queries. Just get your API key from DigitalNZ, then try entering keywords and selecting options. Once you understand how the API works, you can start thinking about how you can make use of it in your own projects.</p>\n\n<p>üëâüèª <a href=\"https://mybinder.org/v2/gh/GLAM-Workbench/digitalnz/master?urlpath=voila%2Frender%2Fbuild_api_query.ipynb\">Try it out live on Binder!</a></p>\n\n<p>Under the hood the API Query Builder is a Jupyter notebook (of course), but it uses <a href=\"https://ipyvuetify.readthedocs.io/en/latest/index.html\">ipyvuetify</a> to create good-looking, responsive, form widgets. It‚Äôs intended to be run using <a href=\"https://voila.readthedocs.io/en/stable/index.html\">Voil√†</a>, which turns notebooks into interactive apps and dashboards. You can now run any Jupyter notebook <a href=\"https://voila.readthedocs.io/en/stable/deploy.html#deployment-on-binder\">using Voil√† on Binder</a>, just by changing the url.</p>\n\n<p>If this app seems useful (let me know!) I might put a version on Heroku so the start up time is reduced. I‚Äôm also thinking of using this sort of pattern to create apps for other APIs in the GLAM Workbench. #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/48f0490cce.jpg\" width=\"600\" height=\"445\" alt=\"\" /></p>\n",
				"content_text": "I‚Äôve added an API Query Builder to the [DigitalNZ section of the GLAM Workbench](https://glam-workbench.github.io/digitalnz/). You can use it to learn about the different parameters available from the search API, and experiment with different queries. Just get your API key from DigitalNZ, then try entering keywords and selecting options. Once you understand how the API works, you can start thinking about how you can make use of it in your own projects.\n\nüëâüèª [Try it out live on Binder!](https://mybinder.org/v2/gh/GLAM-Workbench/digitalnz/master?urlpath=voila%2Frender%2Fbuild_api_query.ipynb)\n\nUnder the hood the API Query Builder is a Jupyter notebook (of course), but it uses [ipyvuetify](https://ipyvuetify.readthedocs.io/en/latest/index.html) to create good-looking, responsive, form widgets. It‚Äôs intended to be run using [Voil√†](https://voila.readthedocs.io/en/stable/index.html), which turns notebooks into interactive apps and dashboards. You can now run any Jupyter notebook [using Voil√† on Binder](https://voila.readthedocs.io/en/stable/deploy.html#deployment-on-binder), just by changing the url.\n\nIf this app seems useful (let me know!) I might put a version on Heroku so the start up time is reduced. I‚Äôm also thinking of using this sort of pattern to create apps for other APIs in the GLAM Workbench. #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/48f0490cce.jpg\" width=\"600\" height=\"445\" alt=\"\" />\n",
				"date_published": "2021-02-03T10:08:17+11:00",
				"url": "https://updates.timsherratt.org/2021/02/03/new-digitalnz-api.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/01/28/openglam-fireworks-finding.html",
				"title": "OpenGLAM fireworks! Finding open collections in DigitalNZ",
				"content_html": "<p>Lately I‚Äôve been updating and expanding the notebooks in the <a href=\"https://glam-workbench.github.io/digitalnz/\">DigitalNZ section</a> of the GLAM Workbench. In particular, I‚Äôve been looking at the <code>usage</code> facet to understand how much of the aggregated content is ‚Äòopen‚Äô. What do I mean by ‚Äòopen‚Äô? The <a href=\"https://opendefinition.org/\">Open Knowledge Foundation definition</a> states that ‚Äòopen data and content can be freely used, modified, and shared by anyone for any purpose‚Äô. Obviously things that are in the public domain, such as out-of-copyright resources, are open. But so are resources with an <a href=\"https://opendefinition.org/licenses/\">open licence</a> such as <a href=\"https://opendefinition.org/licenses/cc-by\">CC-BY</a> or <a href=\"https://opendefinition.org/licenses/cc-by-sa\">CC-BY-SA</a>. The Creative Commons ‚ÄòNon commercial&rsquo; and ‚ÄòNo derivatives‚Äô licences are <em>not</em> open because they put limits on how you can use resources.</p>\n\n<p>How does this definition map to DigitalNZ? The <code>usage</code> facet includes <a href=\"https://github.com/GLAM-Workbench/digitalnz/blob/master/facets/usage.csv\">five values</a>:</p>\n\n<ul>\n<li>Share</li>\n<li>Modify</li>\n<li>Use commercially</li>\n<li>All rights reserved</li>\n<li>Unknown</li>\n</ul>\n\n<p>These values have been assigned by DigitalNZ based on  the <a href=\"https://github.com/GLAM-Workbench/digitalnz/blob/master/facets/rights.csv\">35,000 different rights statements</a> and <a href=\"https://github.com/GLAM-Workbench/digitalnz/blob/master/facets/copyright.csv\">30 different copyright statements</a> that are included in DigitalNZ metadata records. I find I have to turn the <code>usage</code> values inside out to really understand them. A resource that only allows you to ‚ÄòShare‚Äô, excludes the ‚ÄòModify‚Äô and ‚ÄòUse commercially‚Äô permissions and so is sort of equivalent to a CC-BY-ND-NC licence. The only open value, according to the definition above, is ‚ÄòUse commercially‚Äô, which is like CC-BY. I‚Äôm assuming that ‚ÄòUse commercially‚Äô has been assigned to resources that either out of copyright (or with no known copyright restrictions)  or are openly licensed.</p>\n\n<p>It‚Äôs also worth noting that the ‚Äòusage‚Äô values are not mutually-exclusive. A record with a ‚Äòusage‚Äô value of ‚ÄòUse commercially‚Äô, will also be assigned ‚ÄòShare‚Äô and ‚ÄòModify&rsquo; values. This is because ‚ÄòUse commercially‚Äô includes the &lsquo;Share&rsquo; and ‚ÄòModify‚Äô permissions. This seems a bit counter-intuitive, but makes sense if you think about doing a search for everything you&rsquo;re allowed to share.</p>\n\n<p>A rough calculation based on the usage facet indicates that 71.76% of the resources aggregated by DigitalNZ are open. That seems pretty good, though a lot of those are probably out-of-copyright newspaper articles from Papers Past. For a more fine-grained analysis, I decided to look at the ‚Äòusage‚Äô data for each combination of ‚Äòcontent_partner‚Äô and ‚Äòprimary_collection‚Äô. How open is each individual collection in DigitalNZ?</p>\n\n<p>For added excitement, and to stretch my knowledge of what <a href=\"https://altair-viz.github.io/\">Altair</a> can do, I decided to visualise the results as display of colourful fireworks. The higher the explosion, the more open the collection! I‚Äôm pretty pleased with the result.</p>\n\n<p><a href=\"https://glam-workbench.github.io/images/dnz-fireworks.png\"><img src=\"https://updates.timsherratt.org/uploads/2021/533add5b13.jpg\" width=\"600\" height=\"174\" alt=\"\" /></a></p>\n\n<p>I&rsquo;ve saved <a href=\"http://timsherratt.org/shed/digitalnz/open_collections_digitalnz.html\">a HTML version of the chart</a> so you can mouseover the explosions for more details. All the code is <a href=\"https://glam-workbench.github.io/digitalnz/#visualising-open-collections-in-digitalnz\">included in this notebook</a>, along with a <a href=\"https://github.com/GLAM-Workbench/digitalnz/blob/master/facets/usage_by_collection_and_partner.csv\">CSV file</a> containing all the harvested facet data. #dhhacks</p>\n",
				"content_text": "Lately I‚Äôve been updating and expanding the notebooks in the [DigitalNZ section](https://glam-workbench.github.io/digitalnz/) of the GLAM Workbench. In particular, I‚Äôve been looking at the `usage` facet to understand how much of the aggregated content is ‚Äòopen‚Äô. What do I mean by ‚Äòopen‚Äô? The [Open Knowledge Foundation definition](https://opendefinition.org/) states that ‚Äòopen data and content can be freely used, modified, and shared by anyone for any purpose‚Äô. Obviously things that are in the public domain, such as out-of-copyright resources, are open. But so are resources with an [open licence](https://opendefinition.org/licenses/) such as [CC-BY](https://opendefinition.org/licenses/cc-by) or [CC-BY-SA](https://opendefinition.org/licenses/cc-by-sa). The Creative Commons ‚ÄòNon commercial' and ‚ÄòNo derivatives‚Äô licences are *not* open because they put limits on how you can use resources.\n\nHow does this definition map to DigitalNZ? The `usage` facet includes [five values](https://github.com/GLAM-Workbench/digitalnz/blob/master/facets/usage.csv):\n\n* Share\n* Modify\n* Use commercially\n* All rights reserved\n* Unknown\n\nThese values have been assigned by DigitalNZ based on  the [35,000 different rights statements](https://github.com/GLAM-Workbench/digitalnz/blob/master/facets/rights.csv) and [30 different copyright statements](https://github.com/GLAM-Workbench/digitalnz/blob/master/facets/copyright.csv) that are included in DigitalNZ metadata records. I find I have to turn the `usage` values inside out to really understand them. A resource that only allows you to ‚ÄòShare‚Äô, excludes the ‚ÄòModify‚Äô and ‚ÄòUse commercially‚Äô permissions and so is sort of equivalent to a CC-BY-ND-NC licence. The only open value, according to the definition above, is ‚ÄòUse commercially‚Äô, which is like CC-BY. I‚Äôm assuming that ‚ÄòUse commercially‚Äô has been assigned to resources that either out of copyright (or with no known copyright restrictions)  or are openly licensed.\n\nIt‚Äôs also worth noting that the ‚Äòusage‚Äô values are not mutually-exclusive. A record with a ‚Äòusage‚Äô value of ‚ÄòUse commercially‚Äô, will also be assigned ‚ÄòShare‚Äô and ‚ÄòModify' values. This is because ‚ÄòUse commercially‚Äô includes the 'Share' and ‚ÄòModify‚Äô permissions. This seems a bit counter-intuitive, but makes sense if you think about doing a search for everything you're allowed to share.\n\nA rough calculation based on the usage facet indicates that 71.76% of the resources aggregated by DigitalNZ are open. That seems pretty good, though a lot of those are probably out-of-copyright newspaper articles from Papers Past. For a more fine-grained analysis, I decided to look at the ‚Äòusage‚Äô data for each combination of ‚Äòcontent_partner‚Äô and ‚Äòprimary_collection‚Äô. How open is each individual collection in DigitalNZ?\n\nFor added excitement, and to stretch my knowledge of what [Altair](https://altair-viz.github.io/) can do, I decided to visualise the results as display of colourful fireworks. The higher the explosion, the more open the collection! I‚Äôm pretty pleased with the result.\n\n<a href=\"https://glam-workbench.github.io/images/dnz-fireworks.png\"><img src=\"https://updates.timsherratt.org/uploads/2021/533add5b13.jpg\" width=\"600\" height=\"174\" alt=\"\" /></a>\n\nI've saved [a HTML version of the chart](http://timsherratt.org/shed/digitalnz/open_collections_digitalnz.html) so you can mouseover the explosions for more details. All the code is [included in this notebook](https://glam-workbench.github.io/digitalnz/#visualising-open-collections-in-digitalnz), along with a [CSV file](https://github.com/GLAM-Workbench/digitalnz/blob/master/facets/usage_by_collection_and_partner.csv) containing all the harvested facet data. #dhhacks\n",
				"date_published": "2021-01-28T11:29:00+11:00",
				"url": "https://updates.timsherratt.org/2021/01/28/openglam-fireworks-finding.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/01/25/easy-browsing-of.html",
				"title": "Easy browsing of Trove newspapers with these keyboard shortcuts!",
				"content_html": "<p>If you like browsing Trove&rsquo;s digitised newspapers page by page, you might have found that the current interface is a bit clunky. To move between pages you have to hover over the page number and click on &lsquo;Next&rsquo; or &lsquo;Previous&rsquo;. Wouldn&rsquo;t it be good if you could just use the arrow keys on your keyboard? Well now you can!</p>\n\n<p>I&rsquo;ve created a very simple script that allows you to use the arrows on your keyboard to move between pages in Trove&rsquo;s digitised newspapers. Once it&rsquo;s enabled you can use the following shortcuts:</p>\n\n<ul>\n<li>‚¨ÜÔ∏è <strong>Up</strong> arrow ‚Äì go to the first page of the previous issue</li>\n<li>‚¨áÔ∏è <strong>Down</strong> arrow ‚Äì go the the first page of the next issue</li>\n<li>‚¨ÖÔ∏è <strong>Left</strong> arrow ‚Äì go to the previous page</li>\n<li>‚û°Ô∏è <strong>Right</strong> arrow ‚Äì go to the next page</li>\n</ul>\n\n<p>Go here for <a href=\"https://gist.github.com/wragge/af8bd20a14005d267ffc759463bd832c\">installation instructions</a>.</p>\n\n<p>This makes browsing through a newspaper <em>much</em> easier. Enjoy! #dhhacks</p>\n",
				"content_text": "If you like browsing Trove's digitised newspapers page by page, you might have found that the current interface is a bit clunky. To move between pages you have to hover over the page number and click on 'Next' or 'Previous'. Wouldn't it be good if you could just use the arrow keys on your keyboard? Well now you can!\n\nI've created a very simple script that allows you to use the arrows on your keyboard to move between pages in Trove's digitised newspapers. Once it's enabled you can use the following shortcuts:\n\n* ‚¨ÜÔ∏è **Up** arrow ‚Äì go to the first page of the previous issue\n* ‚¨áÔ∏è **Down** arrow ‚Äì go the the first page of the next issue\n* ‚¨ÖÔ∏è **Left** arrow ‚Äì go to the previous page\n* ‚û°Ô∏è **Right** arrow ‚Äì go to the next page\n\nGo here for [installation instructions](https://gist.github.com/wragge/af8bd20a14005d267ffc759463bd832c).\n\nThis makes browsing through a newspaper *much* easier. Enjoy! #dhhacks\n",
				"date_published": "2021-01-25T11:32:05+11:00",
				"url": "https://updates.timsherratt.org/2021/01/25/easy-browsing-of.html"
			},
			{
				"id": "http://wragge.micro.blog/2021/01/18/new-dataset-twenty.html",
				"title": "New dataset and notebooks ‚Äì twenty years of ABC Radio National",
				"content_html": "<p>There‚Äôs a <a href=\"https://glam-workbench.github.io/trove-music/\">new  GLAM Workbench section</a> for working with data from Trove‚Äôs Music &amp; Sound zone!</p>\n\n<p><strong>Inside you&rsquo;ll find out how to harvest all the metadata from ABC Radio National program records ‚Äì that&rsquo;s 400,000+ records, from 160 Radio National programs, over more than 20 years.</strong></p>\n\n<p>It‚Äôs metadata only, so not full transcripts or audio, though there are links back to the ABC site where you might find transcripts. Most records should at least have a title, a date, the name of the program it was broadcast on, a list of contributors, and perhaps a brief abstract/summary. It&rsquo;s also worth noting that many of these records, particularly those from the main current affairs programs, represent individual stories or segments ‚Äì so they provide a detailed record of the major news stories for the last couple of decades!</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/43f5a3e067.jpg\" width=\"600\" height=\"365\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2021/c1f9a22191.jpg\" width=\"600\" height=\"243\" alt=\"\" /></p>\n\n<p>The <a href=\"https://glam-workbench.github.io/trove-music/#harvest-abc-radio-national-records-from-trove\">harvesting notebook</a> shows you how to get the data from the Trove API. There are a number of duplicate records, and some inconsistencies in the way the data is formatted, so the harvesting code tries to clean things up a bit. You can of course adjust this to meet your own needs.</p>\n\n<p>If you don&rsquo;t want to do the harvesting yourself, there‚Äôs <a href=\"https://glam-workbench.github.io/trove-music/#abc-radio-national-programs\">pre-harvested datasets</a> that you can download immediately from Cloudstor and start exploring. The complete harvest of all 400,000+ records is available both in JSONL (newline separated JSON) and CSV formats. There&rsquo;s also a series of separate datasets for the most frequently occurring programs: RN Breakfast, RN Drive, AM, PM, The World Today, Late Night Live, Life Matters, and the Science Show.</p>\n\n<p>There‚Äôs also a <a href=\"https://glam-workbench.github.io/trove-music/#exploring-abc-radio-national-metadata\">notebook</a> that demonstrates a few possible ways you might start to play with the data ‚Äì looking at the range of programs, the distribution of records over time, the people involved in each story, and words in the titles of each segment.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/228b9e1e74.jpg\" width=\"600\" height=\"506\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2021/61b8d46dbe.jpg\" width=\"600\" height=\"300\" alt=\"\" /></p>\n\n<p>This is a very rich source of data for examining Australia&rsquo;s political and social history over the last twenty years. Dive in and see what you can find! #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/2e05accfd1.jpg\" width=\"403\" height=\"600\" alt=\"\" /></p>\n",
				"content_text": "There‚Äôs a [new  GLAM Workbench section](https://glam-workbench.github.io/trove-music/) for working with data from Trove‚Äôs Music & Sound zone!\n\n**Inside you'll find out how to harvest all the metadata from ABC Radio National program records ‚Äì that's 400,000+ records, from 160 Radio National programs, over more than 20 years.**\n\nIt‚Äôs metadata only, so not full transcripts or audio, though there are links back to the ABC site where you might find transcripts. Most records should at least have a title, a date, the name of the program it was broadcast on, a list of contributors, and perhaps a brief abstract/summary. It's also worth noting that many of these records, particularly those from the main current affairs programs, represent individual stories or segments ‚Äì so they provide a detailed record of the major news stories for the last couple of decades!\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/43f5a3e067.jpg\" width=\"600\" height=\"365\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2021/c1f9a22191.jpg\" width=\"600\" height=\"243\" alt=\"\" />\n\nThe [harvesting notebook](https://glam-workbench.github.io/trove-music/#harvest-abc-radio-national-records-from-trove) shows you how to get the data from the Trove API. There are a number of duplicate records, and some inconsistencies in the way the data is formatted, so the harvesting code tries to clean things up a bit. You can of course adjust this to meet your own needs.\n\nIf you don't want to do the harvesting yourself, there‚Äôs [pre-harvested datasets](https://glam-workbench.github.io/trove-music/#abc-radio-national-programs) that you can download immediately from Cloudstor and start exploring. The complete harvest of all 400,000+ records is available both in JSONL (newline separated JSON) and CSV formats. There's also a series of separate datasets for the most frequently occurring programs: RN Breakfast, RN Drive, AM, PM, The World Today, Late Night Live, Life Matters, and the Science Show.\n\nThere‚Äôs also a [notebook](https://glam-workbench.github.io/trove-music/#exploring-abc-radio-national-metadata) that demonstrates a few possible ways you might start to play with the data ‚Äì looking at the range of programs, the distribution of records over time, the people involved in each story, and words in the titles of each segment.\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/228b9e1e74.jpg\" width=\"600\" height=\"506\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2021/61b8d46dbe.jpg\" width=\"600\" height=\"300\" alt=\"\" />\n\nThis is a very rich source of data for examining Australia's political and social history over the last twenty years. Dive in and see what you can find! #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/2e05accfd1.jpg\" width=\"403\" height=\"600\" alt=\"\" />\n",
				"date_published": "2021-01-18T10:27:00+11:00",
				"url": "https://updates.timsherratt.org/2021/01/18/new-dataset-twenty.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2021/01/14/finding-nonenglish-newspapers.html",
				"title": "Finding non-English newspapers in Trove",
				"content_html": "<p>There are a growing number of non-English newspapers in Trove, but how do you know what&rsquo;s there? After trying a few different approaches, I generated a <a href=\"https://gist.github.com/wragge/9aa385648cff5f0de0c7d4837896df97\">list of 48 newspapers</a> with non-English content. The full details are <a href=\"https://nbviewer.jupyter.org/github/GLAM-Workbench/trove-newspapers/blob/88a4415cd64de28a1fccba8a787018c6143b1a09/find-non-english-newspapers.ipynb\">in this notebook</a>).</p>\n\n<p>As the notebook describes, I found the language metadata for newspapers was incomplete, so I used some language detection code on a sample of articles from every newspaper to try and find those with non-English content. But this had its own problems ‚Äì such as the fact that the language detection code thought that bad OCR looked like Maltese&hellip;</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/3ac74cebb8.jpg\" width=\"600\" height=\"225\" alt=\"\" /></p>\n\n<p>Anyway, if you‚Äôre just searching using English keywords, you might not even be aware that these titles exist. It‚Äôs important to explore ways of making diversity visible within large digitised collections. #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/d3c0de69dc.jpg\" width=\"600\" height=\"514\" alt=\"\" /></p>\n",
				"content_text": "There are a growing number of non-English newspapers in Trove, but how do you know what's there? After trying a few different approaches, I generated a [list of 48 newspapers](https://gist.github.com/wragge/9aa385648cff5f0de0c7d4837896df97) with non-English content. The full details are [in this notebook](https://nbviewer.jupyter.org/github/GLAM-Workbench/trove-newspapers/blob/88a4415cd64de28a1fccba8a787018c6143b1a09/find-non-english-newspapers.ipynb)).\n\nAs the notebook describes, I found the language metadata for newspapers was incomplete, so I used some language detection code on a sample of articles from every newspaper to try and find those with non-English content. But this had its own problems ‚Äì such as the fact that the language detection code thought that bad OCR looked like Maltese...\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/3ac74cebb8.jpg\" width=\"600\" height=\"225\" alt=\"\" />\n\nAnyway, if you‚Äôre just searching using English keywords, you might not even be aware that these titles exist. It‚Äôs important to explore ways of making diversity visible within large digitised collections. #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/d3c0de69dc.jpg\" width=\"600\" height=\"514\" alt=\"\" />\n",
				"date_published": "2021-01-14T16:17:00+11:00",
				"url": "https://updates.timsherratt.org/2021/01/14/finding-nonenglish-newspapers.html"
			},
			{
				"id": "http://wragge.micro.blog/2021/01/14/last-year-i.html",
				"title": "Open access versions of Australian history articles",
				"content_html": "<p>Last year I did some analysis of the availability of open access versions of research articles published between 2008 and 2018 in <em>Australian Historical Studies</em>. I&rsquo;ve now broadened this out to cover all individual articles (with a DOI) across a number of journals. It&rsquo;s pretty grim. Despite Green OA policies that allow researchers to share versions of their articles through institutional repositories, Australian history journals still seem to be about 94% closed.</p>\n\n<p>Full details are <a href=\"https://nbviewer.jupyter.org/github/wragge/ozhist-openaccess/blob/9e1f81cd3917a1a01b2cf4ac6cc376a63c9ff0a3/open_access_versions_australian_hass_journals.ipynb\">in this notebook</a>.</p>\n\n<p><strong>But this can be fixed!</strong> If you&rsquo;re in a university, talk to your librarians about depositing a Green OA version of your article in an institutional repository. If not, you can use the <a href=\"https://shareyourpaper.org/\">Share your paper</a> service to upload a Green OA version to Zenodo. Your research will be easier to find, easier to access, easier to cite, and available to everyone ‚Äì not just those with the luxury of an institutional subscription. #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2021/cd60058555.jpg\" width=\"600\" height=\"311\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2021/4484496c82.jpg\" width=\"600\" height=\"293\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2021/b873500284.jpg\" width=\"600\" height=\"501\" alt=\"\" /></p>\n",
				"content_text": "Last year I did some analysis of the availability of open access versions of research articles published between 2008 and 2018 in *Australian Historical Studies*. I've now broadened this out to cover all individual articles (with a DOI) across a number of journals. It's pretty grim. Despite Green OA policies that allow researchers to share versions of their articles through institutional repositories, Australian history journals still seem to be about 94% closed.\n\nFull details are [in this notebook](https://nbviewer.jupyter.org/github/wragge/ozhist-openaccess/blob/9e1f81cd3917a1a01b2cf4ac6cc376a63c9ff0a3/open_access_versions_australian_hass_journals.ipynb).\n\n**But this can be fixed!** If you're in a university, talk to your librarians about depositing a Green OA version of your article in an institutional repository. If not, you can use the [Share your paper](https://shareyourpaper.org/) service to upload a Green OA version to Zenodo. Your research will be easier to find, easier to access, easier to cite, and available to everyone ‚Äì not just those with the luxury of an institutional subscription. #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2021/cd60058555.jpg\" width=\"600\" height=\"311\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2021/4484496c82.jpg\" width=\"600\" height=\"293\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2021/b873500284.jpg\" width=\"600\" height=\"501\" alt=\"\" />\n",
				"date_published": "2021-01-14T16:03:00+11:00",
				"url": "https://updates.timsherratt.org/2021/01/14/last-year-i.html"
			},
			{
				"id": "http://wragge.micro.blog/2021/01/03/a-long-thread.html",
				
				"content_html": "<p>A <em>long</em> thread exploring files in the National Archives of Australia with the access status of &lsquo;closed‚Äô. This is the 6th consecutive year I‚Äôve harvested &lsquo;closed&rsquo; files on or about 1 January.</p>\n\n<p><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">It‚Äôs January 1, the day each year when our minds turn to newly released Cabinet records from <a href=\"https://twitter.com/naagovau?ref_src=twsrc%5Etfw\">@naagovau</a>. But while the media focuses on the records that have been made open, I‚Äôll be spending the day looking at those that were closed. What weren‚Äôt you allowed to see in 2020?</p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1344805120261832705?ref_src=twsrc%5Etfw\">January 1, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script></p>\n",
				"content_text": "A *long* thread exploring files in the National Archives of Australia with the access status of 'closed‚Äô. This is the 6th consecutive year I‚Äôve harvested 'closed' files on or about 1 January.\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">It‚Äôs January 1, the day each year when our minds turn to newly released Cabinet records from <a href=\"https://twitter.com/naagovau?ref_src=twsrc%5Etfw\">@naagovau</a>. But while the media focuses on the records that have been made open, I‚Äôll be spending the day looking at those that were closed. What weren‚Äôt you allowed to see in 2020?</p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1344805120261832705?ref_src=twsrc%5Etfw\">January 1, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script> \n",
				"date_published": "2021-01-03T11:44:00+11:00",
				"url": "https://updates.timsherratt.org/2021/01/03/a-long-thread.html"
			},
			{
				"id": "http://wragge.micro.blog/2021/01/03/more-updates-from.html",
				
				"content_html": "<p>More updates from The Real Face of White Australia ‚Äì running facial detection code over NAA: SP42/1.</p>\n\n<p><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Finished! NAA: SP42/1 is a general correspondence series from the Collector of Customs in Sydney. It includes many files relating to the administration of the White Australia Policy. 3,375 files have been digitised (about 20% of the series), that‚Äôs 49,781 digital images. <a href=\"https://t.co/Y1ZoAYSXeP\">https://t.co/Y1ZoAYSXeP</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1344230640149938177?ref_src=twsrc%5Etfw\">December 30, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script></p>\n",
				"content_text": "More updates from The Real Face of White Australia ‚Äì running facial detection code over NAA: SP42/1. \n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Finished! NAA: SP42/1 is a general correspondence series from the Collector of Customs in Sydney. It includes many files relating to the administration of the White Australia Policy. 3,375 files have been digitised (about 20% of the series), that‚Äôs 49,781 digital images. <a href=\"https://t.co/Y1ZoAYSXeP\">https://t.co/Y1ZoAYSXeP</a></p>&mdash; Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1344230640149938177?ref_src=twsrc%5Etfw\">December 30, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script> \n",
				"date_published": "2021-01-03T11:41:13+11:00",
				"url": "https://updates.timsherratt.org/2021/01/03/more-updates-from.html"
			},
			{
				"id": "http://wragge.micro.blog/2021/01/03/httpstwittercomwraggestatus.html",
				
				"content_html": "<p><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">I reharvested NAA: ST84/1 and ended up with 14,545 images from 461 digitised files (about 17% of the total series).<br><br>In these images I found 9,970 faces ‚Äì this is a couple of thousand more than when I used OpenCV in 2010/11 for the original wall of faces. <a href=\"https://t.co/BAnkX7u83S\">https://t.co/BAnkX7u83S</a></p>‚Äî Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1342987632519745536?ref_src=twsrc%5Etfw\">December 27, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script></p>\n",
				"content_text": "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">I reharvested NAA: ST84/1 and ended up with 14,545 images from 461 digitised files (about 17% of the total series).<br><br>In these images I found 9,970 faces ‚Äì this is a couple of thousand more than when I used OpenCV in 2010/11 for the original wall of faces. <a href=\"https://t.co/BAnkX7u83S\">https://t.co/BAnkX7u83S</a></p>‚Äî Tim Sherratt (@wragge) <a href=\"https://twitter.com/wragge/status/1342987632519745536?ref_src=twsrc%5Etfw\">December 27, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script> \n",
				"date_published": "2021-01-03T11:34:00+11:00",
				"url": "https://updates.timsherratt.org/2021/01/03/httpstwittercomwraggestatus.html"
			},
			{
				"id": "http://wragge.micro.blog/2020/12/16/glam-workbench-wins.html",
				"title": "GLAM Workbench wins British Library Labs Research Award!",
				"content_html": "<p><strong>Asking questions with web archives ‚Äì introductory notebooks for historians</strong> has won the British Library Labs Research Award for 2020. <a href=\"https://data.bl.uk/bl_labs_awards/index.html\">The awards</a> recognise &lsquo;exceptional projects that have used the Library‚Äôs digital collections and data&rsquo;.</p>\n\n<p>This project gave me a chance to work with web archives collections and staff from the British Library, the National Library of Australia, and the National Library of New Zealand, and was <a href=\"https://netpreserve.org/projects/jupyter-notebooks-for-historians/\">supported</a> by the International Internet Preservation Consortium&rsquo;s Discretionary Funding Program.</p>\n\n<p>We developed a range of tools, examples, and documentation to help researchers use and explore the vast historical resources available through web archives. A new <a href=\"https://glam-workbench.github.io/web-archives/\">web archives section</a> was added to the GLAM Workbench, and 16 Jupyter notebooks, combining text, images, and live code, were created.</p>\n\n<p>Here&rsquo;s a <a href=\"https://youtu.be/qhaRQ0LxNAo\">30 second summary</a> of the project!</p>\n\n<p>The judges noted:</p>\n\n<blockquote>\n<p>‚ÄúThe panel were impressed with the level of documentation and thought that went into how to work computationally through Jupyter notebooks with web archives which are challenging to work with because of their size. These tools were some of the first of their kind.</p>\n\n<p>‚ÄúThe Labs Advisory Board wanted to acknowledge and reward the incredible work of Tim Sherratt in particular. Tim you have been a pioneer as a one-person lab over many years and these 16 notebooks are a fine addition to your already extensive suite in your GLAM Workbench. Your work has inspired so many in GLAM, the humanities community, and BL Labs to develop their own notebooks. To our audience, we strongly recommend that you look at the GLAM Workbench if you‚Äôre interested in doing computational experiments with many institutions‚Äô data sources.</p>\n</blockquote>\n\n<p>Thanks to Andy, Olga, Alex, and Ben for your advice and support. And thanks to the British Library Labs for the award! #dhhacks</p>\n",
				"content_text": "**Asking questions with web archives ‚Äì introductory notebooks for historians** has won the British Library Labs Research Award for 2020. [The awards](https://data.bl.uk/bl_labs_awards/index.html) recognise 'exceptional projects that have used the Library‚Äôs digital collections and data'.\n\nThis project gave me a chance to work with web archives collections and staff from the British Library, the National Library of Australia, and the National Library of New Zealand, and was [supported](https://netpreserve.org/projects/jupyter-notebooks-for-historians/) by the International Internet Preservation Consortium's Discretionary Funding Program.\n\nWe developed a range of tools, examples, and documentation to help researchers use and explore the vast historical resources available through web archives. A new [web archives section](https://glam-workbench.github.io/web-archives/) was added to the GLAM Workbench, and 16 Jupyter notebooks, combining text, images, and live code, were created.\n\nHere's a [30 second summary](https://youtu.be/qhaRQ0LxNAo) of the project! \n\nThe judges noted:\n\n> ‚ÄúThe panel were impressed with the level of documentation and thought that went into how to work computationally through Jupyter notebooks with web archives which are challenging to work with because of their size. These tools were some of the first of their kind.\n\n> ‚ÄúThe Labs Advisory Board wanted to acknowledge and reward the incredible work of Tim Sherratt in particular. Tim you have been a pioneer as a one-person lab over many years and these 16 notebooks are a fine addition to your already extensive suite in your GLAM Workbench. Your work has inspired so many in GLAM, the humanities community, and BL Labs to develop their own notebooks. To our audience, we strongly recommend that you look at the GLAM Workbench if you‚Äôre interested in doing computational experiments with many institutions‚Äô data sources.\n\nThanks to Andy, Olga, Alex, and Ben for your advice and support. And thanks to the British Library Labs for the award! #dhhacks\n",
				"date_published": "2020-12-16T11:46:00+11:00",
				"url": "https://updates.timsherratt.org/2020/12/16/glam-workbench-wins.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/12/15/want-to-relive.html",
				
				"content_html": "<p>Want to relive the early days of digital humanities in Australia? I‚Äôve <a href=\"https://thatcampcanberra.org/\">archived the websites</a> created for THATCamp Canberra in 2010, 2011, and 2014. They&rsquo;re now static sites so search and commenting won‚Äôt work, but all the content should be there! #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/9be0a05dcd.jpg\" width=\"600\" height=\"489\" alt=\"\" /></p>\n",
				"content_text": "Want to relive the early days of digital humanities in Australia? I‚Äôve [archived the websites](https://thatcampcanberra.org/) created for THATCamp Canberra in 2010, 2011, and 2014. They're now static sites so search and commenting won‚Äôt work, but all the content should be there! #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/9be0a05dcd.jpg\" width=\"600\" height=\"489\" alt=\"\" />\n",
				"date_published": "2020-12-15T13:55:00+11:00",
				"url": "https://updates.timsherratt.org/2020/12/15/want-to-relive.html"
			},
			{
				"id": "http://wragge.micro.blog/2020/12/15/the-invisible-australians.html",
				
				"content_html": "<p>The <em>Invisible Australians</em> website has been given a much needed overhaul, and we‚Äôve brought all our related projects together under the title <a href=\"https://www.realfaceofwhiteaustralia.net/\">The real face of White Australia</a>. This includes an updated version of the wall of faces. #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/2a72ceb53a.jpg\" width=\"600\" height=\"407\" alt=\"\" /></p>\n",
				"content_text": "The *Invisible Australians* website has been given a much needed overhaul, and we‚Äôve brought all our related projects together under the title [The real face of White Australia](https://www.realfaceofwhiteaustralia.net/). This includes an updated version of the wall of faces. #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/2a72ceb53a.jpg\" width=\"600\" height=\"407\" alt=\"\" />\n",
				"date_published": "2020-12-15T13:51:38+11:00",
				"url": "https://updates.timsherratt.org/2020/12/15/the-invisible-australians.html"
			},
			{
				"id": "http://wragge.micro.blog/2020/12/15/the-glam-workbench.html",
				"title": "The GLAM Workbench as research infrastructure (some basic stats)",
				"content_html": "<p>Repositories in the <a href=\"https://glam-workbench.github.io/\">GLAM Workbench</a> have been launched on <a href=\"https://mybinder.org/\">Binder</a> 3,529 times since the start of this year (according to data from the <a href=\"https://archive.analytics.mybinder.org\">Binder Events log</a>). That‚Äôs repository launches, not notebooks. Having launched a repository, users might use multiple notebooks. And of course these stats don‚Äôt include people using the notebooks in contexts other than Binder ‚Äì on their own machines, servers, or services like AARNet‚Äôs SWAN. Or just viewing the notebooks in GitHub and copying code into their own projects.</p>\n\n<p>I‚Äôm suspicious of web stats, but the Binder data indicates that people have actually done more than ‚Äòvisit‚Äô ‚Äì they‚Äôve spun up a Binder session ready to do some exploration.</p>\n\n<p>Every Jupyter notebook in the GLAM Workbench has a link that opens the notebook in Binder. If you click on the link, Binder reads configuration details from the repository and loads a customised computing environment. All in your browser! That means you can start using the GLAM Workbench without installing any software. Just click on the Binder link and start exploring!</p>\n\n<p>There are about <a href=\"https://github.com/GLAM-Workbench/\">40 different repositories</a> in the GLAM Workbench, helping you work with data from Trove, DigitalNZ, NAA, SLNSW, NSW Archives, NMA, ArchivesNZ, ANU Archives &amp; more! The image below shows them ranked by number of Binder launches this year.</p>\n\n<p>The <a href=\"https://glam-workbench.github.io/web-archives/\">web archives section</a> was added this year in collaboration with the IIPC, the UK Web Archive, the Australian Web Archive, and the NZ Web Archive. Its annual number of launches is inflated a bit by the development process. But there‚Äôs been 426 launches since it went public in June.</p>\n\n<p>I‚Äôm really pleased to see the <a href=\"https://glam-workbench.github.io/trove-harvester/\">Trove newspaper harvester</a> up near the top. At least once a day (on average) someone‚Äôs been firing up the repository to grab Trove newspaper articles in bulk.</p>\n\n<p>Overall, that‚Äôs about 11 GLAM Workbench repository launches a day on Binder. It might not seem like much, but that‚Äôs 11 research opportunities that didn‚Äôt exist before, 11 GLAM collections opened to exploration, 11 researchers building their digital skills‚Ä¶</p>\n\n<p>As humanities researchers continue to learn of the possibilities of GLAM data and develop their digital skills the numbers will grow. It‚Äôs a start. And a reminder that not all research infrastructure needs to be built in Go8 unis, by large teams, with $millions. We can all contribute by sharing our tools and methods. #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/5db095f0fe.jpg\" width=\"600\" height=\"592\" alt=\"\" /></p>\n",
				"content_text": "Repositories in the [GLAM Workbench](https://glam-workbench.github.io/) have been launched on [Binder](https://mybinder.org/) 3,529 times since the start of this year (according to data from the [Binder Events log](https://archive.analytics.mybinder.org)). That‚Äôs repository launches, not notebooks. Having launched a repository, users might use multiple notebooks. And of course these stats don‚Äôt include people using the notebooks in contexts other than Binder ‚Äì on their own machines, servers, or services like AARNet‚Äôs SWAN. Or just viewing the notebooks in GitHub and copying code into their own projects.\n\nI‚Äôm suspicious of web stats, but the Binder data indicates that people have actually done more than ‚Äòvisit‚Äô ‚Äì they‚Äôve spun up a Binder session ready to do some exploration.\n\nEvery Jupyter notebook in the GLAM Workbench has a link that opens the notebook in Binder. If you click on the link, Binder reads configuration details from the repository and loads a customised computing environment. All in your browser! That means you can start using the GLAM Workbench without installing any software. Just click on the Binder link and start exploring!\n\nThere are about [40 different repositories](https://github.com/GLAM-Workbench/) in the GLAM Workbench, helping you work with data from Trove, DigitalNZ, NAA, SLNSW, NSW Archives, NMA, ArchivesNZ, ANU Archives & more! The image below shows them ranked by number of Binder launches this year.\n\nThe [web archives section](https://glam-workbench.github.io/web-archives/) was added this year in collaboration with the IIPC, the UK Web Archive, the Australian Web Archive, and the NZ Web Archive. Its annual number of launches is inflated a bit by the development process. But there‚Äôs been 426 launches since it went public in June.\n\nI‚Äôm really pleased to see the [Trove newspaper harvester](https://glam-workbench.github.io/trove-harvester/) up near the top. At least once a day (on average) someone‚Äôs been firing up the repository to grab Trove newspaper articles in bulk. \n\nOverall, that‚Äôs about 11 GLAM Workbench repository launches a day on Binder. It might not seem like much, but that‚Äôs 11 research opportunities that didn‚Äôt exist before, 11 GLAM collections opened to exploration, 11 researchers building their digital skills‚Ä¶\n\nAs humanities researchers continue to learn of the possibilities of GLAM data and develop their digital skills the numbers will grow. It‚Äôs a start. And a reminder that not all research infrastructure needs to be built in Go8 unis, by large teams, with $millions. We can all contribute by sharing our tools and methods. #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/5db095f0fe.jpg\" width=\"600\" height=\"592\" alt=\"\" />\n",
				"date_published": "2020-12-15T10:43:00+11:00",
				"url": "https://updates.timsherratt.org/2020/12/15/the-glam-workbench.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/11/27/earlier-this-year.html",
				
				"content_html": "<p>Earlier this year I gave a seminar for the International Internet Preservation Consortium (IIPC) introducing the <a href=\"https://glam-workbench.github.io/web-archives/\">web archives section</a> of the GLAM Workbench. The seminar is now available online: <a href=\"https://youtu.be/rVidh_wexoo\">youtu.be/rVidh_wex&hellip;</a></p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/51f7e056dd.jpg\" width=\"600\" height=\"397\" alt=\"\" /></p>\n\n<p>Here are <a href=\"https://slides.com/wragge/iipc-jupyter\">the slides</a> if you want to follow along. #dhhacks</p>\n",
				"content_text": "Earlier this year I gave a seminar for the International Internet Preservation Consortium (IIPC) introducing the [web archives section](https://glam-workbench.github.io/web-archives/) of the GLAM Workbench. The seminar is now available online: [youtu.be/rVidh_wex...](https://youtu.be/rVidh_wexoo) \n\n<img src=\"https://updates.timsherratt.org/uploads/2020/51f7e056dd.jpg\" width=\"600\" height=\"397\" alt=\"\" />\n\nHere are [the slides](https://slides.com/wragge/iipc-jupyter) if you want to follow along. #dhhacks\n",
				"date_published": "2020-11-27T16:02:00+11:00",
				"url": "https://updates.timsherratt.org/2020/11/27/earlier-this-year.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/11/25/harvest-text-from.html",
				"title": "Harvest text from the Australian Women's Weekly!",
				"content_html": "<p>The Trove Newspaper &amp; Gazette Harvester has been updated to version 0.4.0. The major change is that if the OCRd text for an article isn&rsquo;t available through the API, it will be automatically downloaded via the web interface. What does this mean in practice? Well previously you couldn&rsquo;t harvest OCRd text from the <em>Australian Women&rsquo;s Weekly</em> because it&rsquo;s not included in API results, but now you can!</p>\n\n<p>You don&rsquo;t need to do anything differently. If there are AWW articles in your search, and you ask for all the OCRd text using the <code>--text</code> option, the AWW text files will automagically appear in your harvest.</p>\n\n<p>Under the hood, I&rsquo;ve started using <a href=\"https://pypi.org/project/html2text/\">html2text</a> to remove tags from the OCRd text. I think this should produce more consistent results. As previously, line breaks are removed by default from the OCRd text files. However, I&rsquo;ve now added a <code>--include_linebreaks</code> option if you&rsquo;d like to keep them. This generally produces text that is more human-readable, but note that the line breaks produced by OCR aren&rsquo;t always accurate.</p>\n\n<p>Head to the <a href=\"https://glam-workbench.github.io/trove-harvester/\">GLAM Workbench to try it out</a>, or <a href=\"https://pypi.org/project/troveharvester/0.4.0/\">download the code from PyPi</a>. #dhhacks</p>\n",
				"content_text": "The Trove Newspaper & Gazette Harvester has been updated to version 0.4.0. The major change is that if the OCRd text for an article isn't available through the API, it will be automatically downloaded via the web interface. What does this mean in practice? Well previously you couldn't harvest OCRd text from the *Australian Women's Weekly* because it's not included in API results, but now you can!\n\nYou don't need to do anything differently. If there are AWW articles in your search, and you ask for all the OCRd text using the `--text` option, the AWW text files will automagically appear in your harvest.\n\nUnder the hood, I've started using [html2text](https://pypi.org/project/html2text/) to remove tags from the OCRd text. I think this should produce more consistent results. As previously, line breaks are removed by default from the OCRd text files. However, I've now added a `--include_linebreaks` option if you'd like to keep them. This generally produces text that is more human-readable, but note that the line breaks produced by OCR aren't always accurate.\n\nHead to the [GLAM Workbench to try it out](https://glam-workbench.github.io/trove-harvester/), or [download the code from PyPi](https://pypi.org/project/troveharvester/0.4.0/). #dhhacks\n",
				"date_published": "2020-11-25T15:52:00+11:00",
				"url": "https://updates.timsherratt.org/2020/11/25/harvest-text-from.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/11/13/beyond-the-copyright.html",
				"title": "Beyond the copyright cliff of death",
				"content_html": "<p>If you&rsquo;ve done any searching in Trove&rsquo;s digitised newspapers, you&rsquo;ve probably noticed that there aren&rsquo;t many results after 1954. This is basically because of copyright restrictions (though given the complexities of Australia&rsquo;s copyright system, you can&rsquo;t be sure that everything published before 1955 is <em>out</em> of copyright). We can visualise the impact of this by looking at the number of newspaper articles in Trove by year.</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/dcf55d9941.jpg\" width=\"600\" height=\"333\" alt=\"\" /></p>\n\n<p>You can see why I started referring to it as the <strong>copyright cliff of death</strong>.</p>\n\n<p>But you can also see a little trickle of articles continuing post-1954. The number of newspapers from beyond the copyright cliff of death continues to increase as agreements are made with publishers to put them online. I just checked and there&rsquo;s now 83 newspapers that have at least <em>some</em> post-1954 articles available. Here&rsquo;s the top 10 (by number of articles).</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/95e9d27bd6.jpg\" width=\"600\" height=\"223\" alt=\"\" /></p>\n\n<p>If you&rsquo;d like to browse the full list of post-1954 newspapers, <a href=\"https://github.com/GLAM-Workbench/trove-newspapers/blob/master/newspapers_post_54.csv\">here&rsquo;s the data</a> as a CSV (spreadsheet) file.</p>\n\n<p>If you&rsquo;d like to see how I generated this list, have a look <a href=\"https://glam-workbench.github.io/trove-newspapers/#beyond-the-copyright-cliff-of-death\">at this notebook</a> in the Trove Newspapers section of the GLAM Workbench.</p>\n\n<p>If you&rsquo;d like to know how I created the chart above, have a look at <a href=\"https://glam-workbench.github.io/trove-newspapers/#visualise-the-total-number-of-newspaper-articles-in-trove-by-year-and-state\">Visualise the total number of newspaper articles in Trove by year and state</a>. #dhhacks</p>\n\n<p>Questions? Ask away at <a href=\"https://ozglam.chat/t/trove-newspapers-and-the-copyright-cliff-of-death/94?u=wragge\">OzGLAM Help</a>. #dhhacks</p>\n",
				"content_text": "If you've done any searching in Trove's digitised newspapers, you've probably noticed that there aren't many results after 1954. This is basically because of copyright restrictions (though given the complexities of Australia's copyright system, you can't be sure that everything published before 1955 is *out* of copyright). We can visualise the impact of this by looking at the number of newspaper articles in Trove by year.\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/dcf55d9941.jpg\" width=\"600\" height=\"333\" alt=\"\" />\n\nYou can see why I started referring to it as the **copyright cliff of death**.\n\nBut you can also see a little trickle of articles continuing post-1954. The number of newspapers from beyond the copyright cliff of death continues to increase as agreements are made with publishers to put them online. I just checked and there's now 83 newspapers that have at least *some* post-1954 articles available. Here's the top 10 (by number of articles).\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/95e9d27bd6.jpg\" width=\"600\" height=\"223\" alt=\"\" />\n\nIf you'd like to browse the full list of post-1954 newspapers, [here's the data](https://github.com/GLAM-Workbench/trove-newspapers/blob/master/newspapers_post_54.csv) as a CSV (spreadsheet) file.\n\nIf you'd like to see how I generated this list, have a look [at this notebook](https://glam-workbench.github.io/trove-newspapers/#beyond-the-copyright-cliff-of-death) in the Trove Newspapers section of the GLAM Workbench.\n\nIf you'd like to know how I created the chart above, have a look at [Visualise the total number of newspaper articles in Trove by year and state](https://glam-workbench.github.io/trove-newspapers/#visualise-the-total-number-of-newspaper-articles-in-trove-by-year-and-state). #dhhacks\n\nQuestions? Ask away at [OzGLAM Help](https://ozglam.chat/t/trove-newspapers-and-the-copyright-cliff-of-death/94?u=wragge). #dhhacks\n\n",
				"date_published": "2020-11-13T09:56:00+11:00",
				"url": "https://updates.timsherratt.org/2020/11/13/beyond-the-copyright.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/11/13/updated-find-trove.html",
				
				"content_html": "<p>Updated! Find Trove newspapers by place of publication by using this simple interface ‚Äì just <a href=\"https://troveplaces.herokuapp.com/map/\">click on the map</a> to find the 10 closest newspapers. Now including newspapers added to Trove since June.</p>\n\n<p>You can also <a href=\"https://troveplaces.herokuapp.com/all/\">browse the locations</a> of all newspapers across Australia.</p>\n\n<p>The underlying data file is <a href=\"https://docs.google.com/spreadsheets/d/1rURriHBSf3MocI8wsdl1114t0YeyU0BVSXWeg232MZs/edit?usp=sharing\">available as a spreadsheet</a>. Feel free to add a comment if you notice any problems. I‚Äôm geolocating place names found in newspaper titles, so it‚Äôs not always exact.</p>\n\n<p>Questions? Ask away at <a href=\"https://ozglam.chat/t/find-trove-newspapers-by-place/92?u=wragge\">OzGLAM Help</a>. #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/51a7f4f97a.jpg\" width=\"600\" height=\"548\" alt=\"\" /></p>\n",
				"content_text": "Updated! Find Trove newspapers by place of publication by using this simple interface ‚Äì just [click on the map](https://troveplaces.herokuapp.com/map/) to find the 10 closest newspapers. Now including newspapers added to Trove since June.\n\nYou can also [browse the locations](https://troveplaces.herokuapp.com/all/) of all newspapers across Australia.\n\nThe underlying data file is [available as a spreadsheet](https://docs.google.com/spreadsheets/d/1rURriHBSf3MocI8wsdl1114t0YeyU0BVSXWeg232MZs/edit?usp=sharing). Feel free to add a comment if you notice any problems. I‚Äôm geolocating place names found in newspaper titles, so it‚Äôs not always exact. \n\nQuestions? Ask away at [OzGLAM Help](https://ozglam.chat/t/find-trove-newspapers-by-place/92?u=wragge). #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/51a7f4f97a.jpg\" width=\"600\" height=\"548\" alt=\"\" />\n",
				"date_published": "2020-11-13T09:52:00+11:00",
				"url": "https://updates.timsherratt.org/2020/11/13/updated-find-trove.html"
			},
			{
				"id": "http://wragge.micro.blog/2020/10/26/ive-added-a.html",
				
				"content_html": "<p>I‚Äôve added a <a href=\"https://glam-workbench.github.io/anu-archives/\">new section to the GLAM Workbench</a> for the ANU Archives. The first set of notebooks relates to the <a href=\"http://archivescollection.anu.edu.au/index.php/or59j\">Sydney Stock exchange stock and share lists</a>. As the content note describes:</p>\n\n<blockquote>\n<p>These are large format bound volumes of the official lists that were posted up for the public to see - 3 times a day - forenoon, noon and afternoon - at the close of the trading session in the call room at the Sydney Stock Exchange. The closing prices of stocks and shares were entered in by hand on pre-printed sheets.</p>\n</blockquote>\n\n<p>The volumes have been digitised, resulting in a collection of 70,000+ high resolution images. You can browse the details of each volume using <a href=\"https://nbviewer.jupyter.org/github/GLAM-Workbench/anu-archives/blob/master/stock-exchange-details-by-volume.ipynb\">this notebook</a>.</p>\n\n<p>I‚Äôve been exploring ways of getting useful, machine-readable data out of the images. There‚Äôs more information about the processes involved in <a href=\"https://github.com/wragge/sydney-stock-exchange\">this repository</a>. I‚Äôve also been working on improving the metadata and have managed to assign a date and session (Morning, Noon, or Afternoon) to each page. We these, we can start to explore the content!</p>\n\n<p>One of the notebooks creates a <a href=\"https://nbviewer.jupyter.org/github/GLAM-Workbench/anu-archives/blob/master/stock-exchange-pages-calendar.ipynb\">calendar-like view</a> of the whole collection, showing the number of pages surviving from each trading day. This makes it easy to find the gaps and changes in process. #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/00cfdb0dde.jpg\" width=\"600\" height=\"470\" alt=\"\" /></p>\n",
				"content_text": "I‚Äôve added a [new section to the GLAM Workbench](https://glam-workbench.github.io/anu-archives/) for the ANU Archives. The first set of notebooks relates to the [Sydney Stock exchange stock and share lists](http://archivescollection.anu.edu.au/index.php/or59j). As the content note describes:\n\n> These are large format bound volumes of the official lists that were posted up for the public to see - 3 times a day - forenoon, noon and afternoon - at the close of the trading session in the call room at the Sydney Stock Exchange. The closing prices of stocks and shares were entered in by hand on pre-printed sheets.\n\nThe volumes have been digitised, resulting in a collection of 70,000+ high resolution images. You can browse the details of each volume using [this notebook](https://nbviewer.jupyter.org/github/GLAM-Workbench/anu-archives/blob/master/stock-exchange-details-by-volume.ipynb).\n\nI‚Äôve been exploring ways of getting useful, machine-readable data out of the images. There‚Äôs more information about the processes involved in [this repository](https://github.com/wragge/sydney-stock-exchange). I‚Äôve also been working on improving the metadata and have managed to assign a date and session (Morning, Noon, or Afternoon) to each page. We these, we can start to explore the content!\n\nOne of the notebooks creates a [calendar-like view](https://nbviewer.jupyter.org/github/GLAM-Workbench/anu-archives/blob/master/stock-exchange-pages-calendar.ipynb) of the whole collection, showing the number of pages surviving from each trading day. This makes it easy to find the gaps and changes in process. #dhhacks\n\n\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/00cfdb0dde.jpg\" width=\"600\" height=\"470\" alt=\"\" />\n",
				"date_published": "2020-10-26T17:15:00+11:00",
				"url": "https://updates.timsherratt.org/2020/10/26/ive-added-a.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/10/26/any-regular-user.html",
				
				"content_html": "<p>Any regular user of RecordSearch, the National Archives of Australia‚Äôs online database, will understand its frustrations. But here‚Äôs a handy little hack to fix a couple of annoying problems and add some useful functionality!</p>\n\n<p>The <a href=\"https://gist.github.com/wragge/b2af9dc56f7cb0a9476b\">RecordSearch Show Pages userscript</a> updates links to digitised files in search results and item details pages, inserting the number of pages in a file. This means that you can easily scan a list of search results to see where the big fat files are, without having to click through to each one individually.</p>\n\n<p>But wait there‚Äôs more! The script also rewrites the link to the digitised file viewer so that it opens in the current tab, as you would expect, and not in an annoying pop up window!</p>\n\n<p>And as an extra bonus if you install now, the script also inserts a link on the barcode of an item in the digitised file viewer that takes you back to the item details page. Links to the digitised file viewer are shareable (unlike most RecordSearch links), but they don‚Äôt give you a way to find more information about the item. That problem is also fixed by this handy little script.</p>\n\n<p>For more information see <a href=\"https://ozglam.chat/t/some-diy-recordsearch-improvements/76?u=wragge\">OzGLAM Help</a>. #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/e406561e28.jpg\" width=\"600\" height=\"285\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/034c445232.jpg\" width=\"600\" height=\"369\" alt=\"\" /></p>\n",
				"content_text": "Any regular user of RecordSearch, the National Archives of Australia‚Äôs online database, will understand its frustrations. But here‚Äôs a handy little hack to fix a couple of annoying problems and add some useful functionality!\n\nThe [RecordSearch Show Pages userscript](https://gist.github.com/wragge/b2af9dc56f7cb0a9476b) updates links to digitised files in search results and item details pages, inserting the number of pages in a file. This means that you can easily scan a list of search results to see where the big fat files are, without having to click through to each one individually.\n\nBut wait there‚Äôs more! The script also rewrites the link to the digitised file viewer so that it opens in the current tab, as you would expect, and not in an annoying pop up window!\n\nAnd as an extra bonus if you install now, the script also inserts a link on the barcode of an item in the digitised file viewer that takes you back to the item details page. Links to the digitised file viewer are shareable (unlike most RecordSearch links), but they don‚Äôt give you a way to find more information about the item. That problem is also fixed by this handy little script.\n\nFor more information see [OzGLAM Help](https://ozglam.chat/t/some-diy-recordsearch-improvements/76?u=wragge). #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/e406561e28.jpg\" width=\"600\" height=\"285\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/034c445232.jpg\" width=\"600\" height=\"369\" alt=\"\" />\n",
				"date_published": "2020-10-26T17:10:00+11:00",
				"url": "https://updates.timsherratt.org/2020/10/26/any-regular-user.html"
			},
			{
				"id": "http://wragge.micro.blog/2020/10/26/ive-added-more.html",
				
				"content_html": "<p>I‚Äôve added more years to my <a href=\"https://github.com/wragge/hansard-xml\">repository of Commonwealth Hansard</a>! The repository now includes XML-formatted text files for both houses from 1901 to 1980, and 1998 to 2005. I‚Äôve done some more checking and confirmed that the XML files for 1981 to 1997 aren&rsquo;t currently available through ParlInfo, however, the Parliamentary Library are looking into it. I‚Äôve also created a <a href=\"https://github.com/GLAM-Workbench/australian-commonwealth-hansard/blob/master/data/all-sitting-days.csv\">CSV-formatted list of sitting days</a> from 1901 to 2005 (based on ParlInfo search results). Details of the harvesting process are available <a href=\"https://glam-workbench.github.io/hansard/\">in the GLAM Workbench</a>. #dhhacks</p>\n",
				"content_text": "I‚Äôve added more years to my [repository of Commonwealth Hansard](https://github.com/wragge/hansard-xml)! The repository now includes XML-formatted text files for both houses from 1901 to 1980, and 1998 to 2005. I‚Äôve done some more checking and confirmed that the XML files for 1981 to 1997 aren't currently available through ParlInfo, however, the Parliamentary Library are looking into it. I‚Äôve also created a [CSV-formatted list of sitting days](https://github.com/GLAM-Workbench/australian-commonwealth-hansard/blob/master/data/all-sitting-days.csv) from 1901 to 2005 (based on ParlInfo search results). Details of the harvesting process are available [in the GLAM Workbench](https://glam-workbench.github.io/hansard/). #dhhacks\n",
				"date_published": "2020-10-26T16:52:00+11:00",
				"url": "https://updates.timsherratt.org/2020/10/26/ive-added-more.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/10/26/it-was-open.html",
				
				"content_html": "<p>It was Open Access Week last week, so I tried a little experiment. How many research articles published in <em>Australian Historical Studies</em> between 2008 and 2018 are available via Open Access? Just <strong>9.5%</strong> (23 out of 242). This is despite the fact that all articles published in 2018 or earlier are outside of the journal‚Äôs embargo period and Green OA versions could be shared through repositories.</p>\n\n<p>Here‚Äôs all the code, it could be easily modified to work with other journals: <a href=\"https://nbviewer.jupyter.org/github/wragge/ozhist-openaccess/blob/master/finding-oa-versions-of-AHS-articles.ipynb\">nbviewer.jupyter.org/github/wr&hellip;</a> #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/5323332221.jpg\" width=\"600\" height=\"339\" alt=\"\" /></p>\n",
				"content_text": "It was Open Access Week last week, so I tried a little experiment. How many research articles published in _Australian Historical Studies_ between 2008 and 2018 are available via Open Access? Just **9.5%** (23 out of 242). This is despite the fact that all articles published in 2018 or earlier are outside of the journal‚Äôs embargo period and Green OA versions could be shared through repositories. \n\nHere‚Äôs all the code, it could be easily modified to work with other journals: [nbviewer.jupyter.org/github/wr...](https://nbviewer.jupyter.org/github/wragge/ozhist-openaccess/blob/master/finding-oa-versions-of-AHS-articles.ipynb) #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/5323332221.jpg\" width=\"600\" height=\"339\" alt=\"\" />\n",
				"date_published": "2020-10-26T11:21:00+11:00",
				"url": "https://updates.timsherratt.org/2020/10/26/it-was-open.html"
			},
			{
				"id": "http://wragge.micro.blog/2020/09/24/the-trove-newspaper.html",
				
				"content_html": "<p>The Trove Newspaper and Gazette Harvester has been updated to include the <code>snippet</code> field in the harvested metadata. <a href=\"https://ozglam.chat/t/trove-newspaper-gazette-harvester-updated-to-version-0-3-3/56\">https://ozglam.chat/t/trove-newspaper-gazette-harvester-updated-to-version-0-3-3/56</a> #dhhacks</p>\n",
				"content_text": "The Trove Newspaper and Gazette Harvester has been updated to include the `snippet` field in the harvested metadata. https://ozglam.chat/t/trove-newspaper-gazette-harvester-updated-to-version-0-3-3/56 #dhhacks\n",
				"date_published": "2020-09-24T11:50:00+11:00",
				"url": "https://updates.timsherratt.org/2020/09/24/the-trove-newspaper.html"
			},
			{
				"id": "http://wragge.micro.blog/2020/09/22/calling-users-of.html",
				
				"content_html": "<p>Calling users of Australian galleries, libraries, archives, &amp; museums ‚Äì <a href=\"https://ozglam.chat/\">OzGLAM Help</a> is now live! Ask a question or simply share your latest discoveries. There‚Äôs handy tips, news about recent developments, &amp; links to useful tools. Please use &amp; share! #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/6aff8fd452.jpg\" width=\"600\" height=\"571\" alt=\"\" /></p>\n",
				"content_text": "Calling users of Australian galleries, libraries, archives, & museums ‚Äì [OzGLAM Help](https://ozglam.chat/) is now live! Ask a question or simply share your latest discoveries. There‚Äôs handy tips, news about recent developments, & links to useful tools. Please use & share! #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/6aff8fd452.jpg\" width=\"600\" height=\"571\" alt=\"\" />\n",
				"date_published": "2020-09-22T11:12:21+11:00",
				"url": "https://updates.timsherratt.org/2020/09/22/calling-users-of.html"
			},
			{
				"id": "http://wragge.micro.blog/2020/09/21/the-zotero-translator.html",
				
				"content_html": "<p>The Zotero translator for RecordSearch (the National Archives of Australia&rsquo;s online database) has been updated. There&rsquo;s many fixes and enhancements ‚Äî see the <a href=\"https://ozglam.chat/t/zotero-translator-for-recordsearch-updated/27?u=wragge\">full details</a>. #dhhacks</p>\n",
				"content_text": "The Zotero translator for RecordSearch (the National Archives of Australia's online database) has been updated. There's many fixes and enhancements ‚Äî see the [full details](https://ozglam.chat/t/zotero-translator-for-recordsearch-updated/27?u=wragge). #dhhacks\n",
				"date_published": "2020-09-21T12:02:41+11:00",
				"url": "https://updates.timsherratt.org/2020/09/21/the-zotero-translator.html"
			},
			{
				"id": "http://wragge.micro.blog/2020/09/20/if-you-try.html",
				
				"content_html": "<p>If you try to share or bookmark the url of an item in RecordSearch (the National Archives of Australia&rsquo;s online database), you‚Äôll often get a ‚ÄòSession time out‚Äô error when you access it. That‚Äôs because the urls only work within the current active RecordSearch session. So how can you create a shareable link that works across sessions? I‚Äôve created a simple app that helps you create shareable links: <a href=\"https://recordsearch-links.glitch.me/\">recordsearch-links.glitch.me</a> #dhhacks</p>\n",
				"content_text": "If you try to share or bookmark the url of an item in RecordSearch (the National Archives of Australia's online database), you‚Äôll often get a ‚ÄòSession time out‚Äô error when you access it. That‚Äôs because the urls only work within the current active RecordSearch session. So how can you create a shareable link that works across sessions? I‚Äôve created a simple app that helps you create shareable links: [recordsearch-links.glitch.me](https://recordsearch-links.glitch.me/) #dhhacks\n",
				"date_published": "2020-09-20T18:18:07+11:00",
				"url": "https://updates.timsherratt.org/2020/09/20/if-you-try.html"
			},
			{
				"id": "http://wragge.micro.blog/2020/09/15/the-zotero-translator.html",
				
				"content_html": "<p>The Zotero translator for Trove was failing on newspaper articles with tags. I‚Äôve submitted a fix for approval: <a href=\"https://github.com/zotero/translators/pull/2246\">github.com/zotero/tr&hellip;</a></p>\n\n<p>I‚Äôm not sure yet whether the capture of works and search results can be fixed following the Trove redesign. React is not very scraper friendly‚Ä¶</p>\n",
				"content_text": "The Zotero translator for Trove was failing on newspaper articles with tags. I‚Äôve submitted a fix for approval: [github.com/zotero/tr...](https://github.com/zotero/translators/pull/2246)\n\nI‚Äôm not sure yet whether the capture of works and search results can be fixed following the Trove redesign. React is not very scraper friendly‚Ä¶\n",
				"date_published": "2020-09-15T13:20:00+11:00",
				"url": "https://updates.timsherratt.org/2020/09/15/the-zotero-translator.html"
			},
			{
				"id": "http://wragge.micro.blog/2020/08/14/another-glamworkbench-update.html",
				
				"content_html": "<p>Another #GLAMWorkbench update! Snip words out of @TroveAustralia newspaper pages and create big composite images. OCR art! <a href=\"https://glam-workbench.github.io/trove-newspapers/#create-large-composite-images-from-snipped-words\">glam-workbench.github.io/trove-new&hellip;</a> #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/84a098fba1.jpg\" width=\"600\" height=\"380\" alt=\"\" /></p>\n",
				"content_text": "Another #GLAMWorkbench update! Snip words out of @TroveAustralia newspaper pages and create big composite images. OCR art! [glam-workbench.github.io/trove-new...](https://glam-workbench.github.io/trove-newspapers/#create-large-composite-images-from-snipped-words) #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/84a098fba1.jpg\" width=\"600\" height=\"380\" alt=\"\" />\n",
				"date_published": "2020-08-14T18:29:50+11:00",
				"url": "https://updates.timsherratt.org/2020/08/14/another-glamworkbench-update.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/08/10/just-in-time.html",
				
				"content_html": "<p>Just in time for #GovHack, I‚Äôve given the Trove API Console a major overhaul. It‚Äôs been updated for the latest API versions and has MANY MANY more examples. Explore all the data you can get from @TroveAustralia! <a href=\"https://troveconsole.herokuapp.com/\">troveconsole.herokuapp.com</a> #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/d548f71ad1.jpg\" width=\"600\" height=\"484\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/55b3c90d67.jpg\" width=\"600\" height=\"481\" alt=\"\" /></p>\n",
				"content_text": "Just in time for #GovHack, I‚Äôve given the Trove API Console a major overhaul. It‚Äôs been updated for the latest API versions and has MANY MANY more examples. Explore all the data you can get from @TroveAustralia! [troveconsole.herokuapp.com](https://troveconsole.herokuapp.com/) #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/d548f71ad1.jpg\" width=\"600\" height=\"484\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/55b3c90d67.jpg\" width=\"600\" height=\"481\" alt=\"\" />\n",
				"date_published": "2020-08-10T17:29:26+11:00",
				"url": "https://updates.timsherratt.org/2020/08/10/just-in-time.html"
			},
			{
				"id": "http://wragge.micro.blog/2020/07/30/ok-so-do.html",
				
				"content_html": "<p>Ok, so do you want to make your own ‚Äòscissors &amp; paste‚Äô messages using words from @TroveAustralia  newspaper articles? Go to <a href=\"https://glam-workbench.github.io/trove-newspapers/#create-scissors-and-paste-messages-from-trove-newspaper-articles\">the notebook</a> in #GLAMWorkbench &amp; click on ‚ÄòRun live on Binder in Appmode‚Äô. #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/f81fa29de5.jpg\" width=\"600\" height=\"534\" alt=\"\" /></p>\n",
				"content_text": "Ok, so do you want to make your own ‚Äòscissors & paste‚Äô messages using words from @TroveAustralia  newspaper articles? Go to [the notebook](https://glam-workbench.github.io/trove-newspapers/#create-scissors-and-paste-messages-from-trove-newspaper-articles) in #GLAMWorkbench & click on ‚ÄòRun live on Binder in Appmode‚Äô. #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/f81fa29de5.jpg\" width=\"600\" height=\"534\" alt=\"\" />\n",
				"date_published": "2020-07-30T12:37:16+11:00",
				"url": "https://updates.timsherratt.org/2020/07/30/ok-so-do.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/07/29/another-glamworkbench-update.html",
				
				"content_html": "<p>Another #GLAMWorkbench update! The Trove Harvester will now download both newspaper <em>and gazette</em> articles in bulk. You can optionally include full text, and save copies of the articles as images and PDFs. #dhhacks <a href=\"https://glam-workbench.github.io/trove-harvester/\">glam-workbench.github.io/trove-har&hellip;</a></p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/6517b75846.jpg\" width=\"600\" height=\"401\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/f24a2a85a7.jpg\" width=\"600\" height=\"418\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/8512bd6dcc.jpg\" width=\"600\" height=\"426\" alt=\"\" /></p>\n",
				"content_text": "Another #GLAMWorkbench update! The Trove Harvester will now download both newspaper *and gazette* articles in bulk. You can optionally include full text, and save copies of the articles as images and PDFs. #dhhacks [glam-workbench.github.io/trove-har...](https://glam-workbench.github.io/trove-harvester/)\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/6517b75846.jpg\" width=\"600\" height=\"401\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/f24a2a85a7.jpg\" width=\"600\" height=\"418\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/8512bd6dcc.jpg\" width=\"600\" height=\"426\" alt=\"\" />\n",
				"date_published": "2020-07-29T14:17:56+11:00",
				"url": "https://updates.timsherratt.org/2020/07/29/another-glamworkbench-update.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/07/28/interested-in-using.html",
				
				"content_html": "<p>Interested in using web archives in your research? Join us on 5/6 August for a free @netpreserve webinar introducing the tools and examples available in the new #webarchives section of the #GLAMWorkbench. There are two timeslots to cover multiple timezones: <a href=\"https://www.eventbrite.com/e/iipc-rss-webinar-jupyter-notebooks-for-web-archives-i-tickets-111349651806\">www.eventbrite.com/e/iipc-rs&hellip;</a> and <a href=\"https://www.eventbrite.com/e/iipc-rss-webinar-jupyter-notebooks-for-web-archives-ii-tickets-112728556146\">www.eventbrite.com/e/iipc-rs&hellip;</a></p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/7c05a95c47.jpg\" width=\"600\" height=\"600\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/2b04bdefc6.jpg\" width=\"600\" height=\"534\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/97c4d924f2.jpg\" width=\"600\" height=\"255\" alt=\"\" /></p>\n",
				"content_text": "Interested in using web archives in your research? Join us on 5/6 August for a free @netpreserve webinar introducing the tools and examples available in the new #webarchives section of the #GLAMWorkbench. There are two timeslots to cover multiple timezones: [www.eventbrite.com/e/iipc-rs...](https://www.eventbrite.com/e/iipc-rss-webinar-jupyter-notebooks-for-web-archives-i-tickets-111349651806) and [www.eventbrite.com/e/iipc-rs...](https://www.eventbrite.com/e/iipc-rss-webinar-jupyter-notebooks-for-web-archives-ii-tickets-112728556146)\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/7c05a95c47.jpg\" width=\"600\" height=\"600\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/2b04bdefc6.jpg\" width=\"600\" height=\"534\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/97c4d924f2.jpg\" width=\"600\" height=\"255\" alt=\"\" />\n",
				"date_published": "2020-07-28T10:27:51+11:00",
				"url": "https://updates.timsherratt.org/2020/07/28/interested-in-using.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/07/27/introducing-a-brand.html",
				
				"content_html": "<p>Introducing a brand new section of the #GLAMWorkbench, exploring the @MuseumsVictoria collection API. Harvest species records, display random images, and download ALL THE ANTECHINUSES! <a href=\"https://glam-workbench.github.io/museumsvictoria/\">glam-workbench.github.io/museumsvi&hellip;</a> #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/49e33f96fa.jpg\" width=\"504\" height=\"600\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/4c51985cb0.jpg\" width=\"600\" height=\"510\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/8e81a5f34f.jpg\" width=\"600\" height=\"369\" alt=\"\" /></p>\n",
				"content_text": "Introducing a brand new section of the #GLAMWorkbench, exploring the @MuseumsVictoria collection API. Harvest species records, display random images, and download ALL THE ANTECHINUSES! [glam-workbench.github.io/museumsvi...](https://glam-workbench.github.io/museumsvictoria/) #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/49e33f96fa.jpg\" width=\"504\" height=\"600\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/4c51985cb0.jpg\" width=\"600\" height=\"510\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/8e81a5f34f.jpg\" width=\"600\" height=\"369\" alt=\"\" />\n",
				"date_published": "2020-07-27T18:46:40+11:00",
				"url": "https://updates.timsherratt.org/2020/07/27/introducing-a-brand.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/07/27/new-additions-to.html",
				
				"content_html": "<p>New additions to the @TroveAustralia books section of the #GLAMWorkbench ‚Äì word frequency examples with OCRd text from digitised books, and a random recipe generator powered by a 19th C cook book! <a href=\"https://glam-workbench.github.io/trove-books/\">glam-workbench.github.io/trove-boo&hellip;</a> #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/70f278df90.jpg\" width=\"600\" height=\"485\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/5fdbedbcea.jpg\" width=\"600\" height=\"229\" alt=\"\" /></p>\n",
				"content_text": "New additions to the @TroveAustralia books section of the #GLAMWorkbench ‚Äì word frequency examples with OCRd text from digitised books, and a random recipe generator powered by a 19th C cook book! [glam-workbench.github.io/trove-boo...](https://glam-workbench.github.io/trove-books/) #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/70f278df90.jpg\" width=\"600\" height=\"485\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/5fdbedbcea.jpg\" width=\"600\" height=\"229\" alt=\"\" />\n",
				"date_published": "2020-07-27T16:32:34+11:00",
				"url": "https://updates.timsherratt.org/2020/07/27/new-additions-to.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/07/27/with-the-recent.html",
				
				"content_html": "<p>With the recent changes to @TroveAustralia, the Australian Women‚Äôs Weekly cover browser was retired. As a low-tech alternative, I‚Äôve harvested all the cover images from the Women&rsquo;s Weekly and saved them into PDFs for easy browsing, one for each decade. There are 2,566 images from 1933 to 1982.</p>\n\n<ul>\n<li><a href=\"https://www.dropbox.com/s/0j6zpeuw6tbey5k/aww-1933-1939.pdf?dl=0\">1933 to 1939</a></li>\n<li><a href=\"https://www.dropbox.com/s/y1he8dd6h655weu/aww-1940-1949.pdf?dl=0\">1940 to 1949</a></li>\n<li><a href=\"https://www.dropbox.com/s/i9gp9i51nofmlqo/aww-1950-1959.pdf?dl=0\">1950 to 1959</a></li>\n<li><a href=\"https://www.dropbox.com/s/2of63tovcnphijo/aww-1960-1969.pdf?dl=0\">1960 to 1969</a></li>\n<li><a href=\"https://www.dropbox.com/s/f2yxpg8u4dx5uf2/aww-1970-1979.pdf?dl=0\">1970 to 1979</a></li>\n<li><a href=\"https://www.dropbox.com/s/xanohtas1fi7eu4/aww-1980-1982.pdf?dl=0\">1980 to 1982</a></li>\n</ul>\n\n<p>Just click on the link below each image to explore the complete issue on Trove. You can also download the full collection of images <a href=\"https://cloudstor.aarnet.edu.au/plus/s/NaKjoKNFOGXXDNN\">from Cloudstor</a>. There&rsquo;s a <a href=\"https://github.com/GLAM-Workbench/trove-newspapers/blob/58307d3ccae4d2c939ecb6aff59944f27d213842/data/aww-issues.csv\">CSV file</a> containing all the issue metadata.</p>\n\n<p>The <a href=\"https://glam-workbench.github.io/trove-newspapers/#harvest-australian-womens-weekly-covers-or-the-front-pages-of-any-newspaper\">notebook used to harvest the images</a> is in the Trove newspapers section of the GLAM Workbench. You could easily adapt the notebook to harvest the front pages of any newspaper. #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/a8730e6b43.jpg\" width=\"447\" height=\"600\" alt=\"\" /></p>\n",
				"content_text": "With the recent changes to @TroveAustralia, the Australian Women‚Äôs Weekly cover browser was retired. As a low-tech alternative, I‚Äôve harvested all the cover images from the Women's Weekly and saved them into PDFs for easy browsing, one for each decade. There are 2,566 images from 1933 to 1982. \n\n  * [1933 to 1939](https://www.dropbox.com/s/0j6zpeuw6tbey5k/aww-1933-1939.pdf?dl=0)\n  * [1940 to 1949](https://www.dropbox.com/s/y1he8dd6h655weu/aww-1940-1949.pdf?dl=0)\n  * [1950 to 1959](https://www.dropbox.com/s/i9gp9i51nofmlqo/aww-1950-1959.pdf?dl=0)\n  * [1960 to 1969](https://www.dropbox.com/s/2of63tovcnphijo/aww-1960-1969.pdf?dl=0)\n  * [1970 to 1979](https://www.dropbox.com/s/f2yxpg8u4dx5uf2/aww-1970-1979.pdf?dl=0)\n  * [1980 to 1982](https://www.dropbox.com/s/xanohtas1fi7eu4/aww-1980-1982.pdf?dl=0)\n\nJust click on the link below each image to explore the complete issue on Trove. You can also download the full collection of images [from Cloudstor](https://cloudstor.aarnet.edu.au/plus/s/NaKjoKNFOGXXDNN). There's a [CSV file](https://github.com/GLAM-Workbench/trove-newspapers/blob/58307d3ccae4d2c939ecb6aff59944f27d213842/data/aww-issues.csv) containing all the issue metadata.\n\nThe [notebook used to harvest the images](https://glam-workbench.github.io/trove-newspapers/#harvest-australian-womens-weekly-covers-or-the-front-pages-of-any-newspaper) is in the Trove newspapers section of the GLAM Workbench. You could easily adapt the notebook to harvest the front pages of any newspaper. #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/a8730e6b43.jpg\" width=\"447\" height=\"600\" alt=\"\" />\n",
				"date_published": "2020-07-27T11:52:18+11:00",
				"url": "https://updates.timsherratt.org/2020/07/27/with-the-recent.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/07/17/the-trove-books.html",
				
				"content_html": "<p>The <a href=\"https://glam-workbench.github.io/trove-books/\">Trove books section</a> of the #GLAMWorkbench has been updated. There&rsquo;s a fresh harvest of OCRd text &amp; the notebooks have been changed to work with the new @TroveAustralia interface. Download &amp; explore 24,620 files (3gb) of OCRd text! #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/766d9155ba.jpg\" width=\"600\" height=\"527\" alt=\"\" /></p>\n",
				"content_text": "The [Trove books section](https://glam-workbench.github.io/trove-books/) of the #GLAMWorkbench has been updated. There's a fresh harvest of OCRd text & the notebooks have been changed to work with the new @TroveAustralia interface. Download & explore 24,620 files (3gb) of OCRd text! #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/766d9155ba.jpg\" width=\"600\" height=\"527\" alt=\"\" />\n",
				"date_published": "2020-07-17T23:11:35+11:00",
				"url": "https://updates.timsherratt.org/2020/07/17/the-trove-books.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/07/17/revisiting-my-historic.html",
				
				"content_html": "<p>Revisiting my Historic Hansard XML repository &amp; realising how easy it is to load files as needed via the GitHub API &amp; explore with Pandas &amp; Jupyter. This #GLAMWorkbench <a href=\"https://glam-workbench.github.io/hansard/#convert-a-years-worth-of-historic-hansard-into-a-dataframe-for-analysis\">notebook</a> helps you explore a particular year/house. #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/2839d8e003.jpg\" width=\"600\" height=\"357\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/ec52714756.jpg\" width=\"600\" height=\"265\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/a4c3f7667d.jpg\" width=\"600\" height=\"396\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/a788b76bb3.jpg\" width=\"600\" height=\"436\" alt=\"\" /></p>\n",
				"content_text": "Revisiting my Historic Hansard XML repository & realising how easy it is to load files as needed via the GitHub API & explore with Pandas & Jupyter. This #GLAMWorkbench [notebook](https://glam-workbench.github.io/hansard/#convert-a-years-worth-of-historic-hansard-into-a-dataframe-for-analysis) helps you explore a particular year/house. #dhhacks \n\n<img src=\"https://updates.timsherratt.org/uploads/2020/2839d8e003.jpg\" width=\"600\" height=\"357\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/ec52714756.jpg\" width=\"600\" height=\"265\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/a4c3f7667d.jpg\" width=\"600\" height=\"396\" alt=\"\" /><img src=\"https://updates.timsherratt.org/uploads/2020/a788b76bb3.jpg\" width=\"600\" height=\"436\" alt=\"\" />\n",
				"date_published": "2020-07-17T17:07:44+11:00",
				"url": "https://updates.timsherratt.org/2020/07/17/revisiting-my-historic.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/07/14/the-trove-journals.html",
				
				"content_html": "<p>The <a href=\"https://glam-workbench.github.io/trove-journals/\">Trove Journals section</a> of the #GLAMWorkbench has been updated to work with the new @TroveAustralia interface! I‚Äôve also re-harvested ALL the OCRd text from digitised journals ‚Äî 6gb of text from 397 journals now downloadable in bulk from CloudStor. #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/d9b0c2e64d.jpg\" width=\"600\" height=\"264\" alt=\"\" /></p>\n",
				"content_text": "The [Trove Journals section](https://glam-workbench.github.io/trove-journals/) of the #GLAMWorkbench has been updated to work with the new @TroveAustralia interface! I‚Äôve also re-harvested ALL the OCRd text from digitised journals ‚Äî 6gb of text from 397 journals now downloadable in bulk from CloudStor. #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/d9b0c2e64d.jpg\" width=\"600\" height=\"264\" alt=\"\" />\n",
				"date_published": "2020-07-14T14:31:47+11:00",
				"url": "https://updates.timsherratt.org/2020/07/14/the-trove-journals.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/07/12/new-in-glamworkbench.html",
				
				"content_html": "<p>New in #GLAMWorkbench! After you‚Äôve used the @TroveAustralia Newspaper Harvester to download lots &amp; lots of articles, try exploring the results in Datasette. <a href=\"https://glam-workbench.github.io/trove-harvester/#display-the-results-of-a-harvest-as-a-searchable-database-using-datasette\">This notebook</a> sets everything up, you can even add full text search &amp; images! #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/43c8c5e1e7.jpg\" width=\"600\" height=\"428\" alt=\"\" /></p>\n",
				"content_text": "New in #GLAMWorkbench! After you‚Äôve used the @TroveAustralia Newspaper Harvester to download lots & lots of articles, try exploring the results in Datasette. [This notebook](https://glam-workbench.github.io/trove-harvester/#display-the-results-of-a-harvest-as-a-searchable-database-using-datasette) sets everything up, you can even add full text search & images! #dhhacks \n\n<img src=\"https://updates.timsherratt.org/uploads/2020/43c8c5e1e7.jpg\" width=\"600\" height=\"428\" alt=\"\" />\n",
				"date_published": "2020-07-12T14:18:00+11:00",
				"url": "https://updates.timsherratt.org/2020/07/12/new-in-glamworkbench.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/06/29/download-newspaper-articles.html",
				
				"content_html": "<p>Download newspaper articles in bulk! The Trove Newspaper Harvester has been updated to work with the new @TroveAustralia interface. I‚Äôve also added the ability to save articles as .jpg images! The easiest way to get started is <a href=\"https://glam-workbench.github.io/trove-harvester/\">via the #GLAMWorkbench</a>. #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/fe9cb9a58b.jpg\" width=\"600\" height=\"487\" alt=\"Screenshot of Trove Harvester page in GLAM Workbench\" /><img src=\"https://updates.timsherratt.org/uploads/2020/5b8395e147.jpg\" width=\"600\" height=\"255\" alt=\"Screenshot of TroveHarvester web app\" /><img src=\"https://updates.timsherratt.org/uploads/2020/39a828a8c3.jpg\" width=\"600\" height=\"270\" alt=\"Details of image file naming scheme\" /><img src=\"https://updates.timsherratt.org/uploads/2020/af98a9856b.jpg\" width=\"600\" height=\"302\" alt=\"Thumbnails of newspaper articles saved as images\" /></p>\n",
				"content_text": "Download newspaper articles in bulk! The Trove Newspaper Harvester has been updated to work with the new @TroveAustralia interface. I‚Äôve also added the ability to save articles as .jpg images! The easiest way to get started is [via the #GLAMWorkbench](https://glam-workbench.github.io/trove-harvester/). #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/fe9cb9a58b.jpg\" width=\"600\" height=\"487\" alt=\"Screenshot of Trove Harvester page in GLAM Workbench\" /><img src=\"https://updates.timsherratt.org/uploads/2020/5b8395e147.jpg\" width=\"600\" height=\"255\" alt=\"Screenshot of TroveHarvester web app\" /><img src=\"https://updates.timsherratt.org/uploads/2020/39a828a8c3.jpg\" width=\"600\" height=\"270\" alt=\"Details of image file naming scheme\" /><img src=\"https://updates.timsherratt.org/uploads/2020/af98a9856b.jpg\" width=\"600\" height=\"302\" alt=\"Thumbnails of newspaper articles saved as images\" />\n",
				"date_published": "2020-06-29T10:48:53+11:00",
				"url": "https://updates.timsherratt.org/2020/06/29/download-newspaper-articles.html",
				"tags": ["glamworkbench"]
			},
			{
				"id": "http://wragge.micro.blog/2020/06/22/my-app-for.html",
				
				"content_html": "<p>My <a href=\"https://trove-titles.herokuapp.com/\">app for searching</a> in @TroveAustralia‚Äôs digitised journals has been updated to work with the new Trove interface. You‚Äôll need to have switched over to the new interface before you try searching (just click the link on the Trove home page). #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/bf6d84e823.jpg\" width=\"600\" height=\"479\" alt=\"\" /></p>\n",
				"content_text": "My [app for searching](https://trove-titles.herokuapp.com/) in @TroveAustralia‚Äôs digitised journals has been updated to work with the new Trove interface. You‚Äôll need to have switched over to the new interface before you try searching (just click the link on the Trove home page). #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/bf6d84e823.jpg\" width=\"600\" height=\"479\" alt=\"\" />\n",
				"date_published": "2020-06-22T23:48:00+11:00",
				"url": "https://updates.timsherratt.org/2020/06/22/my-app-for.html"
			},
			{
				"id": "http://wragge.micro.blog/2020/06/09/another-db-migrated.html",
				
				"content_html": "<p>Another db migrated and app updated!</p>\n\n<p>Have you ever wondered what interjections in historic hansard would look like as tweets? Well I did‚Ä¶ Now with longer interjections &amp; more emojis!</p>\n\n<p><a href=\"https://hansard-interjections.herokuapp.com/tweets/\">hansard-interjections.herokuapp.com/tweets/</a> #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/6842a3978c.jpg\" width=\"600\" height=\"501\" alt=\"\" /></p>\n",
				"content_text": "Another db migrated and app updated! \n\nHave you ever wondered what interjections in historic hansard would look like as tweets? Well I did‚Ä¶ Now with longer interjections & more emojis! \n\n[hansard-interjections.herokuapp.com/tweets/](https://hansard-interjections.herokuapp.com/tweets/) #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/6842a3978c.jpg\" width=\"600\" height=\"501\" alt=\"\" />\n",
				"date_published": "2020-06-09T14:56:01+11:00",
				"url": "https://updates.timsherratt.org/2020/06/09/another-db-migrated.html"
			},
			{
				"id": "http://wragge.micro.blog/2020/06/09/heres-a-map.html",
				
				"content_html": "<p>Here&rsquo;s a map of places where @TroveAustralia digitised newspapers were published/circulated. Click on the map to find the closest newspapers to a place. Updated with new titles from the last year! <a href=\"https://troveplaces.herokuapp.com/map/\">troveplaces.herokuapp.com/map/</a> #dhhacks</p>\n\n<p><img src=\"https://updates.timsherratt.org/uploads/2020/ce6d32a952.jpg\" width=\"600\" height=\"576\" alt=\"\" /></p>\n",
				"content_text": "Here's a map of places where @TroveAustralia digitised newspapers were published/circulated. Click on the map to find the closest newspapers to a place. Updated with new titles from the last year! [troveplaces.herokuapp.com/map/](https://troveplaces.herokuapp.com/map/) #dhhacks\n\n<img src=\"https://updates.timsherratt.org/uploads/2020/ce6d32a952.jpg\" width=\"600\" height=\"576\" alt=\"\" />\n",
				"date_published": "2020-06-09T10:43:12+11:00",
				"url": "https://updates.timsherratt.org/2020/06/09/heres-a-map.html"
			}
	]
}
